{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer MITOCHONDRIA - part 5ï¸âƒ£\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE: âœ… Infer sub-cellular component  MITOCHONDRIA  in order to understand interactome \n",
    "\n",
    "\n",
    "\n",
    "Dependencies:\n",
    "The MITOCHONDRIA  inference rely on the CYTOSOL, which is SOMA&~NUCLEI.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "# TODO:  prune the imports.. this is the big set for almost all organelles\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.seg_dot import dot_3d_wrapper, dot_slice_by_slice, dot_2d_slice_by_slice_wrapper, dot_3d\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_3d,  \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "from aicssegmentation.core.utils import topology_preserving_thinning, size_filter\n",
    "from aicssegmentation.core.MO_threshold import MO\n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from aicssegmentation.core.vessel import filament_2d_wrapper, vesselnessSliceBySlice\n",
    "from aicssegmentation.core.output_utils import   save_segmentation,  generate_segmentation_contour\n",
    "                                                 \n",
    "from skimage import filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.morphology import remove_small_objects, binary_closing, ball , dilation, remove_small_holes   # function for post-processing (size filter)\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.utils.file_io import (read_input_image, \n",
    "                                                                    list_image_files, \n",
    "                                                                    export_ome_tiff, \n",
    "                                                                    etree_to_dict, \n",
    "                                                                    save_parameters, \n",
    "                                                                    load_parameters, \n",
    "                                                                    export_ndarray)\n",
    "from infer_subc_2d.utils.img import *\n",
    "from infer_subc_2d.organelles.nuclei import infer_NUCLEI\n",
    "from infer_subc_2d.organelles.soma import infer_SOMA\n",
    "from infer_subc_2d.organelles.cytosol import infer_CYTOSOL\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "test_img_n = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE PROCESSING Objective 5:  infer MITOCHONDRIA\n",
    "\n",
    "\n",
    "## summary of steps (Workflow #1 & #2)\n",
    "\n",
    "INPUT\n",
    "- channel  3\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  smoothe / remove noise\n",
    "\n",
    "CORE-PROCESSING\n",
    "-  segment objects\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - filter objects\n",
    "\n",
    "OUTPUT\n",
    "- object MITOCHONDRIA \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------------------------\n",
    "# LOAD RAW IMAGE DATA\n",
    "Identify path to _raw_ image data and load our example image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n",
    "\n",
    "bioim_image = read_input_image(test_img_name)\n",
    "img_data = bioim_image.image\n",
    "raw_meta_data = bioim_image.raw_meta\n",
    "ome_types = []\n",
    "meta_dict = bioim_image.meta\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get default parameters, including  \"optimal\" Z\n",
    "\n",
    "takes ~ 4 seconds to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_Z_from_params = False\n",
    "\n",
    "\n",
    "if load_Z_from_params:\n",
    "\n",
    "    default_params = load_parameters( test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )\n",
    "\n",
    "    ch_to_agg = default_params[\"ch_to_agg\"]\n",
    "    nuc_ch = default_params['nuc_ch']\n",
    "    optimal_Z = default_params[\"optimal_Z\"] #find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n",
    "else:\n",
    "    ch_to_agg = (1,2,3,4,5,6)\n",
    "    nuc_ch = 0\n",
    "    optimal_Z = find_optimal_Z(img_data, nuc_ch, ch_to_agg) \n",
    "\n",
    "    default_params = defaultdict(str, **{\n",
    "        #\"intensity_norm_param\" : [0.5, 15]\n",
    "        \"intensity_norm_param\" : [0],\n",
    "        \"gaussian_smoothing_sigma\" : 1.34,\n",
    "        \"gaussian_smoothing_truncate_range\" : 3.0,\n",
    "        \"dot_2d_sigma\" : 2,\n",
    "        \"dot_2d_sigma_extra\" : 1,\n",
    "        \"dot_2d_cutoff\" : 0.025,\n",
    "        \"min_area\" : 10,\n",
    "        \"low_level_min_size\" :  100,\n",
    "        \"median_filter_size\" : 4,\n",
    "        \"ch_to_agg\" : (1,2,3,4,5,6), # exclude residual\n",
    "        \"nuc_ch\" : 0,\n",
    "        \"optimal_Z\": optimal_Z,\n",
    "    })\n",
    "    save_parameters(default_params, test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )\n",
    "# make sure we have removed Z\n",
    "if len(scale)>2:\n",
    "    scale = scale[1:]\n",
    "\n",
    "\n",
    "img_2D = img_data[:,[optimal_Z],:,:].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the inferred nuclei object\n",
    "\n",
    "(takes < 1 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "raw_nuclei = img_2D[0].copy()\n",
    "NU_object, NU_label, out_p =  infer_NUCLEI(raw_nuclei.copy(), default_params) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the inferred soma object\n",
    "\n",
    "(takes < 1 sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n",
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "raw_soma = (4. * img_2D[1].copy() + \n",
    "                               1. * img_2D[5].copy() + \n",
    "                               1. * img_2D[7].copy() )\n",
    "\n",
    "SO_object, SO_label, out_p =  infer_SOMA(raw_soma.copy(), NU_label, default_params) \n",
    "CY_object =  infer_CYTOSOL(SO_object, NU_object) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKFLOW #1 \n",
    "\n",
    "Generally following the Allen Cell Segmenter procedure, but doing more aggressive contrast scaling than their prescribed contrast scaling.\n",
    "\n",
    "> Using Allen Cell Segmenter Tom20as a potential Mitochondrian segmenter to start with  start from [Allen Cell](https://www.allencell.org/cell-observations/category/mitochondria).   using [seg_tomm20.py](\"../../../../aics-segmentation/aicssegmentation/structure_wrapper/seg_tomm20.py\")\n",
    "\n",
    "## summary of steps\n",
    "\n",
    "INPUT\n",
    "- channel  2\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  smoothe / remove noise\n",
    "\n",
    "CORE-PROCESSING\n",
    "-  'vesselness' enhancement\n",
    "-  threshold objects\n",
    "\n",
    "- POST-PROCESSING\n",
    "  - filter objects\n",
    "\n",
    "OUTPUT\n",
    "- object MITOCHONDRIA \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "raw_mito    = img_2D[2].copy()\n",
    "\n",
    "# mask object\n",
    "masked_mito = apply_mask(raw_mito,CY_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "intensity_norm_param = [0, 9] # from Allen Cell Segmenter LAMP1  workflow\n",
    "\n",
    "# Linear-ish smoothing\n",
    "struct_img = intensity_normalization( masked_mito ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "med_filter_size = 3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "struct_img = median_filter(struct_img,    size=med_filter_size  )\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "# dot and filiment enhancement - 2D\n",
    "\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "vesselness_sigma = [1.5]\n",
    "vesselness_cutoff = 0.1\n",
    "# 2d vesselness slice by slice\n",
    "response = vesselnessSliceBySlice(structure_img_smooth, sigmas=vesselness_sigma, tau=1, whiteonblack=True)\n",
    "bw = response > vesselness_cutoff\n",
    "\n",
    "\n",
    "# # from Sec61b workflows - playground references Tom20\n",
    "# f2_param = [[1.5, 0.16]]\n",
    "# bw = filament_2d_wrapper(structure_img_smooth, f2_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 3D\n",
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "################################\n",
    "## PARAMETERS for this step ##\n",
    "\n",
    "small_object_max = 3\n",
    "\n",
    "MT_object = size_filter_2D(bw, \n",
    "                                                min_size= small_object_max**2, \n",
    "                                                connectivity=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'structure_img_smooth' at 0x14e0ede50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "viewer = napari.view_image(\n",
    "    raw_mito,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    structure_img_smooth,\n",
    "    scale=scale\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'bw' at 0x17920c850>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer.add_image(\n",
    "    bw,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE `infer_MITOCHONDRIA` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  infer_MITOCHONDRIA\n",
    "##########################\n",
    "def _infer_MITOCHONDRIA(struct_img, CY_object,  in_params) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer MITOCHONDRIA  from linearly unmixed input.\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the MITOCHONDRIA signal\n",
    "\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of MITOCHONDRIA\n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "\n",
    "    struct_img = apply_mask(struct_img,CY_object)\n",
    "    \n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    scaling_param =  [0,9]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "   # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 3   \n",
    "    structure_img = median_filter(struct_img,    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 1.34\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    # log_img, d = log_transform( struct_img ) \n",
    "    # struct_img = intensity_normalization( log_img ,  scaling_param=[0] )  \n",
    "    # struct_img = intensity_normalization( struct_img ,  scaling_param=[0] )  \n",
    "\n",
    "\n",
    "   ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    ################################\n",
    "    ## PARAMETERS for this step ##\n",
    "    vesselness_sigma = [1.5]\n",
    "    vesselness_cutoff = 0.1\n",
    "    # 2d vesselness slice by slice\n",
    "    response = vesselnessSliceBySlice(structure_img_smooth, sigmas=vesselness_sigma, tau=1, whiteonblack=True)\n",
    "    bw = response > vesselness_cutoff\n",
    "\n",
    "    out_p[\"vesselness_sigma\"] = vesselness_sigma \n",
    "    out_p[\"vesselness_cutoff\"] = vesselness_cutoff \n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    # MT_object = remove_small_objects(bw > 0, min_size=small_object_max**2, connectivity=1, in_place=False)\n",
    "    small_object_max = 3\n",
    "    struct_obj = size_filter_2D(bw, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max**2, \n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max'] = small_object_max\n",
    "\n",
    "    retval = (struct_obj,  out_p)\n",
    "    return retval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "# TEST `infer_MITOCHONDRIA` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "raw_mito    = img_2D[2].copy()\n",
    "\n",
    "MT_object, out_p =  _infer_MITOCHONDRIA(raw_mito, CY_object, default_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'Labels' at 0x18347cb20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "viewer.add_image(\n",
    "    MT_object,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_labels(\n",
    "    label(MT_object),\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles.mitochondria import infer_MITOCHONDRIA\n",
    "\n",
    "\n",
    "img_2D = img_data[:,[optimal_Z],:,:].copy()\n",
    "raw_mito    = img_2D[2].copy()\n",
    "\n",
    "MT_object, out_p =  infer_MITOCHONDRIA(raw_mito, CY_object, default_params) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "\n",
    " ðŸš§ WIP ðŸš§ (ðŸš¨ðŸš¨ðŸš¨ðŸš¨ )\n",
    "\n",
    "# WORKFLOW #2 (WIP)\n",
    "as per 6/22 CellProfiler pipeline from MCZ\n",
    " > ADAPTIVE... not sure exactly how to impliment this...\n",
    "\n",
    "  >ReduceNoise performs non-local means noise reduction. Instead of only using a neighborhood of pixels around a central pixel for denoising, such as in GaussianFilter, multiple neighborhoods are pooled together. The neighborhood pool is determined by scanning the image for regions similar to the area around the central pixel using a correlation metric and a cutoff value.\n",
    "   \n",
    "## summary of steps (Workflow #1 & #2)\n",
    "\n",
    "INPUT\n",
    "- ch 3\n",
    "- CY mask\n",
    "\n",
    "PRE-PROCESSING\n",
    "-  non-local noise reduction\n",
    "  - size:4, distance:2, cut-off:0.1\n",
    "\n",
    "CORE-PROCESSING\n",
    "  - adaptive Otsu\n",
    "    - diameter: (2,200)\n",
    "  - two classes\n",
    "    - threshold smoothing scale: 0\n",
    "    - threshold correction factor: .1\n",
    "    - threshold bounds: (0.14 1)\n",
    "    - adaptive window: 20 pixels\n",
    "\n",
    "POST-PROCESSING\n",
    "  - N/A\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "raw_mito    = img_2D[2].copy()\n",
    "\n",
    "# mask object\n",
    "masked_mito = apply_mask(raw_mito,CY_object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intensity normalization: min-max normalization with NO absoluteintensity upper bound\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "\n",
    "intensity_norm_param = [0] # \n",
    "\n",
    "# Linear-ish smoothing\n",
    "raw_mito = intensity_normalization( masked_mito ,  scaling_param=intensity_norm_param)\n",
    "\n",
    "med_filter_size =3  \n",
    "\n",
    "gaussian_smoothing_sigma = 1.3\n",
    "gaussian_smoothing_truncate_range = 3.0\n",
    "\n",
    "struct_img = median_filter(raw_mito,    size=med_filter_size  )\n",
    "\n",
    "structure_img_smooth = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                                        truncate_range=gaussian_smoothing_truncate_range,\n",
    "                                                                                                                    )\n",
    "\n",
    "\n",
    "# log_img, d = log_transform( structure_img_smooth ) \n",
    "# struct_img = intensity_normalization(  log_img  ,  scaling_param=[0] )  \n",
    "\n",
    "struct_img = structure_img_smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORE PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "# enhance spreckles - 40\n",
    "big_struct_rad = 40\n",
    "big_img = enhance_speckles(struct_img.copy(),big_struct_rad, True)\n",
    "\n",
    "#adaptive_otsu(big_struct) # three class - middle foreground\n",
    "# adaptive window- 20\n",
    "#size: 10,100\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.1497,1)\n",
    "#fill holes\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 10\n",
    "bw_big, _bw_low_level = MO(big_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# enhance speckles\n",
    "#   adaptive_sauvola(sm_struct) \n",
    "# adaptive window- 10\n",
    "#size: 2,10\n",
    "# threshold smooth 1.34\n",
    "# threshold correction 1\n",
    "# threshold (0.05,1)\n",
    "#fill holes\n",
    "\n",
    "# enhance spreckles - 10\n",
    "sm_struct_rad = 20\n",
    "sm_img = enhance_speckles(struct_img.copy(),sm_struct_rad, True)\n",
    "\n",
    "# \"adatpive\" thresholds are NOT currently working... will use      \n",
    "# \"Masked Object Thresholding\" - 3D\n",
    "low_level_min_size = 2\n",
    "bw_sm, _bw_low_level = MO(sm_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size, \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= 0.5, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    " # or this?                                               \n",
    "#    struct_obj = struct_img > filters.threshold_otsu(struct_img)\n",
    "#     threshold_value_log = threshold_otsu_log(struct_img)\n",
    "#     threshold_factor = 0.9 #from cellProfiler\n",
    "#     thresh_min = .1\n",
    "#     thresh_max = 1.\n",
    "#     threshold = min( max(threshold_value_log*threshold_factor, thresh_min), thresh_max)\n",
    "#     struct_obj = struct_img > threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POST-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "\n",
    "# 3D\n",
    "# cleaned_img = remove_small_objects(removed_holes>0, \n",
    "#                                                             min_size=minArea, \n",
    "#                                                             connectivity=1, \n",
    "#                                                             in_place=False)\n",
    "small_object_max = 10\n",
    "cleaned_img_big = size_filter(bw_big, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "#                                                             in_place=False)\n",
    "small_object_max = 2\n",
    "cleaned_img_sm = size_filter(bw_sm, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                         min_size= small_object_max**2,\n",
    "                                                         method = \"slice_by_slice\",\n",
    "                                                         connectivity=1)\n",
    "\n",
    "\n",
    "\n",
    "cleaned_img = np.logical_or(cleaned_img_big, cleaned_img_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize with `napari`\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'sm_img' at 0x17ac9dfa0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "viewer.add_image(\n",
    "    cleaned_img,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.scale_bar.visible = True\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    big_img,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    cleaned_img_big,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    sm_img,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ahenrie/Projects/Imaging/data/intermediate/ZSTACK_PBTOhNGN2hiPSCs_BR3_N14_Unmixed.czi_params.pkl'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save updated parameters for ongoing testing\n",
    "save_parameters(default_params, test_img_name.split(\"/\")[-1], data_root_path / \"intermediate\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# DEFINE `infer_MITOCHONDRIA_CP` function (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of infer_subc_2d.organelles.lysosomes failed: Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 257, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 455, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/opt/anaconda3/envs/napariNEW/lib/python3.9/importlib/__init__.py\", line 159, in reload\n",
      "    raise ImportError(msg.format(parent_name),\n",
      "ImportError: parent 'infer_subc_2d.organelles' not in sys.modules\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# copy this to base.py for easy import\n",
    "# mangle so we can call from base.py\n",
    "def _infer_MITOCHONDRIA_CP(struct_img: np.ndarray,  CY_object:np.array,  in_params:dict) -> tuple:\n",
    "    \"\"\"\n",
    "    Procedure to infer MITOCHONDRIA from linearly unmixed input as per CellProfiler procedure\n",
    "\n",
    "    Parameters:\n",
    "    ------------\n",
    "    struct_img: np.ndarray\n",
    "        a 3d image containing the MITOCHONDRIA signal (should be CY masked)\n",
    "    CY_object: np.ndarray boolean\n",
    "        a 3d image containing the NU labels\n",
    "\n",
    "    in_params: dict\n",
    "        holds the needed parameters\n",
    "\n",
    "    Returns:\n",
    "    -------------\n",
    "    tuple of:\n",
    "        object\n",
    "            mask defined boundaries of SOMA\n",
    "    \n",
    "        parameters: dict\n",
    "            updated parameters in case any needed were missing\n",
    "    \n",
    "    \"\"\"\n",
    "    out_p= in_params.copy()\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    #TODO: replace params below with the input params\n",
    "    scaling_param =  [0]   \n",
    "    struct_img = intensity_normalization(struct_img, scaling_param=scaling_param)\n",
    "    out_p[\"intensity_norm_param\"] = scaling_param\n",
    "\n",
    "\n",
    "    # 2D smoothing\n",
    "    # make a copy for post-post processing\n",
    "    scaled_signal = struct_img.copy()\n",
    "\n",
    "    med_filter_size = 9   \n",
    "    # structure_img_median_3D = ndi.median_filter(struct_img,    size=med_filter_size  )\n",
    "    struct_img = median_filter_slice_by_slice( \n",
    "                                                                    struct_img,\n",
    "                                                                    size=med_filter_size  )\n",
    "    out_p[\"median_filter_size\"] = med_filter_size \n",
    "\n",
    "    gaussian_smoothing_sigma = 3.\n",
    "    gaussian_smoothing_truncate_range = 3.0\n",
    "    struct_img = image_smoothing_gaussian_slice_by_slice(   struct_img,\n",
    "                                                                                                        sigma=gaussian_smoothing_sigma,\n",
    "                                                                                                        truncate_range = gaussian_smoothing_truncate_range\n",
    "                                                                                                    )\n",
    "    out_p[\"gaussian_smoothing_sigma\"] = gaussian_smoothing_sigma \n",
    "    out_p[\"gaussian_smoothing_truncate_range\"] = gaussian_smoothing_truncate_range\n",
    "\n",
    "    #    edges = filters.scharr(struct_img)\n",
    "    # struct_img, d = log_transform( struct_img ) \n",
    "    # struct_img = intensity_normalization(  struct_img,  scaling_param=[0] )\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # enhance spreckles - 40\n",
    "    big_struct_rad = 40\n",
    "    big_img = enhance_speckles(struct_img,big_struct_rad)\n",
    "    out_p[\"big_struct_rad\"] = big_struct_rad \n",
    "\n",
    "    local_adjust = 0.5\n",
    "    low_level_min_size = 10\n",
    "    bw_big, _bw_low_level = MO(big_img, \n",
    "                                                global_thresh_method='ave', \n",
    "                                                object_minArea=low_level_min_size **2 , \n",
    "                                                extra_criteria=True,\n",
    "                                                local_adjust= local_adjust, \n",
    "                                                return_object=True,\n",
    "                                                dilate=True)\n",
    "    out_p[\"local_adjust\"] = local_adjust \n",
    "    out_p[\"low_level_min_size_big\"] = low_level_min_size_big \n",
    "\n",
    "    # enhance spreckles - 10\n",
    "    sm_struct_rad = 20\n",
    "    sm_img = enhance_speckles(struct_img,sm_struct_rad)\n",
    "    out_p[\"big_struct_rad\"] = big_struct_rad \n",
    "\n",
    "    # \"adatpive\" thresholds are NOT currently working... will use      \n",
    "    # \"Masked Object Thresholding\" - 3D\n",
    "    low_level_min_size_sm = 2\n",
    "    bw_sm, _bw_low_level = MO(sm_img, \n",
    "                                                    global_thresh_method='ave', \n",
    "                                                    object_minArea=low_level_min_size_sm **2, \n",
    "                                                    extra_criteria=True,\n",
    "                                                    local_adjust= local_adjust, \n",
    "                                                    return_object=True,\n",
    "                                                    dilate=True)\n",
    "\n",
    "    out_p[\"sm_struct_rad\"] = sm_struct_rad \n",
    "    out_p[\"low_level_min_size_sm\"] = low_level_min_size_sm \n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    # 3D\n",
    "    small_object_max_big = 10\n",
    "    bw_big = size_filter(bw_big, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max_big**2,\n",
    "                                                            method = \"slice_by_slice\",\n",
    "                                                            connectivity=1)\n",
    "\n",
    "\n",
    "    #                                                             in_place=False)\n",
    "    small_object_max_sm = 3\n",
    "    bw_sm = size_filter(bw_sm, # wrapper to remove_small_objects which can do slice by slice\n",
    "                                                            min_size= small_object_max_sm**2,\n",
    "                                                            method = \"slice_by_slice\",\n",
    "                                                            connectivity=1)\n",
    "    out_p['small_object_max_sm'] = small_object_max\n",
    "\n",
    "    struct_obj = np.logical_or(bw_big, bw_sm)\n",
    "\n",
    "    retval = (struct_obj, out_p)\n",
    "    return retval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('napariNEW')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
