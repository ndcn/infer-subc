{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export workflow definitions\n",
    "\n",
    "We need to compose workflows and place the function prototypes into their proper place."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.organelles_config.helper import write_workflow_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import infer_subc_2d.constants"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## WORKFLOWS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## NUCLEI workflow\n",
    "\n",
    "Write the `infer_nuclei_fromlabel` spec to the widget json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import NUC_CH\n",
    "\n",
    "\n",
    "def make_infer_nuclei_dict():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    step_n = 1\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = NUC_CH) )\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"apply_log_li_threshold\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(thresh_factor = 0.9, \n",
    "                                                            thresh_min = .1,\n",
    "                                                            thresh_max = 1.))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_nuclei_dict = make_infer_nuclei_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.1.nuclei\", infer_nuclei_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "\n",
    "## CELLMASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_infer_cellmask_fromaggr_step_by_step_dict():\n",
    "    \"\"\"\n",
    "    crete .json version of infer_cellmask_fromaggr\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    step_n = 1\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_nuclei_fromlabel\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(\n",
    "                                nuc_ch = NUC_CH,\n",
    "                                median_sz = 4,\n",
    "                                gauss_sig = 1.34,\n",
    "                                thresh_factor = 0.9,\n",
    "                                thresh_min = 0.1,\n",
    "                                thresh_max = 1.0,\n",
    "                                max_hole_w = 25,\n",
    "                                small_obj_w = 15)\n",
    "                                )\n",
    "                                \n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"get  nuclei segmentation: {step_n}\")    \n",
    "    step_n += 1                     \n",
    "    nuc_step = step_n\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"raw_cellmask_fromaggr\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\" this creates an aggregate signal for the cellmask\" )\n",
    "    cellmask_input_step = step_n\n",
    "\n",
    "    step_n += 1                     \n",
    "    ### PRE PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(cellmask_input_step)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    struct_img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"non_linear_cellmask_transform_MCZ\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    parent.append(step_n-1)\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### CORE\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( th_method=\"ave_tri_med\",\n",
    "                                                            cutoff_size = 100,\n",
    "                                                            th_adjust = 0.5))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    \n",
    "    step_n += 1\n",
    "\n",
    "    ### POST- POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"choose_max_label_cellmask_union_nucleus\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"cellmask segmentation: {step_n}\")\n",
    "    parent.append([struct_img_step, step_n-1,nuc_step])\n",
    "\n",
    "    soma_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(dict(erode_nuclei=True))\n",
    "    parent.append([nuc_step, soma_step])\n",
    "    annotation.append(f\"infer cytoplasm: {step_n}\")\n",
    "    cyto_step = step_n\n",
    "\n",
    "\n",
    "    # ###################\n",
    "    # # EXPORT\n",
    "    # ###################\n",
    "    # step_name.append(\"18\")\n",
    "    # function_name.append(\"export_PLACE_HOLDER\")\n",
    "    # category.append(\"export\")\n",
    "    # parameter_values.append(None)\n",
    "    # parent.append([5, 17])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_cellmask_fromaggr_stepbystep_dict = make_infer_cellmask_fromaggr_step_by_step_dict()\n",
    "infer_cellmask_fromaggr_stepbystep_dict\n",
    "\n",
    "write_workflow_json(\"conf_1.2.cellmask\", infer_cellmask_fromaggr_stepbystep_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import NUC_CH\n",
    "\n",
    "def make_infer_cellmask_fromaggr_step_by_step_dict2():\n",
    "    \"\"\"\n",
    "    crete .json version of infer_cellmask_fromaggr\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "    step_n = 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_nuclei_fromlabel\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(\n",
    "                                nuc_ch = NUC_CH,\n",
    "                                median_sz = 4,\n",
    "                                gauss_sig = 1.34,\n",
    "                                thresh_factor = 0.9,\n",
    "                                thresh_min = 0.1,\n",
    "                                thresh_max = 1.0,\n",
    "                                max_hole_w = 25,\n",
    "                                small_obj_w = 15)\n",
    "                                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"get  nuclei segmentation: {step_n}\")    \n",
    "    nuc_step = step_n\n",
    "\n",
    "    step_n += 1                     \n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"make_aggregate\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(dict(w0=0,\n",
    "                                    w1=6,\n",
    "                                    w2=0,\n",
    "                                    w3=2,\n",
    "                                    w4=0,\n",
    "                                    w5=1,\n",
    "                                    w6=0,\n",
    "                                    w7=0,\n",
    "                                    w8=0,\n",
    "                                    w9=0,\n",
    "                                    scale_min_max = True) \n",
    "                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\" this creates an aggregate signal for the cellmask\" )\n",
    "    cellmask_input_step = step_n\n",
    "\n",
    "    step_n += 1                   \n",
    "\n",
    "    ### PRE PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(cellmask_input_step)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    struct_img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"non_linear_cellmask_transform_MCZ\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    parent.append(step_n-1)\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### CORE\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( th_method=\"ave_tri_med\",\n",
    "                                                            cutoff_size = 100,\n",
    "                                                            th_adjust = 0.5))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    ### POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic nuclei segmentation: {step_n}\")\n",
    "    \n",
    "    step_n += 1\n",
    "\n",
    "    ### POST- POST_PROCESSING\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"choose_max_label_cellmask_union_nucleus\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    annotation.append(f\"basic cellmask segmentation: {step_n}\")\n",
    "    parent.append([struct_img_step, step_n-1,nuc_step])\n",
    "    soma_step = step_n\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"postpostprocessing\")\n",
    "    parameter_values.append(dict(erode_nuclei=True))\n",
    "    parent.append([nuc_step, soma_step])\n",
    "    annotation.append(f\"infer cytoplasm: {step_n}\")\n",
    "    cyto_step = step_n\n",
    "\n",
    "\n",
    "    # ###################\n",
    "    # # EXPORT\n",
    "    # ###################\n",
    "    # step_name.append(\"18\")\n",
    "    # function_name.append(\"export_PLACE_HOLDER\")\n",
    "    # category.append(\"export\")\n",
    "    # parameter_values.append(None)\n",
    "    # parent.append([5, 17])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_cellmask_fromaggr_stepbystep_dict2 = make_infer_cellmask_fromaggr_step_by_step_dict2()\n",
    "\n",
    "write_workflow_json(\"conf_1.2.cellmask2\", infer_cellmask_fromaggr_stepbystep_dict2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "## CYTOPLASM .json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_infer_cytoplasm_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer cyto from linearly unmixed input. (logical cellmask AND NOT nucleus)\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_nuclei_fromlabel\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(\n",
    "                                nuc_ch = NUC_CH,\n",
    "                                median_sz = 4,\n",
    "                                gauss_sig = 1.34,\n",
    "                                thresh_factor = 0.9,\n",
    "                                thresh_min = 0.1,\n",
    "                                thresh_max = 1.0,\n",
    "                                max_hole_w = 25,\n",
    "                                small_obj_w = 15)\n",
    "                                )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"get  nuclei segmentation: {step_n}\")    \n",
    "    nuc_step = step_n\n",
    "    step_n += 1                     \n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cellmask_fromaggr_MCZ\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(dict(\n",
    "                                                    median_sz = 15,\n",
    "                                            gauss_sig = 1.34,\n",
    "                                            mo_method = \"ave_tri_med\",\n",
    "                                            mo_adjust = 0.5,\n",
    "                                            mo_cutoff_size = 150,\n",
    "                                            max_hole_w = 50,\n",
    "                                            small_obj_w = 45\n",
    "                                            ))\n",
    "    parent.append([raw_input_step, nuc_step])\n",
    "    annotation.append(f\" this creates an aggregate signal for the cellmask\" )\n",
    "    cellmask_step = step_n\n",
    "\n",
    "    step_n += 1                     \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"infer_cytoplasm\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(erode_nuclei=True))\n",
    "    parent.append([nuc_step, cellmask_step])\n",
    "    annotation.append(f\"basic cellmask segmentation: {step_n}\")\n",
    "    cyto_step = step_n\n",
    "\n",
    "\n",
    "    # ###################\n",
    "    # # EXPORT\n",
    "    # ###################\n",
    "    # step_name.append(\"18\")\n",
    "    # function_name.append(\"export_PLACE_HOLDER\")\n",
    "    # category.append(\"export\")\n",
    "    # parameter_values.append(None)\n",
    "    # parent.append([5, 17])\n",
    "\n",
    "\n",
    "    ##########################\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_cytoplasm_dict = make_infer_cytoplasm_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.3.cytoplasm\", infer_cytoplasm_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## LYSOSOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import LYSO_CH\n",
    "def make_infer_lyso_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer lysosome from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = LYSO_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic lyso segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic lyso segmentation: {step_n}\")\n",
    "    img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"spot_filter_3\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( dot_scale_1 = 5,\n",
    "                                dot_cut_1 = 0.09,\n",
    "                                dot_scale_2 = 2.5,\n",
    "                                dot_cut_2 = 0.07,\n",
    "                                dot_scale_3 = 1,\n",
    "                                dot_cut_3 = 0.01))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic lyso - spot filter: {step_n}\")\n",
    "    spot_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"filament_filter\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(  filament_scale = 1.,\n",
    "                                                        filament_cut = 0.15))\n",
    "    parent.append(img_step)\n",
    "    annotation.append(f\"basic lyso - filament filter: {step_n}\")\n",
    "    fil_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"logical_or\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append([spot_step,fil_step])\n",
    "    annotation.append(f\"basic lyso - combine spot+filament: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic lyso - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_lyso_stepbystep_from_raw_dict = make_infer_lyso_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.4.lyso\", infer_lyso_stepbystep_from_raw_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## MITO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import MITO_CH \n",
    "\n",
    "def make_infer_mito_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = MITO_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic mito segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"vesselness_slice_by_slice\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( dict( sigma=1.5, cutoff=0.05))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito - vesselness filter: {step_n}\")\n",
    "    spot_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_mito_stepbystep_from_raw_dict = make_infer_mito_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.5.mito\", infer_mito_stepbystep_from_raw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## GOLGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import GOLGI_CH\n",
    "def make_infer_golgi_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = GOLGI_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic golgi segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 4, gauss_sig=1.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic golgi segmentation: {step_n}\")\n",
    "    img_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"masked_object_thresh\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(th_method= \"triangle\", \n",
    "                                                            cutoff_size=1200,\n",
    "                                                            th_adjust = 0.5) )\n",
    "    parent.append(img_step)\n",
    "    annotation.append(f\"basic golgi - mo: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"topology_preserving_thinning\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(    \n",
    "                                                min_thickness = 1.6,\n",
    "                                                thin = 1) )\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic golgi - thinning filter: {step_n}\")\n",
    "    fil_step = step_n\n",
    "    step_n += 1\n",
    "    \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"spot_filter_3\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( dot_scale_1 = 1.6,\n",
    "                                dot_cut_1 = 0.02,\n",
    "                                dot_scale_2 = 0,\n",
    "                                dot_cut_2 = 0.1,\n",
    "                                dot_scale_3 = 0,\n",
    "                                dot_cut_3 = 0.1))\n",
    "    parent.append(img_step)\n",
    "    annotation.append(f\"basic golgi - spot filter: {step_n}\")\n",
    "    spot_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"logical_or\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append([spot_step,fil_step])\n",
    "    annotation.append(f\"basic golgi - combine spot+thinned: {step_n}\")\n",
    "\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 25, \n",
    "                                  min_size = 15,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic mito - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_golgi_stepbystep_from_raw_dict = make_infer_golgi_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.6.golgi\", infer_golgi_stepbystep_from_raw_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## PEROXISOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import PEROX_CH\n",
    "\n",
    "\n",
    "def make_infer_perox_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = PEROX_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic perox segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 0, gauss_sig=3.0 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic perox segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"spot_filter_3\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict( dot_scale_1 = 1.0,\n",
    "                                dot_cut_1 = 0.01,\n",
    "                                dot_scale_2 = 0,\n",
    "                                dot_cut_2 = 0.1,\n",
    "                                dot_scale_3 = 0,\n",
    "                                dot_cut_3 = 0.1))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic perox - spot filter (1 scale): {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 0, \n",
    "                                  min_size = 2,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic perox - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_perox_stepbystep_from_raw_dict = make_infer_perox_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.7.perox\", infer_perox_stepbystep_from_raw_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## ER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import ER_CH\n",
    "def make_infer_er_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer mitochondria from linearly unmixed input from raw\n",
    "\n",
    "    \"\"\"\n",
    "   \n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_n = 1\n",
    "    raw_input_step = 0\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = ER_CH) )\n",
    "    parent.append(raw_input_step)\n",
    "    annotation.append(f\"basic ER segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 0, gauss_sig=3.0 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic ER segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"filament_filter\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(  filament_scale = 1.,\n",
    "                                                        filament_cut = 0.015))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic ER - filament filter: {step_n}\")\n",
    "    fil_step = step_n\n",
    "    step_n += 1\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 0, \n",
    "                                  min_size = 2,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic ER - fill/filter: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    \n",
    "    return out_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_er_stepbystep_from_raw_dict = make_infer_er_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.8.ER\", infer_er_stepbystep_from_raw_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## LD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc_2d.constants import LD_CH\n",
    "\n",
    "def make_infer_LD_step_by_step_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer lipid from linearly unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: np.ndarray\n",
    "        a 3d image containing all the channels\n",
    "\n",
    "    soma_mask: np.ndarray\n",
    "        mask\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    LD_object\n",
    "        mask defined extent of NU\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "    annotation = []\n",
    "    step_n = 1\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    raw_input_step = 0\n",
    "\n",
    "\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = LD_CH) )\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"scale_and_smooth\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(median_sz = 0, gauss_sig=2.4 ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"apply_threshold\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(method = \"otsu\",\n",
    "                                                        thresh_factor = 0.8, \n",
    "                                                            thresh_min = .5,\n",
    "                                                            thresh_max = 1.))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    step_name.append(f\"{step_n}\")\n",
    "    function_name.append(\"fill_and_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, \n",
    "                                 hole_max= 2.5, \n",
    "                                  min_size = 4,\n",
    "                                 method=\"slice_by_slice\" ))\n",
    "    parent.append(step_n-1)\n",
    "    annotation.append(f\"basic LD segmentation: {step_n}\")\n",
    "    step_n += 1\n",
    "\n",
    "    \n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i],\n",
    "                            annotation=annotation[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "infer_LD_stepbystep_from_raw_dict = make_infer_LD_step_by_step_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.9.LD\", infer_LD_stepbystep_from_raw_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napariNEW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
