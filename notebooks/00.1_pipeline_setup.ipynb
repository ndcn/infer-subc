{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Pipeline Setup\n",
    "\n",
    "SCohenLab 2D Image Processing notebook 00\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OVERVIEW\n",
    "\n",
    "The first thing we need to be able to do is access the data files and interact wiht them.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# IMPORTS\n",
    "\n",
    "The convention with notebooks (and python in general) is to import the nescessary packages as the first thing.\n",
    "\n",
    "We are using `napari` for visualization, and `scipy` `ndimage` and `skimage` for analyzing the image files.  The underlying data format are `numpy` `ndarrays` and tools from  Allen Institute for Cell Science.\n",
    "\n",
    "## NOTES:\n",
    "There are a few convences used here worth explanation.  Note the `imports.py` and `constants.py` files in the base level of the `infer_subc_2d` module.  These provide sortcuts for keeping track of imports and constants.   cf. the bottom of the imports below.  A second thing to note is the use of the \"magics\" ([[ link to magics info %%]]) `%load_ext autoreload` `%autoreload 2`, which tells the notebook to reload any changes made in the source code of the module on change; hence, avoid re-executing the imports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "from typing import Union, List, Tuple, Any\n",
    "# TODO:  prune the imports.. this is the big set for almost all organelles\n",
    "# # function for core algorithm\n",
    "from scipy import ndimage as ndi\n",
    "import aicssegmentation\n",
    "from aicssegmentation.core.pre_processing_utils import ( intensity_normalization, \n",
    "                                                         image_smoothing_gaussian_slice_by_slice )\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc_2d\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc_2d.utils.file_io import (read_czi_image,\n",
    "                                                                    list_image_files)\n",
    "from infer_subc_2d.utils.img import *\n",
    "from infer_subc_2d.organelles import fixed_get_optimal_Z_image, get_optimal_Z_image\n",
    "from infer_subc_2d.constants import (TEST_IMG_N,\n",
    "                                                                    NUC_CH ,\n",
    "                                                                    LYSO_CH ,\n",
    "                                                                    MITO_CH ,\n",
    "                                                                    GOLGI_CH ,\n",
    "                                                                    PEROXI_CH ,\n",
    "                                                                    ER_CH ,\n",
    "                                                                    LIPID_CH ,\n",
    "                                                                    RESIDUAL_CH , \n",
    "                                                                    ALL_CHANNELS)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "test_img_n = TEST_IMG_N"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Get and load Image for processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read the data into memeory from the `.czi` files.  (Note: there is also the 2D slice .tif file read for later comparision).  WE will also collect metatdata.\n",
    "\n",
    "> the `data_path` variable should have the full path to the set of images wrapped in a `Path()`.   Below the path is built in 3 stages\n",
    "> 1. my user directory \"~\" plus\n",
    "> 2. general imaging data directory \"Projects/Imaging/data\" plus\n",
    "> 3. \"raw\" where the linearly unmixed zstacks are\n",
    "\n",
    "The image \"type\" is also set by `im_type = \".czi\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ahenrie/Projects/Imaging/data/raw/ZSTACK_PBTOhNGN2hiPSCs_BR3_N04_Unmixed.czi'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# depricate this\n",
    "# list_img_files = lambda img_folder,f_type: [os.path.join(img_folder,f_name) for f_name in os.listdir(img_folder) if f_name.endswith(f_type)]\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "\n",
    "test_img_name = img_file_list[test_img_n]\n",
    "test_img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:105: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "## SUMMARY\n",
    "\n",
    "The above shows the general procedure importing the relavent modules, setting up the file I/O and finally reading in the `img_data` multi channel 3D flourescence image.\n",
    "\n",
    "## NEXT:  CHOOZE Z-SLICE\n",
    "\n",
    "proceed to [00.2_extract_optimal_Z.ipynb](./00.2_extract_optimal_Z.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
