{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUTATIVE WORKFLOW\n",
    "\n",
    "\n",
    "## WORKFLOW EDITOR PLUGIN\n",
    "- FINE-TUNE SEGMENTATIONS\n",
    "  - export workflow.jsons\n",
    "    - masks:\n",
    "      - nuclei\n",
    "      - cellmask\n",
    "      - cytoplasm\n",
    "    - organelles:\n",
    "      - lyso\n",
    "      - mito\n",
    "      - golgi\n",
    "      - perox\n",
    "      - ER\n",
    "      - LD\n",
    "\n",
    "\n",
    "## BATCHPROCESS WORKFLOW\n",
    "- BATCH PROCESS\n",
    "  - load workflow.jsons for: \n",
    "  1. masks\n",
    "    - export: masks .tiff as stack (nuclei, cellmask, cytoplasm)\n",
    "  2. organelles\n",
    "    - export individual .tiffs\n",
    "\n",
    "\n",
    "\n",
    "## NOTEBOOK ~~OR ***FUTURE*** PLUGIN~~\n",
    "- COLLECT ORGANELLE STATS\n",
    "  - extract masks.tiffs as individual\n",
    "    - nuclei, cellmask, cytoplasm\n",
    "  - collect regionprops for all organelles\n",
    "    - export .csvs\n",
    "\n",
    "\n",
    "## NOTEBOOK ~~OR __FUTURE__ PLUGIN~~\n",
    "- SUMMARIZE STUDY DATA\n",
    "  - munge .csv to create summary stats across all cells/images\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________\n",
    "\n",
    "## TO DO\n",
    "- add \"segmentation name\" field instead of copying from workflow.json name\n",
    "\n",
    "\n",
    "- choose alternate conf_XXX.json location. \n",
    "  - strategy:  add to \"prebuilt\" list from path\n",
    "\n",
    "\n",
    "  \n",
    "  ## FILE NAME CONVENTIONS\n",
    "\n",
    "  raw file name is kept.\n",
    "\n",
    "  PREFIX = \"segmentation name\" or regionprop name.  e.g. \n",
    "  SUFFIX = \"description\" i.e. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### These is the same import code that all of the other notebooks have\n",
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from typing import Optional, Union, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image,\n",
    "                                        export_inferred_organelle,\n",
    "                                        import_inferred_organelle,\n",
    "                                        export_tiff,\n",
    "                                        list_image_files)\n",
    "\n",
    "\n",
    "\n",
    "from infer_subc.constants import *\n",
    "from infer_subc.utils.stats import *\n",
    "from infer_subc.utils.stats_helpers import *\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be the example image for testing the pipeline below\n",
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(\"C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis\")\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "int_data_path = data_root_path / \"test_files\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files\n",
    "img_file_list = list_image_files(int_data_path,im_type)\n",
    "\n",
    "# save output \".tiff\" files here\n",
    "out_data_path = data_root_path / \"20230606_out\"\n",
    "\n",
    "if not Path.exists(out_data_path):\n",
    "    Path.mkdir(out_data_path)\n",
    "    print(f\"making {out_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:',\n",
       " 'Users',\n",
       " 'redre',\n",
       " 'Documents',\n",
       " 'CohenLab',\n",
       " 'MSI-3D-analysis',\n",
       " '20230606_test_files_practice_analysis',\n",
       " 'test_files']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(int_data_path).split(\"\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_2_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_10_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a24hrs-Ctrl_14_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_01_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_02_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl + oleic acid_07_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_10_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_7_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_8_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "a48hrs-Ctrl_9_Unmixing\n",
      "summary-cross\n",
      "summary-proj\n",
      "summary-stats\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'24hrs-Ctrl +oleicAcid 50uM_2_Unmixing'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### I made a function to make this all cleaner\n",
    "v = list_image_files(out_data_path,\"csv\")\n",
    "for i in range(len(v)):\n",
    "    print((v[i]).stem.split(\"-\")[0] + \"-\" + (v[i]).stem.split(\"-\")[1])\n",
    "stoom = (v[0]).stem.split(\"-\")[0] + \"-\" + (v[1]).stem.split(\"-\")[1]\n",
    "stoom\n",
    "def correction(name : Path):\n",
    "    return (name).stem.split(\"-\")[0] + \"-\" + (name).stem.split(\"-\")[1]\n",
    "correction(v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing.czi')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I guess they are using this as an example image, I changed it to the one I used in the previous documents\n",
    "im_path = Path(img_file_list[1])\n",
    "im_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. get each unique cells accouding to filename\n",
    "\n",
    "\n",
    "### extract ID. e.g.\n",
    "\n",
    "### process each cell & summarize\n",
    "\n",
    "\n",
    "\n",
    "## 2. aggregate all cells into a database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing\n",
      "24hrs-Ctrl +oleicAcid 50uM_3_Unmixing.czi\n",
      "C:\n",
      "C:\\\n"
     ]
    }
   ],
   "source": [
    "# I just wanted to mess with path\n",
    "print(im_path.stem)\n",
    "print(im_path.name)\n",
    "print(im_path.drive)\n",
    "print(im_path.anchor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name method for paths takes in the file name without the path\n",
    "# cell_ids is the first part of the stem before the dash and with the new data included, there are three\n",
    "full_name = im_path.name\n",
    "\n",
    "cell_ids = [ Path(fn).stem.split(\"-\")[0] for fn in img_file_list]\n",
    "cell_ids = list(set(cell_ids))\n",
    "\n",
    "masks_postfix = \"masks2\"\n",
    "organelle_postfix = [\"lyso\", \"mito\",\"golgi\",\"perox\",\"ER\",\"LD\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a24hrs', '24hrs', 'a48hrs']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASK process\n",
    "# 1. get a listof all files based on a \"prefix\" and \"suffix\" for a given path\n",
    "# dump three .tiff from the mask multichannel tiff\n",
    "# from tifffile import imwrite, imread#, tiffcomment\n",
    "from infer_subc.core.img import label_uint16\n",
    "from infer_subc.core.file_io import export_tiff, read_tiff_image\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "def _explode_mask(mask_path: Union[Path,str], postfix: str= \"masks\", im_type: str = \".tiff\") -> bool:\n",
    "    \"\"\" \n",
    "    TODO: add loggin instead of printing\n",
    "        append tiffcomments with provenance\n",
    "    \"\"\"\n",
    "    if isinstance(mask_path, str): mask_path = Path(mask_path)\n",
    "    # load image \n",
    "    full_stem = mask_path.stem\n",
    "    if full_stem.endswith(postfix):\n",
    "        stem = full_stem.rstrip(postfix)\n",
    "        image = read_tiff_image(mask_path)\n",
    "        assert image.shape[0]==3\n",
    "        \n",
    "        # make into np.uint16 labels\n",
    "        nuclei = label_uint16(image[0])\n",
    "        # export as np.uint8 (255)\n",
    "        cellmask = image[1]>0            \n",
    "        cytoplasm = image[2]>0\n",
    "\n",
    "        # write wasks\n",
    "        root_stem = mask_path.parent / stem\n",
    "        # ret1 = imwrite(f\"{root}nuclei{stem}\", nuclei)\n",
    "        ret1 = export_tiff(nuclei, f\"{stem}nuc\", mask_path.parent, None)\n",
    "        # ret2 = imwrite(f\"{root}cellmask{stem}\", cellmask)\n",
    "        ret2 = export_tiff(cellmask, f\"{stem}cell\", mask_path.parent, None)\n",
    "        # ret3 = imwrite(f\"{root}cytosol{stem}\", cytosol)\n",
    "        ret3 = export_tiff(cytoplasm, f\"{stem}cyto\", mask_path.parent, None)\n",
    "\n",
    "        print(f\"wrote {stem}-{{nuc,cell,cyto}}\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def _explode_masks(root_path: Union[Path,str], postfix: str= \"masks\", im_type: str = \".tiff\"):\n",
    "    \"\"\"  \n",
    "    TODO: add loggin instead of printing\n",
    "        append tiffcomments with provenance\n",
    "    \"\"\"\n",
    "    if isinstance(root_path, str): root_path = Path(root_path)\n",
    "    img_file_list = list_image_files(root_path,im_type, postfix)\n",
    "    wrote_cnt = 0\n",
    "    for img_f in img_file_list:\n",
    "        if _explode_mask(img_f, postfix=postfix, im_type=im_type): wrote_cnt += 1\n",
    "        else: print(f\"failed to explode {img_f}\")\n",
    "    else:\n",
    "        print(f\"how thefark!!! {img_f}\")\n",
    "\n",
    "    print(f\"exploded {wrote_cnt*100./len(img_file_list)} pct of {len(img_file_list)} files\")\n",
    "    return wrote_cnt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploded 100.0 pct of 13 files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from infer_subc.utils.batch import explode_masks\n",
    "\n",
    "### The explode masks function takes in the masks from the batch files and extracts the nuclei, cellmask and cytoplasm masks\n",
    "\n",
    "cnt = explode_masks(out_data_path, postfix='masks')\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(\"C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis\")\n",
    "# linearly unmixed \".czi\" files are here\n",
    "raw_data_path = data_root_path / \"test_files\"\n",
    "# save output \".tiff\" files here\n",
    "int_data_path = data_root_path / \"20230606_out\"\n",
    "# save stats here\n",
    "out_data_path = data_root_path / \"20230606_out\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = raw_data_path\n",
    "int_path = int_data_path\n",
    "out_path = out_data_path\n",
    "\n",
    "\n",
    "if isinstance(raw_path, str): raw_path = Path(raw_path)\n",
    "if isinstance(int_path, str): int_path = Path(int_path)\n",
    "if isinstance(out_path, str): out_path = Path(out_path)\n",
    "\n",
    "img_file_list = list_image_files(raw_path,\".czi\")\n",
    "\n",
    "if not Path.exists(out_path):\n",
    "    Path.mkdir(out_path)\n",
    "    print(f\"making {out_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/24hrs-Ctrl +oleicAcid 50uM_2_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a24hrs-Ctrl +oleicAcid 50uM_10_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a24hrs-Ctrl +oleicAcid 50uM_4_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a24hrs-Ctrl_10_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a24hrs-Ctrl_14_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a48hrs-Ctrl + oleic acid_01_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a48hrs-Ctrl + oleic acid_02_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a48hrs-Ctrl + oleic acid_07_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a48hrs-Ctrl_10_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a48hrs-Ctrl_7_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a48hrs-Ctrl_8_Unmixing.czi'),\n",
       " WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/a48hrs-Ctrl_9_Unmixing.czi')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Dict, List\n",
    "\n",
    "def _find_segmentation_tiff_files(prototype:Union[Path,str], organelles: List[str], int_path: Union[Path,str]) -> Dict:\n",
    "    \"\"\"\n",
    "    find the nescessary image files based on prototype, the organelles involved, and paths\n",
    "    \"\"\"\n",
    "\n",
    "    # raw\n",
    "    prototype = Path(prototype)\n",
    "    if not prototype.exists():\n",
    "        print(f\"bad prototype. please choose an existing `test_files` file as prototype\")\n",
    "        return dict()\n",
    "    # make sure protoype ends with czi\n",
    "\n",
    "    out_files = {\"test_files\":prototype}\n",
    "\n",
    "    int_path = Path(int_path) \n",
    "    # raw\n",
    "    if not int_path.is_dir():\n",
    "        print(f\"bad path argument. please choose an existing path containing organelle segmentations\")\n",
    "        return out_files\n",
    "    \n",
    "    # cyto, cellmask\n",
    "    cyto_nm = int_path / f\"{prototype.stem}-cyto.tiff\"\n",
    "    if cyto_nm.exists():\n",
    "        out_files[\"cyto\"] = cyto_nm\n",
    "    else:\n",
    "        print(f\"cytosol mask not found.  We'll try to extract from masks \")\n",
    "        if explode_mask(int_path / f\"{prototype.stem}-masks.tiff\"): \n",
    "            out_files[\"cyto\"] = cyto_nm\n",
    "        else: \n",
    "            print(f\"failed to explode {prototype.stem}-masks.tiff\")\n",
    "            return out_files\n",
    "    \n",
    "    cellmask_nm = int_path / f\"{prototype.stem}-cellmask.tiff\"\n",
    "    if  cellmask_nm.exists():\n",
    "        out_files[\"cellmask\"] = cellmask_nm\n",
    "    else:\n",
    "        print(f\"cellmask file not found in {int_path} returning\")\n",
    "        out_files[\"cellmask\"] = None\n",
    "\n",
    "    # organelles\n",
    "    for org_n in organelles:\n",
    "        org_name = Path(int_path) / f\"{prototype.stem}-{org_n}.tiff\"\n",
    "        if org_name.exists(): \n",
    "            out_files[org_n] = org_name\n",
    "        else: \n",
    "            print(f\"{org_n} .tiff file not found in {int_path} returning\")\n",
    "            out_files[org_n] = None\n",
    "    \n",
    "    return out_files\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function finds your czi image as well as all of the tiff files\n",
    "def find_segmentation_tiff_files(prototype:Union[Path,str], organelles: List[str], int_path: Union[Path,str]) -> Dict:\n",
    "    \"\"\"\n",
    "    find the nescessary image files based on protype, the organelles involved, and paths\n",
    "    \"\"\"\n",
    "\n",
    "    # raw\n",
    "    prototype = Path(prototype)\n",
    "    if not prototype.exists():\n",
    "        print(f\"bad prototype. please choose an existing `raw` file as prototype\")\n",
    "        return dict()\n",
    "    # make sure protoype ends with czi\n",
    "\n",
    "    out_files = {\"raw\":prototype}\n",
    "\n",
    "    int_path = Path(int_path) \n",
    "    # raw\n",
    "    if not int_path.is_dir():\n",
    "        print(f\"bad path argument. please choose an existing path containing organelle segmentations\")\n",
    "        return out_files\n",
    "    \n",
    "    # cyto, cellmask\n",
    "    cyto_nm = int_path / f\"{prototype.stem}-20230606_testnrm_cyto.tiff\"\n",
    "    if cyto_nm.exists():\n",
    "        out_files[\"cyto\"] = cyto_nm\n",
    "    else:\n",
    "        print(f\"cytosol mask not found.  We'll try to extract from masks \")\n",
    "        if explode_mask(int_path / f\"{prototype.stem}-20230606_testnrm_masks.tiff\"): \n",
    "            out_files[\"cyto\"] = cyto_nm\n",
    "        else: \n",
    "            print(f\"failed to explode {prototype.stem}-20230606_testnrm_masks.tiff\")\n",
    "            return out_files\n",
    "    \n",
    "    cellmask_nm = int_path / f\"{prototype.stem}-20230606_testnrm_cell.tiff\"\n",
    "    if  cellmask_nm.exists():\n",
    "        out_files[\"cell\"] = cellmask_nm\n",
    "    else:\n",
    "        print(f\"cellmask file not found in {int_path} returning\")\n",
    "        out_files[\"cell\"] = None\n",
    "\n",
    "    # organelles\n",
    "    for org_n in organelles:\n",
    "        org_name = Path(int_path) / f\"{prototype.stem}-20230606_testnrm_{org_n}.tiff\"\n",
    "        if org_name.exists(): \n",
    "            out_files[org_n] = org_name\n",
    "        else: \n",
    "            print(f\"{org_n} .tiff file not found in {int_path} returning\")\n",
    "            out_files[org_n] = None\n",
    "    \n",
    "    if \"nuc\" not in organelles:\n",
    "        nuc_nm = int_path / f\"{prototype.stem}-20230606_testnrm_nuc.tiff\"\n",
    "        if  nuc_nm.exists():\n",
    "            out_files[\"nuc\"] = nuc_nm\n",
    "        else:\n",
    "            print(f\"nuc file not found in {int_path} returning\")\n",
    "            out_files[\"nuc\"] = None\n",
    "\n",
    "\n",
    "\n",
    "    return out_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from infer_subc.utils.batch import find_segmentation_tiff_files\n",
    "from infer_subc.utils.batch import explode_mask\n",
    "prototype = 'C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing.czi'\n",
    "\n",
    "organelles = [\"nuc\",\"lyso\", \"mito\",\"golgi\",\"perox\",\"ER\",\"LD\"]\n",
    "\n",
    "filez = find_segmentation_tiff_files(prototype, organelles, out_data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing.czi'),\n",
       " 'cyto': WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/20230606_out/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing-20230606_testnrm_cyto.tiff'),\n",
       " 'cell': WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/20230606_out/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing-20230606_testnrm_cell.tiff'),\n",
       " 'nuc': WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/20230606_out/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing-20230606_testnrm_nuc.tiff'),\n",
       " 'lyso': WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/20230606_out/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing-20230606_testnrm_lyso.tiff'),\n",
       " 'mito': WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/20230606_out/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing-20230606_testnrm_mito.tiff'),\n",
       " 'golgi': WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/20230606_out/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing-20230606_testnrm_golgi.tiff'),\n",
       " 'perox': WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/20230606_out/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing-20230606_testnrm_perox.tiff'),\n",
       " 'ER': WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/20230606_out/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing-20230606_testnrm_ER.tiff'),\n",
       " 'LD': WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/20230606_out/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing-20230606_testnrm_LD.tiff')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redre\\anaconda3\\envs\\infer-subc-ngudi\\lib\\site-packages\\ome_types\\_convenience.py:112: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "scale = read_czi_image(\"C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/test_files/24hrs-Ctrl +oleicAcid 50uM_3_Unmixing.czi\")[1][\"scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'LD_nrm' at 0x2b8c70cc790>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cyto_nrm = read_tiff_image(filez['cyto'])\n",
    "nuc_nrm = read_tiff_image(filez['nuc'])\n",
    "lyso_nrm = read_tiff_image(filez['lyso'])\n",
    "mito_nrm = read_tiff_image(filez['mito'])\n",
    "golgi_nrm = read_tiff_image(filez['golgi'])\n",
    "perox_nrm = read_tiff_image(filez['perox'])\n",
    "ER_nrm = read_tiff_image(filez['ER'])\n",
    "LD_nrm = read_tiff_image(filez['LD'])\n",
    "\n",
    "viewer.add_image((cyto_nrm), scale=scale, blending=\"additive\")\n",
    "viewer.add_image((nuc_nrm), scale=scale, blending=\"additive\")\n",
    "viewer.add_image((lyso_nrm), scale=scale, blending=\"additive\")\n",
    "viewer.add_image((mito_nrm), scale=scale, blending=\"additive\")\n",
    "viewer.add_image((golgi_nrm), scale=scale, blending=\"additive\")\n",
    "viewer.add_image((perox_nrm), scale=scale, blending=\"additive\")\n",
    "viewer.add_image((ER_nrm), scale=scale, blending=\"additive\")\n",
    "viewer.add_image((LD_nrm), scale=scale, blending=\"additive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.stats_helpers import make_organelle_stat_tables, dump_all_stats_tables\n",
    "from infer_subc.constants import *\n",
    "from infer_subc.organelles import *\n",
    "from infer_subc.core.file_io import read_tiff_image, read_czi_image\n",
    "\n",
    "# names of organelles we have\n",
    "organelle_names = [\"nuc\",\"lyso\", \"mito\",\"golgi\",\"perox\",\"ER\",\"LD\"]\n",
    "\n",
    "# get the intensities\n",
    "organelle_channels = [NUC_CH, LYSO_CH,MITO_CH,GOLGI_CH,PEROX_CH,ER_CH,LD_CH]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# makes the stats tables if the paths exist\n",
    "# for a list of \"prefixes\"  collect stats + cross stats masked by cytosol (including nuclei masked by cellmask)\n",
    "\n",
    "def _dump_all_stats_tables(int_path: Union[Path,str], \n",
    "                   out_path: Union[Path, str], \n",
    "                   raw_path: Union[Path,str], \n",
    "                   organelle_names: List[str]= [\"nuclei\",\"golgi\",\"peroxi\"], \n",
    "                   organelle_chs: List[int]= [NUC_CH,GOLGI_CH, PEROX_CH], \n",
    "                    ) -> int :\n",
    "    \"\"\"  \n",
    "    TODO: add loggin instead of printing\n",
    "        append tiffcomments with provenance\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if isinstance(raw_path, str): raw_path = Path(raw_path)\n",
    "    if isinstance(int_path, str): int_path = Path(int_path)\n",
    "    if isinstance(out_path, str): out_path = Path(out_path)\n",
    "    \n",
    "    img_file_list = list_image_files(raw_path,\".czi\")\n",
    "\n",
    "    if not Path.exists(out_path):\n",
    "        Path.mkdir(out_path)\n",
    "        print(f\"making {out_path}\")\n",
    "        \n",
    "    for img_f in img_file_list:\n",
    "        filez = find_segmentation_tiff_files(img_f, organelle_names, int_path)\n",
    "        img_data,meta_dict = read_czi_image(filez[\"raw\"])\n",
    "\n",
    "        # load organelles and masks\n",
    "        cyto_mask = read_tiff_image(filez[\"cyto\"])\n",
    "        cellmask_obj = read_tiff_image(filez[\"cell\"])\n",
    "\n",
    "\n",
    "\n",
    "        # create intensities from raw as list\n",
    "        intensities = [img_data[ch] for ch in organelle_chs]\n",
    "\n",
    "        # load organelles as list\n",
    "        organelles = [read_tiff_image(filez[org]) for org in organelle_names]\n",
    "        \n",
    "        #get mask (cyto_mask)\n",
    "        nuclei_obj = organelles[ organelle_names.index(\"nuc\") ]\n",
    "\n",
    "        n_files = make_organelle_stat_tables(organelle_names, \n",
    "                                      organelles,\n",
    "                                      intensities, \n",
    "                                      nuclei_obj,\n",
    "                                      cellmask_obj,\n",
    "                                      cyto_mask, \n",
    "                                      out_data_path, \n",
    "                                      img_f,\n",
    "                                      n_rad_bins=5,\n",
    "                                      n_zernike=9)\n",
    "\n",
    "    return n_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redre\\anaconda3\\envs\\infer-subc-ngudi\\lib\\site-packages\\ome_types\\_convenience.py:112: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m bb \u001b[39m=\u001b[39m read_czi_image(data_root_path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_files/24hrs-Ctrl +oleicAcid 50uM_2_Unmixing.czi\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m aa \u001b[39m=\u001b[39m read_tiff_image(data_root_path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m20230606_out/24hrs-Ctrl +oleicAcid 50uM_2_Unmixing-20230606_testnrm_lyso.tiff\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m cc \n\u001b[0;32m      4\u001b[0m get_summary_stats_3D \u001b[39m=\u001b[39m ()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cc' is not defined"
     ]
    }
   ],
   "source": [
    "bb = read_czi_image(data_root_path / \"test_files/24hrs-Ctrl +oleicAcid 50uM_2_Unmixing.czi\")\n",
    "aa = read_tiff_image(data_root_path / \"20230606_out/24hrs-Ctrl +oleicAcid 50uM_2_Unmixing-20230606_testnrm_lyso.tiff\")\n",
    "cc \n",
    "get_summary_stats_3D = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int_path is the path where the tiff files live, out_path is where the stats will live\n",
    "# raw_path is where the czi files are\n",
    "def dump_all_stats_tables(int_path: Union[Path,str], \n",
    "                   out_path: Union[Path, str], \n",
    "                   raw_path: Union[Path,str], \n",
    "                   organelle_names: List[str]= [\"nuclei\",\"golgi\",\"peroxi\"], \n",
    "                   organelle_chs: List[int]= [NUC_CH,GOLGI_CH, PEROX_CH], \n",
    "                    ) -> int :\n",
    "    \"\"\"  \n",
    "    TODO: add loggin instead of printing\n",
    "        append tiffcomments with provenance\n",
    "    \"\"\"\n",
    "\n",
    "    # If the paths are strings then they are converted to paths\n",
    "    if isinstance(raw_path, str): raw_path = Path(raw_path)\n",
    "    if isinstance(int_path, str): int_path = Path(int_path)\n",
    "    if isinstance(out_path, str): out_path = Path(out_path)\n",
    "    \n",
    "    # The file list is obtained\n",
    "    img_file_list = list_image_files(raw_path,\".czi\")\n",
    "    \n",
    "    # If the out folder that was stated does not exist, it creates it for you\n",
    "    if not Path.exists(out_path):\n",
    "        Path.mkdir(out_path)\n",
    "        print(f\"making {out_path}\")\n",
    "    \n",
    "    # For each file in img_file_list the tiff files are located and the original czi image (with the key \"test_files\") is used to define the\n",
    "    ## image data and meta dictionary\n",
    "    ## The cytoplasm mask and cellmask are retrieved\n",
    "    for img_f in img_file_list:\n",
    "        filez = find_segmentation_tiff_files(img_f, organelle_names, int_path)\n",
    "        img_data,meta_dict = read_czi_image(filez[\"raw\"])\n",
    "\n",
    "        # load organelles and masks\n",
    "        cyto_mask = read_tiff_image(filez[\"cyto\"])\n",
    "        cellmask_obj = read_tiff_image(filez[\"cell\"])\n",
    "\n",
    "\n",
    "\n",
    "        # create intensities from raw as list\n",
    "        intensities = [img_data[ch] for ch in organelle_chs]\n",
    "\n",
    "        # load organelles as list\n",
    "        organelles = [read_tiff_image(filez[org]) for org in organelle_names]\n",
    "        \n",
    "        #get mask (cyto_mask)\n",
    "        nuclei_obj = organelles[ organelle_names.index(\"nuc\") ]\n",
    "\n",
    "        n_files = make_organelle_stat_tables(organelle_names, \n",
    "                                      organelles,\n",
    "                                      intensities, \n",
    "                                      nuclei_obj,\n",
    "                                      cellmask_obj,\n",
    "                                      cyto_mask, \n",
    "                                      out_path, \n",
    "                                      img_f,\n",
    "                                      n_rad_bins=5,\n",
    "                                      n_zernike=9)\n",
    "\n",
    "    return n_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redre\\anaconda3\\envs\\infer-subc-ngudi\\lib\\site-packages\\ome_types\\_convenience.py:112: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n",
      "C:\\Users\\redre\\Documents\\CohenLab\\MSI-3D-analysis\\infer-subc\\infer_subc\\utils\\stats.py:667: RuntimeWarning: invalid value encountered in divide\n",
      "  magnitude = np.sqrt(vr * vr + vi * vi) / pixels.sum()\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\redre\\\\Documents\\\\CohenLab\\\\MSI-3D-analysis\\\\20230606_test_files_practice_analysis\\\\20230606_out\\\\24hrs-Ctrl +oleicAcid 50uM_2_Unmixing-lyso-stats.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39m# save stats here\u001b[39;00m\n\u001b[0;32m      8\u001b[0m out_data_path \u001b[39m=\u001b[39m data_root_path \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m20230606_out\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m n_files \u001b[39m=\u001b[39m dump_all_stats_tables(out_data_path, \n\u001b[0;32m     11\u001b[0m                      out_data_path, \n\u001b[0;32m     12\u001b[0m                      raw_data_path, \n\u001b[0;32m     13\u001b[0m                      organelle_names\u001b[39m=\u001b[39;49morganelle_names, \n\u001b[0;32m     14\u001b[0m                      organelle_chs\u001b[39m=\u001b[39;49morganelle_channels)\n\u001b[0;32m     16\u001b[0m n_files\n",
      "Cell \u001b[1;32mIn[36], line 49\u001b[0m, in \u001b[0;36mdump_all_stats_tables\u001b[1;34m(int_path, out_path, raw_path, organelle_names, organelle_chs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[39m#get mask (cyto_mask)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     nuclei_obj \u001b[39m=\u001b[39m organelles[ organelle_names\u001b[39m.\u001b[39mindex(\u001b[39m\"\u001b[39m\u001b[39mnuc\u001b[39m\u001b[39m\"\u001b[39m) ]\n\u001b[1;32m---> 49\u001b[0m     n_files \u001b[39m=\u001b[39m make_organelle_stat_tables(organelle_names, \n\u001b[0;32m     50\u001b[0m                                   organelles,\n\u001b[0;32m     51\u001b[0m                                   intensities, \n\u001b[0;32m     52\u001b[0m                                   nuclei_obj,\n\u001b[0;32m     53\u001b[0m                                   cellmask_obj,\n\u001b[0;32m     54\u001b[0m                                   cyto_mask, \n\u001b[0;32m     55\u001b[0m                                   out_path, \n\u001b[0;32m     56\u001b[0m                                   img_f,\n\u001b[0;32m     57\u001b[0m                                   n_rad_bins\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[0;32m     58\u001b[0m                                   n_zernike\u001b[39m=\u001b[39;49m\u001b[39m9\u001b[39;49m)\n\u001b[0;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m n_files\n",
      "File \u001b[1;32m~\\Documents\\CohenLab\\MSI-3D-analysis\\infer-subc\\infer_subc\\utils\\stats_helpers.py:137\u001b[0m, in \u001b[0;36mmake_organelle_stat_tables\u001b[1;34m(organelle_names, organelles, intensities, nuclei_obj, cellmask_obj, organelle_mask, out_data_path, source_file, n_rad_bins, n_zernike)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39m# write out files... \u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[39m# org_stats_tabs.append(A_stats_tab)\u001b[39;00m\n\u001b[0;32m    136\u001b[0m csv_path \u001b[39m=\u001b[39m out_data_path \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msource_file\u001b[39m.\u001b[39mstem\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m-stats.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 137\u001b[0m a_stats_tab\u001b[39m.\u001b[39;49mto_csv(csv_path)\n\u001b[0;32m    139\u001b[0m csv_path \u001b[39m=\u001b[39m out_data_path \u001b[39m/\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00msource_file\u001b[39m.\u001b[39mstem\u001b[39m}\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m-cross-stats.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    140\u001b[0m crossed_tab\u001b[39m.\u001b[39mto_csv(csv_path)\n",
      "File \u001b[1;32mc:\\Users\\redre\\anaconda3\\envs\\infer-subc-ngudi\\lib\\site-packages\\pandas\\core\\generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3770\u001b[0m )\n\u001b[1;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3773\u001b[0m     path_or_buf,\n\u001b[0;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3789\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\redre\\anaconda3\\envs\\infer-subc-ngudi\\lib\\site-packages\\pandas\\io\\formats\\format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1185\u001b[0m )\n\u001b[1;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\redre\\anaconda3\\envs\\infer-subc-ngudi\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:240\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    241\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    243\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    244\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    245\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    246\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    257\u001b[0m     )\n\u001b[0;32m    259\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\redre\\anaconda3\\envs\\infer-subc-ngudi\\lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\redre\\\\Documents\\\\CohenLab\\\\MSI-3D-analysis\\\\20230606_test_files_practice_analysis\\\\20230606_out\\\\24hrs-Ctrl +oleicAcid 50uM_2_Unmixing-lyso-stats.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(\"C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis\")\n",
    "# linearly unmixed \".czi\" files are here\n",
    "raw_data_path = data_root_path / \"test_files\"\n",
    "# save output \".tiff\" files here\n",
    "int_data_path = data_root_path / \"20230606_out\"\n",
    "# save stats here\n",
    "out_data_path = data_root_path / \"20230606_out\"\n",
    "\n",
    "n_files = dump_all_stats_tables(out_data_path, \n",
    "                     out_data_path, \n",
    "                     raw_data_path, \n",
    "                     organelle_names=organelle_names, \n",
    "                     organelle_chs=organelle_channels)\n",
    "\n",
    "n_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# summary statistics\n",
    "\n",
    "We now need to merge our files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----------------\n",
    "##  SUMMARY STATS  \n",
    "> WARNING: (🚨🚨🚨🚨 WIP)\n",
    "### normalizations.\n",
    "\n",
    "- overlaps, normalized by CYTOPLASM, A, and B\n",
    "- per cell averages, medians, std, and totals\n",
    "\n",
    "These is all pandas munging and very straightforward tabular manipulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Now we are going to combine those tables\n",
    "\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "int_data_path = data_root_path / \"out\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a list of \"prefixes\"  collect stats + cross stats masked by cytosol (including nuclei masked by cellmask)\n",
    "\n",
    "def _summarize_organelle_stats(int_path: Union[Path,str], \n",
    "                              organelle_names: List[str]= [\"nuclei\",\"golgi\",\"peroxi\"]):\n",
    "    \"\"\"  \n",
    "    \"\"\"\n",
    "    # write out files... \n",
    "\n",
    "    if isinstance(int_path, str): int_path = Path(int_path)\n",
    "\n",
    "    if not Path.exists(out_path):\n",
    "        Path.mkdir(out_path)\n",
    "        print(f\"making {out_path}\")\n",
    "\n",
    "    all_stats_df = pd.DataFrame()\n",
    "    all_cross_stats_df = pd.DataFrame()\n",
    "    all_proj_stats_df = pd.DataFrame()\n",
    "    \n",
    "    for target in organelle_names:\n",
    "        stat_file_list = sorted( int_path.glob(f\"*{target}-stats.csv\") )\n",
    "\n",
    "        stats_df = pd.DataFrame()\n",
    "        cross_stats_df = pd.DataFrame()\n",
    "        proj_stats_df = pd.DataFrame()\n",
    "\n",
    "        for stats_f in stat_file_list:\n",
    "            stem = stats_f.stem.split(\"-\")[0] + \"-\" + stats_f.stem.split(\"-\")[1]\n",
    "            # stats load the csv\n",
    "            stats = load_stats_csv(out_path,stem, target)\n",
    "            # projection stats\n",
    "            proj = load_proj_stats_csv(out_path,stem, target)\n",
    "            # cross stats\n",
    "            cross = load_cross_stats_csv(out_path,stem, target)\n",
    "\n",
    "            stats_df = pd.concat([stats_df,stats],axis=0, join='outer')\n",
    "            proj_stats_df = pd.concat([proj_stats_df,proj],axis=0, join='outer')\n",
    "            cross_stats_df = pd.concat([cross_stats_df,cross],axis=0, join='outer')\n",
    "        \n",
    "\n",
    "        ## maybe merge into all the possible files?\n",
    "        # summary_df = pd.DataFrame(index=[f.stem.split(\"-\")[0] for f in stat_file_list])\n",
    "        # cross_stats_df = pd.DataFrame(index=[f.stem.split(\"-\")[0] for f in stat_file_list])\n",
    "        # proj_stats_df = pd.DataFrame(index=[f.stem.split(\"-\")[0] for f in stat_file_list])\n",
    "\n",
    "        summary_df = create_stats_summary(stats_df)\n",
    "        summary_df.insert(loc=1,column=\"organelle\",value=target)\n",
    "        cross_summary_df = summarize_cross_stats(cross_stats_df)\n",
    "        ## cross_summary_df = pivot_cross_stats(cross_stats_df)  #makes a wide version... but has a bug\n",
    "        cross_summary_df.insert(loc=1,column=\"organelle\",value=target)\n",
    "\n",
    "        all_stats_df = pd.concat([all_stats_df,summary_df],axis=0)\n",
    "        all_proj_stats_df = pd.concat([all_proj_stats_df,proj_stats_df],axis=0)\n",
    "        all_cross_stats_df = pd.concat([all_cross_stats_df,cross_summary_df],axis=0)\n",
    "    \n",
    "\n",
    "    return all_stats_df, all_proj_stats_df, all_cross_stats_df\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stats_csv(in_path: Path, img_id: str, target_org: str) -> pd.DataFrame:\n",
    "    \"\"\" helper to load the basic stats csv: `img_id`-`target_organelle` -stats.csv\n",
    "    returns pandas DataFrame \"\"\"\n",
    "    csv_path = in_path / f\"{img_id}-{target_org}-stats.csv\"\n",
    "    stats = pd.read_csv(csv_path, index_col=0,dtype={\"ID\":str,\"organelle\":str})\n",
    "    # need to convert columns *_labels\n",
    "    list_cols = [col for col in stats.columns if col.endswith('_labels')]\n",
    "    stats = fix_int_list_cols(stats,list_cols)\n",
    "    return stats\n",
    "        \n",
    "\n",
    "def load_proj_stats_csv(in_path: Path, img_id: str, target_org: str) -> pd.DataFrame:\n",
    "    \"\"\" helper to load  the projection stats csv: `img_id`-`target_organelle` -proj-stats.csv\n",
    "    returns pandas DataFrame \"\"\"\n",
    "    # obj_cols =  ['ID', 'organelle','radial_n_bins','n_z']  # leave alone\n",
    "    # str_cols = [ 'radial_bins']\n",
    "    int_cols = ['radial_cm_vox_cnt', 'radial_org_vox_cnt', 'radial_org_intensity', 'radial_n_pix','zernike_n', 'zernike_m', 'z','z_cm_vox_cnt','z_org_vox_cnt', 'z_org_intensity', 'z_nuc_vox_cnt']\n",
    "    float_cols = ['radial_cm_cv', 'radial_org_cv', 'radial_img_cv','zernike_cm_mag', 'zernike_cm_phs','zernike_obj_mag', 'zernike_obj_phs', 'zernike_nuc_mag','zernike_nuc_phs', 'zernike_img_mag']\n",
    "\n",
    "    csv_path = in_path / f\"{img_id}-{target_org}-proj-stats.csv\"\n",
    "    proj = pd.read_csv(csv_path, index_col=0)\n",
    "    proj['radial_bins'] = proj['radial_bins'].values.squeeze().tolist()\n",
    "    # proj = fix_str_list_cols(proj, str_cols)\n",
    "    proj = fix_int_list_cols(proj, int_cols)\n",
    "    proj = fix_float_list_cols(proj, float_cols)\n",
    "    return proj\n",
    "        \n",
    "\n",
    "def load_cross_stats_csv(in_path: Path, img_id: str, target_org: str) -> pd.DataFrame:\n",
    "    \"\"\" helper to load  the cross- stats csv: `img_id`-`target_organelle` -cross-stats.csv\n",
    "    returns pandas DataFrame \"\"\"\n",
    "    csv_path = in_path / f\"{img_id}-{target_org}-cross-stats.csv\"\n",
    "    cross = pd.read_csv(csv_path, index_col=0)\n",
    "    return cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis/20230606_out'),\n",
       " ['nuc', 'lyso', 'mito', 'golgi', 'perox', 'ER', 'LD'])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_path, organelle_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from infer_subc.utils.stats_helpers import summarize_organelle_stats, dump_organelle_summary_tables\n",
    "\n",
    "# all the imaging data goes here.\n",
    "data_root_path = Path(\"C:/Users/redre/Documents/CohenLab/MSI-3D-analysis/20230606_test_files_practice_analysis\")\n",
    "# linearly unmixed \".czi\" files are here\n",
    "raw_data_path = data_root_path / \"test_files\"\n",
    "# save output \".tiff\" files here could be different than out\n",
    "int_data_path = data_root_path / \"20230606_out\"\n",
    "# save stats here\n",
    "out_data_path = data_root_path / \"20230606_out\"\n",
    "\n",
    "#Creates a summary of the data and combines/concatenates them into the corresponding pandas tables\n",
    "\n",
    "all_stats_df, all_proj_stats_df, all_cross_stats_df = _summarize_organelle_stats( int_path, organelle_names )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volume_sum</th>\n",
       "      <th>organelle</th>\n",
       "      <th>volume_mean</th>\n",
       "      <th>volume_median</th>\n",
       "      <th>volume_min</th>\n",
       "      <th>volume_max</th>\n",
       "      <th>volume_std</th>\n",
       "      <th>volume_count</th>\n",
       "      <th>equivalent_diameter_sum</th>\n",
       "      <th>equivalent_diameter_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>shell_surface_area_sum</th>\n",
       "      <th>shell_surface_area_mean</th>\n",
       "      <th>shell_surface_area_median</th>\n",
       "      <th>shell_surface_area_min</th>\n",
       "      <th>shell_surface_area_max</th>\n",
       "      <th>shell_surface_area_std</th>\n",
       "      <th>shell_surface_area_count</th>\n",
       "      <th>shell_label__lst</th>\n",
       "      <th>shell_label_a_lst</th>\n",
       "      <th>shell_label_b_lst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11229</td>\n",
       "      <td>lyso</td>\n",
       "      <td>98.500000</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "      <td>4825</td>\n",
       "      <td>465.957464</td>\n",
       "      <td>114</td>\n",
       "      <td>411.400217</td>\n",
       "      <td>3.608774</td>\n",
       "      <td>...</td>\n",
       "      <td>22621.086073</td>\n",
       "      <td>186.951125</td>\n",
       "      <td>50.824539</td>\n",
       "      <td>6.928203</td>\n",
       "      <td>4795.984863</td>\n",
       "      <td>495.056522</td>\n",
       "      <td>121</td>\n",
       "      <td>[2_1, 5_1, 7_1, 9_1, 10_1, 13_1, 4_1, 13_1, 14...</td>\n",
       "      <td>[2.0, 5.0, 7.0, 9.0, 10.0, 13.0, 4.0, 13.0, 14...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>lyso</td>\n",
       "      <td>78.714286</td>\n",
       "      <td>23.5</td>\n",
       "      <td>1</td>\n",
       "      <td>355</td>\n",
       "      <td>102.839254</td>\n",
       "      <td>14</td>\n",
       "      <td>59.139430</td>\n",
       "      <td>4.224245</td>\n",
       "      <td>...</td>\n",
       "      <td>1665.824014</td>\n",
       "      <td>118.987430</td>\n",
       "      <td>60.180458</td>\n",
       "      <td>6.928203</td>\n",
       "      <td>370.871277</td>\n",
       "      <td>124.164551</td>\n",
       "      <td>14</td>\n",
       "      <td>[22_42, 6_46, 27_75, 32_101, 22_68, 25_18, 42_...</td>\n",
       "      <td>[22.0, 6.0, 27.0, 32.0, 22.0, 25.0, 42.0, 45.0...</td>\n",
       "      <td>[42.0, 46.0, 75.0, 101.0, 68.0, 18.0, 84.0, 3....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1800</td>\n",
       "      <td>lyso</td>\n",
       "      <td>112.500000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>423</td>\n",
       "      <td>119.046210</td>\n",
       "      <td>16</td>\n",
       "      <td>83.015993</td>\n",
       "      <td>5.188500</td>\n",
       "      <td>...</td>\n",
       "      <td>3674.489944</td>\n",
       "      <td>229.655621</td>\n",
       "      <td>158.008888</td>\n",
       "      <td>6.928203</td>\n",
       "      <td>548.857422</td>\n",
       "      <td>173.461840</td>\n",
       "      <td>16</td>\n",
       "      <td>[11_3, 14_5, 22_2, 4_2, 6_3, 22_2, 19_2, 6_2, ...</td>\n",
       "      <td>[11.0, 14.0, 22.0, 4.0, 6.0, 22.0, 19.0, 6.0, ...</td>\n",
       "      <td>[3.0, 5.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3082</td>\n",
       "      <td>lyso</td>\n",
       "      <td>44.028571</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>441</td>\n",
       "      <td>80.125259</td>\n",
       "      <td>70</td>\n",
       "      <td>240.222937</td>\n",
       "      <td>3.431756</td>\n",
       "      <td>...</td>\n",
       "      <td>8436.417954</td>\n",
       "      <td>118.822788</td>\n",
       "      <td>56.947926</td>\n",
       "      <td>6.928203</td>\n",
       "      <td>1067.907471</td>\n",
       "      <td>180.562192</td>\n",
       "      <td>71</td>\n",
       "      <td>[10_4, 4_23, 15_34, 17_25, 18_4, 6_26, 6_4, 16...</td>\n",
       "      <td>[10.0, 4.0, 15.0, 17.0, 18.0, 6.0, 6.0, 16.0, ...</td>\n",
       "      <td>[4.0, 23.0, 34.0, 25.0, 4.0, 26.0, 4.0, 18.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "      <td>lyso</td>\n",
       "      <td>10.923077</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>14.268039</td>\n",
       "      <td>13</td>\n",
       "      <td>30.887463</td>\n",
       "      <td>2.375959</td>\n",
       "      <td>...</td>\n",
       "      <td>464.462855</td>\n",
       "      <td>35.727912</td>\n",
       "      <td>21.513260</td>\n",
       "      <td>6.928203</td>\n",
       "      <td>92.804329</td>\n",
       "      <td>28.647155</td>\n",
       "      <td>13</td>\n",
       "      <td>[6_54, 29_55, 38_61, 29_99, 21_67, 6_102, 21_1...</td>\n",
       "      <td>[6.0, 29.0, 38.0, 29.0, 21.0, 6.0, 21.0, 54.0,...</td>\n",
       "      <td>[54.0, 55.0, 61.0, 99.0, 67.0, 102.0, 107.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1794</td>\n",
       "      <td>LD</td>\n",
       "      <td>33.222222</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1</td>\n",
       "      <td>447</td>\n",
       "      <td>84.118664</td>\n",
       "      <td>54</td>\n",
       "      <td>163.387120</td>\n",
       "      <td>3.025687</td>\n",
       "      <td>...</td>\n",
       "      <td>4558.727007</td>\n",
       "      <td>84.420871</td>\n",
       "      <td>40.826969</td>\n",
       "      <td>6.928203</td>\n",
       "      <td>898.259216</td>\n",
       "      <td>155.745454</td>\n",
       "      <td>54</td>\n",
       "      <td>[1_1, 13_1, 17_1, 18_1, 1_1, 26_1, 28_1, 29_1,...</td>\n",
       "      <td>[1.0, 13.0, 17.0, 18.0, 1.0, 26.0, 28.0, 29.0,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>111</td>\n",
       "      <td>LD</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>10.839742</td>\n",
       "      <td>9</td>\n",
       "      <td>23.995991</td>\n",
       "      <td>2.666221</td>\n",
       "      <td>...</td>\n",
       "      <td>431.541039</td>\n",
       "      <td>47.949004</td>\n",
       "      <td>32.362869</td>\n",
       "      <td>18.241911</td>\n",
       "      <td>101.189835</td>\n",
       "      <td>32.274704</td>\n",
       "      <td>9</td>\n",
       "      <td>[14_1, 14_1, 87_1, 94_1, 100_19, 101_19, 88_1,...</td>\n",
       "      <td>[14.0, 14.0, 87.0, 94.0, 100.0, 101.0, 88.0, 9...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 19.0, 19.0, 1.0, 20.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>3</td>\n",
       "      <td>LD</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1.789400</td>\n",
       "      <td>1.789400</td>\n",
       "      <td>...</td>\n",
       "      <td>17.049160</td>\n",
       "      <td>17.049160</td>\n",
       "      <td>17.049160</td>\n",
       "      <td>17.049160</td>\n",
       "      <td>17.049160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>[120_161]</td>\n",
       "      <td>[120.0]</td>\n",
       "      <td>[161.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>536</td>\n",
       "      <td>LD</td>\n",
       "      <td>15.764706</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>30.348540</td>\n",
       "      <td>34</td>\n",
       "      <td>88.391752</td>\n",
       "      <td>2.599757</td>\n",
       "      <td>...</td>\n",
       "      <td>1821.901451</td>\n",
       "      <td>53.585337</td>\n",
       "      <td>38.806271</td>\n",
       "      <td>6.928203</td>\n",
       "      <td>391.502563</td>\n",
       "      <td>69.441030</td>\n",
       "      <td>34</td>\n",
       "      <td>[29_29, 31_15, 33_5, 33_5, 10_37, 42_29, 33_5,...</td>\n",
       "      <td>[29.0, 31.0, 33.0, 33.0, 10.0, 42.0, 33.0, 48....</td>\n",
       "      <td>[29.0, 15.0, 5.0, 5.0, 37.0, 29.0, 5.0, 9.0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>40</td>\n",
       "      <td>LD</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>7.637626</td>\n",
       "      <td>3</td>\n",
       "      <td>8.549181</td>\n",
       "      <td>2.849727</td>\n",
       "      <td>...</td>\n",
       "      <td>138.483580</td>\n",
       "      <td>46.161193</td>\n",
       "      <td>54.853249</td>\n",
       "      <td>24.706015</td>\n",
       "      <td>58.924316</td>\n",
       "      <td>18.691894</td>\n",
       "      <td>3</td>\n",
       "      <td>[36_23, 14_63, 14_91]</td>\n",
       "      <td>[36.0, 14.0, 14.0]</td>\n",
       "      <td>[23.0, 63.0, 91.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   volume_sum organelle  volume_mean  volume_median volume_min volume_max   \n",
       "0       11229      lyso    98.500000           13.5          1       4825  \\\n",
       "1        1102      lyso    78.714286           23.5          1        355   \n",
       "2        1800      lyso   112.500000           48.0          1        423   \n",
       "3        3082      lyso    44.028571           14.0          1        441   \n",
       "4         142      lyso    10.923077            4.0          1         51   \n",
       "..        ...       ...          ...            ...        ...        ...   \n",
       "56       1794        LD    33.222222            9.5          1        447   \n",
       "57        111        LD    12.333333            7.0          3         31   \n",
       "58          3        LD     3.000000            3.0          3          3   \n",
       "59        536        LD    15.764706            8.5          1        173   \n",
       "60         40        LD    13.333333           15.0          5         20   \n",
       "\n",
       "    volume_std  volume_count  equivalent_diameter_sum   \n",
       "0   465.957464           114               411.400217  \\\n",
       "1   102.839254            14                59.139430   \n",
       "2   119.046210            16                83.015993   \n",
       "3    80.125259            70               240.222937   \n",
       "4    14.268039            13                30.887463   \n",
       "..         ...           ...                      ...   \n",
       "56   84.118664            54               163.387120   \n",
       "57   10.839742             9                23.995991   \n",
       "58         NaN             1                 1.789400   \n",
       "59   30.348540            34                88.391752   \n",
       "60    7.637626             3                 8.549181   \n",
       "\n",
       "    equivalent_diameter_mean  ...  shell_surface_area_sum   \n",
       "0                   3.608774  ...            22621.086073  \\\n",
       "1                   4.224245  ...             1665.824014   \n",
       "2                   5.188500  ...             3674.489944   \n",
       "3                   3.431756  ...             8436.417954   \n",
       "4                   2.375959  ...              464.462855   \n",
       "..                       ...  ...                     ...   \n",
       "56                  3.025687  ...             4558.727007   \n",
       "57                  2.666221  ...              431.541039   \n",
       "58                  1.789400  ...               17.049160   \n",
       "59                  2.599757  ...             1821.901451   \n",
       "60                  2.849727  ...              138.483580   \n",
       "\n",
       "    shell_surface_area_mean  shell_surface_area_median   \n",
       "0                186.951125                  50.824539  \\\n",
       "1                118.987430                  60.180458   \n",
       "2                229.655621                 158.008888   \n",
       "3                118.822788                  56.947926   \n",
       "4                 35.727912                  21.513260   \n",
       "..                      ...                        ...   \n",
       "56                84.420871                  40.826969   \n",
       "57                47.949004                  32.362869   \n",
       "58                17.049160                  17.049160   \n",
       "59                53.585337                  38.806271   \n",
       "60                46.161193                  54.853249   \n",
       "\n",
       "    shell_surface_area_min  shell_surface_area_max  shell_surface_area_std   \n",
       "0                 6.928203             4795.984863              495.056522  \\\n",
       "1                 6.928203              370.871277              124.164551   \n",
       "2                 6.928203              548.857422              173.461840   \n",
       "3                 6.928203             1067.907471              180.562192   \n",
       "4                 6.928203               92.804329               28.647155   \n",
       "..                     ...                     ...                     ...   \n",
       "56                6.928203              898.259216              155.745454   \n",
       "57               18.241911              101.189835               32.274704   \n",
       "58               17.049160               17.049160                     NaN   \n",
       "59                6.928203              391.502563               69.441030   \n",
       "60               24.706015               58.924316               18.691894   \n",
       "\n",
       "    shell_surface_area_count   \n",
       "0                        121  \\\n",
       "1                         14   \n",
       "2                         16   \n",
       "3                         71   \n",
       "4                         13   \n",
       "..                       ...   \n",
       "56                        54   \n",
       "57                         9   \n",
       "58                         1   \n",
       "59                        34   \n",
       "60                         3   \n",
       "\n",
       "                                     shell_label__lst   \n",
       "0   [2_1, 5_1, 7_1, 9_1, 10_1, 13_1, 4_1, 13_1, 14...  \\\n",
       "1   [22_42, 6_46, 27_75, 32_101, 22_68, 25_18, 42_...   \n",
       "2   [11_3, 14_5, 22_2, 4_2, 6_3, 22_2, 19_2, 6_2, ...   \n",
       "3   [10_4, 4_23, 15_34, 17_25, 18_4, 6_26, 6_4, 16...   \n",
       "4   [6_54, 29_55, 38_61, 29_99, 21_67, 6_102, 21_1...   \n",
       "..                                                ...   \n",
       "56  [1_1, 13_1, 17_1, 18_1, 1_1, 26_1, 28_1, 29_1,...   \n",
       "57  [14_1, 14_1, 87_1, 94_1, 100_19, 101_19, 88_1,...   \n",
       "58                                          [120_161]   \n",
       "59  [29_29, 31_15, 33_5, 33_5, 10_37, 42_29, 33_5,...   \n",
       "60                              [36_23, 14_63, 14_91]   \n",
       "\n",
       "                                    shell_label_a_lst   \n",
       "0   [2.0, 5.0, 7.0, 9.0, 10.0, 13.0, 4.0, 13.0, 14...  \\\n",
       "1   [22.0, 6.0, 27.0, 32.0, 22.0, 25.0, 42.0, 45.0...   \n",
       "2   [11.0, 14.0, 22.0, 4.0, 6.0, 22.0, 19.0, 6.0, ...   \n",
       "3   [10.0, 4.0, 15.0, 17.0, 18.0, 6.0, 6.0, 16.0, ...   \n",
       "4   [6.0, 29.0, 38.0, 29.0, 21.0, 6.0, 21.0, 54.0,...   \n",
       "..                                                ...   \n",
       "56  [1.0, 13.0, 17.0, 18.0, 1.0, 26.0, 28.0, 29.0,...   \n",
       "57  [14.0, 14.0, 87.0, 94.0, 100.0, 101.0, 88.0, 9...   \n",
       "58                                            [120.0]   \n",
       "59  [29.0, 31.0, 33.0, 33.0, 10.0, 42.0, 33.0, 48....   \n",
       "60                                 [36.0, 14.0, 14.0]   \n",
       "\n",
       "                                    shell_label_b_lst  \n",
       "0   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "1   [42.0, 46.0, 75.0, 101.0, 68.0, 18.0, 84.0, 3....  \n",
       "2   [3.0, 5.0, 2.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, ...  \n",
       "3   [4.0, 23.0, 34.0, 25.0, 4.0, 26.0, 4.0, 18.0, ...  \n",
       "4   [54.0, 55.0, 61.0, 99.0, 67.0, 102.0, 107.0, 1...  \n",
       "..                                                ...  \n",
       "56  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "57   [1.0, 1.0, 1.0, 1.0, 19.0, 19.0, 1.0, 20.0, 1.0]  \n",
       "58                                            [161.0]  \n",
       "59  [29.0, 15.0, 5.0, 5.0, 37.0, 29.0, 5.0, 9.0, 2...  \n",
       "60                                 [23.0, 63.0, 91.0]  \n",
       "\n",
       "[382 rows x 51 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cross_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dump_organelle_summary_tables(\n",
    "                    int_path: Union[Path,str], \n",
    "                    out_path: Union[Path, str], \n",
    "                    organelle_names: List[str]= [\"nuclei\",\"golgi\",\"peroxi\"] ) -> int:\n",
    "    \"\"\"\n",
    "    get summary and all cross stats between organelles `a` and `b`\n",
    "    calls `get_summary_stats_3D`\n",
    "    \"\"\"\n",
    "\n",
    "    if not Path.exists(out_path):\n",
    "        Path.mkdir(out_path)\n",
    "        print(f\"making {out_path}\")\n",
    "\n",
    "\n",
    "    all_stats_df, all_proj_stats_df, all_cross_stats_df = _summarize_organelle_stats( int_path, organelle_names )\n",
    "\n",
    "    csv_path = out_path / f\"summary-stats.csv\"\n",
    "    all_stats_df.to_csv(csv_path)\n",
    "\n",
    "    csv_path = out_path / f\"summary-proj-stats.csv\"\n",
    "    all_proj_stats_df.to_csv(csv_path)\n",
    "\n",
    "    csv_path = out_path / f\"summary-cross-stats.csv\"\n",
    "    all_cross_stats_df.to_csv(csv_path)\n",
    "\n",
    "    return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_files = _dump_organelle_summary_tables(out_data_path, \n",
    "                     out_data_path, \n",
    "                     organelle_names)\n",
    "\n",
    "n_files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some wrappers to deal with reading our summary stats into pandas properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_summary_stats_csv(in_path: Path) -> pd.DataFrame:\n",
    "    \"\"\" helper to load the summary stats csv: summary-stats.csv\n",
    "    returns pandas DataFrame \"\"\"\n",
    "    csv_path = in_path / f\"summary-stats.csv\"\n",
    "    summary_df = pd.read_csv(csv_path, index_col=0)\n",
    "    # need to convert columns *_labels\n",
    "    list_cols = [col for col in summary_df.columns if \"labels\" in col] #if col.contains(\"label\")\n",
    "    summary_df = fix_int_list_cols(summary_df,list_cols)\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def load_summary_proj_stats_csv(in_path: Path) -> pd.DataFrame:\n",
    "    \"\"\" helper to load summary projection stats csv: summary-proj-stats.csv\n",
    "    returns pandas DataFrame \"\"\"\n",
    "    obj_cols =  ['ID', 'organelle','mask','radial_n_bins','n_z']  # leave alone\n",
    "    str_cols = [ 'radial_bins']\n",
    "    int_cols = ['radial_cm_vox_cnt', 'radial_org_vox_cnt', 'radial_org_intensity', 'radial_n_pix','zernike_n', 'zernike_m', 'z','z_cm_vox_cnt','z_org_vox_cnt', 'z_org_intensity', 'z_nuc_vox_cnt']\n",
    "    float_cols = ['radial_cm_cv', 'radial_org_cv', 'radial_img_cv','zernike_cm_mag', 'zernike_cm_phs','zernike_obj_mag', 'zernike_obj_phs', 'zernike_nuc_mag','zernike_nuc_phs', 'zernike_img_mag']\n",
    "\n",
    "    csv_path = in_path / f\"summary-proj-stats.csv\"\n",
    "    proj = pd.read_csv(csv_path, index_col=0)\n",
    "    proj = fix_str_list_cols(proj, str_cols)\n",
    "    proj = fix_int_list_cols(proj, int_cols)\n",
    "    proj = fix_float_list_cols(proj, float_cols)\n",
    "    return proj\n",
    "        \n",
    "\n",
    "def load_summary_cross_stats_csv(in_path: Path) -> pd.DataFrame:\n",
    "    \"\"\" helper to load summary cross- stats csv: summary-cross-stats.csv\n",
    "    returns pandas DataFrame \"\"\"\n",
    "\n",
    "    csv_path = in_path / f\"summary-cross-stats.csv\"\n",
    "    summary_df = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "    list_cols = [col for col in summary_df.columns if \"label\" in col] #if col.contains(\"label\")\n",
    "    str_list_cols = [col for col in list_cols if \"__\" in col]\n",
    "    int_list_cols = [col for col in list_cols if \"__\" not in col]\n",
    "\n",
    "    summary_df = fix_str_list_cols(summary_df,str_list_cols)\n",
    "    summary_df = fix_int_list_cols(summary_df,int_list_cols)\n",
    "\n",
    "    return summary_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_summary_stats_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#summary_shell.head()\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test \u001b[39m=\u001b[39m load_summary_stats_csv(out_data_path)\n\u001b[0;32m      3\u001b[0m test_proj \u001b[39m=\u001b[39m load_summary_proj_stats_csv(out_data_path)\n\u001b[0;32m      4\u001b[0m test_cross \u001b[39m=\u001b[39m load_summary_cross_stats_csv(out_data_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_summary_stats_csv' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#summary_shell.head()\n",
    "test = load_summary_stats_csv(out_data_path)\n",
    "test_proj = load_summary_proj_stats_csv(out_data_path)\n",
    "test_cross = load_summary_cross_stats_csv(out_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'max_columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5304\\730264220.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\redre\\anaconda3\\envs\\infer-subc-ngudi\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5985\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5986\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5987\u001b[0m         ):\n\u001b[0;32m   5988\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5989\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'max_columns'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napariNEW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
