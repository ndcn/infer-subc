{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer ***nuclei*** - 2ï¸âƒ£ \n",
    "\n",
    "> WARNING: (ðŸš¨ðŸš¨ðŸš¨ðŸš¨ Steps 2-9 depend on establishing a good solution here.)\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE: \n",
    "### âœ… Infer sub-cellular component #2: ***nuclei***  in order to understand interactome \n",
    "\n",
    "Infer a segmentation of the ***nuclei*** in order to measure its shape, position, size, and interaction with other organelles/cellular components.  \n",
    "\n",
    "## OVERVIEW:\n",
    "\n",
    "We will infer the nuclei using the nuclei channel (e.g. 'ch = 0).\n",
    "\n",
    "Dependencies:\n",
    "***Soma*** and ***cytoplasm*** inference rely on the ***nuclei*** inference.  Therefore all of the sub-cellular objects rely on the NU segmentation.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preamble\n",
    "\n",
    "1. imports\n",
    "2. setup\n",
    "3. infer-nuclei\n",
    "    * input\n",
    "    * pre-processing\n",
    "    * core processing\n",
    "    * post-processing\n",
    "    * output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from aicssegmentation.core.pre_processing_utils import  image_smoothing_gaussian_slice_by_slice \n",
    "from aicssegmentation.core.utils import hole_filling\n",
    "from skimage.measure import label\n",
    "\n",
    "# # package for io \n",
    "from aicsimageio import AICSImage\n",
    "\n",
    "import napari\n",
    "\n",
    "### import local python functions in ../infer_subc\n",
    "sys.path.append(os.path.abspath((os.path.join(os.getcwd(), '..'))))\n",
    "\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image,\n",
    "                                                                    list_image_files)\n",
    "from infer_subc.core.img import *\n",
    "from infer_subc.organelles import fixed_get_optimal_Z_image, fixed_find_optimal_Z, find_optimal_Z\n",
    "from infer_subc.constants import (TEST_IMG_N,\n",
    "                                                                    NUC_CH ,\n",
    "                                                                    LYSO_CH ,\n",
    "                                                                    MITO_CH ,\n",
    "                                                                    GOLGI_CH ,\n",
    "                                                                    PEROX_CH ,\n",
    "                                                                    ER_CH ,\n",
    "                                                                    LD_CH ,\n",
    "                                                                    RESIDUAL_CH, \n",
    "                                                                    ALL_CHANNELS )          \n",
    "\n",
    "from infer_subc.organelles import infer_cellmask_fromaggr, fixed_infer_cellmask_fromaggr\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## SETUP\n",
    "CUSTOMIZE WITH: \n",
    "1. updated path to data\n",
    "2. updated folder name for \"raw\" data\n",
    "\n",
    "> NOTE: we are operating on a single \"test\" image in this notebook.  The batch-processing of all the images will be happen at the end of the notebook after we have developed/confirmed the setmentation procedures and parameter settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will be the example image for testing the pipeline below\n",
    "test_img_n = TEST_IMG_N\n",
    "\n",
    "# build the datapath\n",
    "# all the imaging data goes here.\n",
    "# CUSTOMIZE HERE --->\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Documents/Python Scripts/infer-subc\"\n",
    "data_root_path = Path(os.path.expanduser(\"~\")) / \"Projects/Imaging/data\"\n",
    "\n",
    "# linearly unmixed \".czi\" files are here\n",
    "# CUSTOMIZE HERE --->\n",
    "data_path = data_root_path / \"raw\"\n",
    "im_type = \".czi\"\n",
    "\n",
    "# get the list of all files in \"raw\"\n",
    "img_file_list = list_image_files(data_path,im_type)\n",
    "test_img_name = img_file_list[test_img_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/napariNEW/lib/python3.9/site-packages/ome_types/_convenience.py:106: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    }
   ],
   "source": [
    "# isolate image as an ndarray and metadata as a dictionary\n",
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# get some top-level info about the RAW data\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## infer ***nuclei***\n",
    "\n",
    "### summary of steps\n",
    "\n",
    "âž¡ï¸ INPUT\n",
    "- channel 0\n",
    "\n",
    "PRE-PROCESSING\n",
    "- scale to min 0, max 1.0\n",
    "- median Filter window 4\n",
    "- gaussian 1.34\n",
    "\n",
    "CORE-PROCESSING\n",
    "  - threshold method minimum cross-entropy.  \n",
    "    - objects 50-400 pixels, \n",
    "    - threshold smoothing scale: 1.34 (later 1 pixel\n",
    "    - threshold correction factor: 0.9 (later 1.2 )\n",
    "    - lower / upper bounds  (.1, 1)\n",
    "    - log transformed thresholding\n",
    "\n",
    "POST-PROCESSING\n",
    "  - fill holes\n",
    "  - remove small objects\n",
    "\n",
    "OUTPUT âž¡ï¸ \n",
    "- mask of NUCLEI\n",
    "\n",
    "\n",
    "> #### Note:  in later steps we will isolate individual cells for analysis. Here, all nuclei are segmented and retained.\n",
    "\n",
    "\n",
    "\n",
    "#### NOTE:  using Allen Cell Segmenter  [Nucleophosmin](https://www.allencell.org/cell-observations/category/nucleophosmin) might be a good generic mechanism.  e.g.\n",
    "-  [playground_npm1.ipynb](https://github.com/AllenInstitute/aics-segmentation/blob/master/lookup_table_demo/playground_npm1.ipynb) and [npm1.py](https://github.com/AllenInstitute/aics-segmentation/blob/master/aicssegmentation/structure_wrapper/seg_npm1.py) and [npm1_SR.py](https://github.com/AllenInstitute/aics-segmentation/blob/master/aicssegmentation/structure_wrapper/seg_npm1_SR.py)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUT (prototype)\n",
    "\n",
    "Get the \"raw\" signals we need to analyze as well as any other dependencies in \"inferred\" objects.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 768, 768)\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "# raw_nuclei = img_data[NUC_CH].copy()\n",
    "raw_nuclei = select_channel_from_raw(img_data, NUC_CH)\n",
    "\n",
    "print(raw_nuclei.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESSING (prototype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 768, 768)\n",
      "(16, 768, 768)\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################           \n",
    "nuclei_norm = min_max_intensity_normalization(raw_nuclei)\n",
    "\n",
    "med_filter_size = 4   \n",
    "nuclei_med = median_filter_slice_by_slice(nuclei_norm,\n",
    "                                      size=med_filter_size)\n",
    "print(nuclei_med.shape)\n",
    "\n",
    "gaussian_smoothing_sigma = 1.34\n",
    "nuclei_gaus = image_smoothing_gaussian_slice_by_slice(nuclei_med,\n",
    "                                                      sigma=gaussian_smoothing_sigma)\n",
    "print(nuclei_gaus.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZE: the nuclei image after pre-processing\n",
    "Use this to adjust median filter size and gaussian sigma above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'nuclei_gaus' at 0x1cf5b5642b0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    raw_nuclei,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    nuclei_med,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    nuclei_gaus,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CORE PROCESSING (prototype)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> #### ASIDE: Thresholding\n",
    "> [Thresholding](https://en.wikipedia.org/wiki/Thresholding_%28image_processing%29) is used to create binary images. A threshold value determines the intensity value separating foreground pixels from background pixels. Foregound pixels are pixels brighter than the threshold value, background pixels are darker. In many cases, images can be adequately segmented by thresholding followed by labelling of *connected components*, which is a fancy way of saying \"groups of pixels that touch each other\".\n",
    "> \n",
    "> Different thresholding algorithms produce different results. [Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method) and [Li's minimum cross entropy threshold](https://scikit-image.org/docs/dev/auto_examples/developers/plot_threshold_li.html) are two common algorithms. Below, we use Li. You can use `skimage.filters.threshold_<TAB>` to find different thresholding methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 704, 704)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "\n",
    "threshold_factor = 0.9 #from cellProfiler\n",
    "thresh_min = .1\n",
    "thresh_max = 1.\n",
    "li_thresholded = apply_log_li_threshold(nuclei_gaus, thresh_factor=threshold_factor, thresh_min=thresh_min, thresh_max=thresh_max)\n",
    "\n",
    "print(li_thresholded.shape)\n",
    "\n",
    "\n",
    "## **************NEED TO ADJUST THESE SETTINGS TO ISOLATE MORE OF THE TOP AND BOTTOM OF THE NUCLEI***************"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZE: the nuclei image after core processing\n",
    "Use this to adjust threshold parameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'li_thresholded' at 0x1cf8f31fe80>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    li_thresholded,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST PROCESSING prototype\n",
    "\n",
    "> NOTE: the size parameters are by convention defined as one dimensional \"width\", so the inputs to the functions need to be _squared_ i.e. raised to the power of 2: `** 2`.   For volumetric (3D) analysis this would be _cubed_:`**3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "\n",
    "hole_width = 5  \n",
    "removed_holes = hole_filling(li_thresholded,\n",
    "                             hole_min=0, \n",
    "                             hole_max=hole_width**2, \n",
    "                             fill_2d=True)\n",
    "# there does not seem to be any observable differences between the slice-by-slice and 3D methods here for hole filling\n",
    "\n",
    "small_object_width = 15\n",
    "cleaned_img = size_filter(removed_holes, \n",
    "                          min_size= small_object_width**3, #changed this to 3 to adjust for the 3D voxel, instead of a 2D pixel \n",
    "                          method=\"3D\",\n",
    "                          connectivity=1)\n",
    "\n",
    "## ************NEED TO ADJUST THESE SETTINGS TO GET RID OF SMALL BITS*****************\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZE: the nuclei image after post-processing\n",
    "Use this to adjust the size parameters above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer 'cleaned_img' at 0x1cf8f2081c0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    removed_holes,\n",
    "    scale=scale\n",
    ")\n",
    "viewer.add_image(\n",
    "    cleaned_img,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "wrapped C/C++ object of type QtViewer has been deleted",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m viewer\u001b[39m.\u001b[39;49mclose()\n",
      "File \u001b[1;32mc:\\Users\\Shannon\\Anaconda3\\envs\\infer-subc\\lib\\site-packages\\napari\\viewer.py:118\u001b[0m, in \u001b[0;36mViewer.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mclear()\n\u001b[0;32m    117\u001b[0m \u001b[39m# Close the main window\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindow\u001b[39m.\u001b[39;49mclose()\n\u001b[0;32m    120\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39masync_loading:\n\u001b[0;32m    121\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexperimental\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchunk\u001b[39;00m \u001b[39mimport\u001b[39;00m chunk_loader\n",
      "File \u001b[1;32mc:\\Users\\Shannon\\Anaconda3\\envs\\infer-subc\\lib\\site-packages\\napari\\_qt\\qt_main_window.py:1222\u001b[0m, in \u001b[0;36mWindow.close\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_qt_window\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   1221\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n\u001b[1;32m-> 1222\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_qt_viewer\u001b[39m.\u001b[39;49mclose()\n\u001b[0;32m   1223\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qt_window\u001b[39m.\u001b[39mclose()\n\u001b[0;32m   1224\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qt_window\n",
      "\u001b[1;31mRuntimeError\u001b[0m: wrapped C/C++ object of type QtViewer has been deleted"
     ]
    }
   ],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust naming and type for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "NU_signal = raw_nuclei\n",
    "\n",
    "# renaming semantic segmentation of nuclei\n",
    "nuclei_object = cleaned_img\n",
    "\n",
    "# creating instance segmentations for all nuclei in nuclei_object\n",
    "NU_labels = label(cleaned_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VISUALIZE final segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Labels layer 'NU_labels' at 0x1cf5b1d7cd0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    NU_signal,\n",
    "    scale=scale,\n",
    ")\n",
    "viewer.add_image(\n",
    "    nuclei_object,\n",
    "    scale=scale,\n",
    "    opacity=0.3,\n",
    ")    \n",
    "viewer.add_labels(\n",
    "    NU_labels,\n",
    "    scale=scale,\n",
    "    opacity=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE `_infer_nuclei` function\n",
    "\n",
    "Based on the _prototyping_ above define the function to infer nuclei.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  _infer_nuclei\n",
    "##########################\n",
    "def _infer_nuclei_3D( in_img: np.ndarray,\n",
    "                       median_sz: int, \n",
    "                       gauss_sig: float,\n",
    "                       thresh_factor: float,\n",
    "                       thresh_min: float,\n",
    "                       thresh_max: float,\n",
    "                       max_hole_w: int,\n",
    "                       small_obj_w: int,\n",
    "                       sz_filter_method: str\n",
    "                     ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to infer 3D nuclei segmentation from multichannel z-stack input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: np.ndarray\n",
    "        a 3d image containing all the channels\n",
    "    soma_mask: Optional[np.ndarray] = None\n",
    "        mask\n",
    "    median_sz: int\n",
    "        width of median filter for signal\n",
    "    gauss_sig: float\n",
    "        sigma for gaussian smoothing of  signal\n",
    "    thresh_factor: float\n",
    "        adjustment factor for log Li threholding\n",
    "    thresh_min: float\n",
    "        abs min threhold for log Li threholding\n",
    "    thresh_max: float\n",
    "        abs max threhold for log Li threholding\n",
    "    max_hole_w: int\n",
    "        hole filling cutoff for nuclei post-processing\n",
    "    small_obj_w: int\n",
    "        minimum object size cutoff for nuclei post-processing\n",
    "    sz_filter_method: str\n",
    "        method for size filtering; either \"3D\" or \"slice_by_slice\"\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    nuclei_object\n",
    "        mask defined extent of NU\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    nuc_ch = NUC_CH\n",
    "    nuclei = select_channel_from_raw(in_img, nuc_ch)\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                \n",
    "    nuclei = min_max_intensity_normalization(nuclei)\n",
    "    nuclei = median_filter_slice_by_slice(nuclei,\n",
    "                                          size=median_sz)\n",
    "    nuclei = image_smoothing_gaussian_slice_by_slice(nuclei,\n",
    "                                                     sigma=gauss_sig )\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    nuclei_object = apply_log_li_threshold(nuclei, \n",
    "                                           thresh_factor=thresh_factor, \n",
    "                                           thresh_min=thresh_min, \n",
    "                                           thresh_max=thresh_max)\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    nuclei_object = hole_filling(nuclei_object, \n",
    "                                 hole_min=0, \n",
    "                                 hole_max=max_hole_w**2, \n",
    "                                 fill_2d=True)\n",
    "\n",
    "    nuclei_object = size_filter(nuclei_object, \n",
    "                                min_size = small_obj_w**3, \n",
    "                                method = sz_filter_method,\n",
    "                                connectivity=1)\n",
    "\n",
    "\n",
    "    return nuclei_object\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE `_fixed_infer_nuclei` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  fixed_infer_nuclei\n",
    "##########################\n",
    "def _fixed_infer_nuclei_3D(in_img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to infer cellmask from linearly unmixed input, with a *fixed* set of parameters for each step in the procedure.  i.e. \"hard coded\"\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: np.ndarray\n",
    "        a 3d image containing all the channels\n",
    "    soma_mask: np.ndarray\n",
    "        mask\n",
    " \n",
    "    Returns\n",
    "    -------------\n",
    "    nuclei_object\n",
    "        mask defined extent of NU\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    nuc_ch = NUC_CH\n",
    "    median_sz = 4   \n",
    "    gauss_sig = 1.34\n",
    "    threshold_factor = 0.9\n",
    "    thresh_min = 0.1\n",
    "    thresh_max = 1.0\n",
    "    max_hole_w = 5\n",
    "    small_obj_w = 15\n",
    "    sz_filter_method = \"3D\"\n",
    "\n",
    "    return _infer_nuclei_3D( in_img,\n",
    "                             median_sz,\n",
    "                             gauss_sig,\n",
    "                             threshold_factor,\n",
    "                             thresh_min,\n",
    "                             thresh_max,\n",
    "                             max_hole_w,\n",
    "                             small_obj_w,\n",
    "                             sz_filter_method )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## TEST `_infer_nuclei`  function defined above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NU_object =  _fixed_infer_nuclei_3D(img_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image layer '_NU_object' at 0x1cf9214fa60>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viewer.add_image(\n",
    "    NU_signal,\n",
    "    scale=scale,\n",
    ")\n",
    "viewer.add_image(\n",
    "    nuclei_object,\n",
    "    scale=scale,\n",
    "    opacity=0.3,\n",
    ")    \n",
    "viewer.add_labels(\n",
    "    NU_labels,\n",
    "    scale=scale,\n",
    "    opacity=0.3,\n",
    ")\n",
    "viewer.add_image(\n",
    "    _NU_object,\n",
    "    scale=scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:yellow;color:black\">***WIP*** 2D-->3D transition stops here</code>\n",
    "\n",
    "---------------------\n",
    "# TEST `infer_nuclei_fromlabel` exported functions\n",
    "\n",
    "> the prototype `_infer_nuclei` was copied to the [`.organelles.nuclei`](../infer_subc/organelles/nuclei.py) sub-module \n",
    "##\n",
    "`infer_nuclei_fromlabel` procedure\n",
    "\n",
    "Use the `infer_nuclei_fromlabel` function to infer the Nucleus and export it as an _ome.tif_ for easy reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.organelles.nuclei import infer_nuclei_fromlabel, fixed_infer_nuclei\n",
    "\n",
    "nuclei_object =  fixed_infer_nuclei(img_2D, soma_mask) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize  2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(\n",
    "    _NU_object,\n",
    "    scale=scale,\n",
    "    opacity=0.3,\n",
    ")    \n",
    "\n",
    "\n",
    "viewer.add_labels(\n",
    "    label(_NU_object),\n",
    "    scale=scale,\n",
    "    opacity=0.3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(\n",
    "    nuclei_object,\n",
    "    scale=scale,\n",
    "    opacity=0.3,\n",
    ")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "# viewer.dims.ndisplay = 3\n",
    "# viewer.camera.angles = (-30, 25, 120)\n",
    "nbscreenshot(viewer, canvas_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "Write the `infer_nuclei_fromlabel` spec to the widget json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'infer nuclei  (fixed parameters)',\n",
       " 'python::module': 'infer_subc.organelles',\n",
       " 'python::function': 'fixed_infer_nuclei',\n",
       " 'parameters': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from infer_subc.organelles_config.helper import add_function_spec_to_widget_json\n",
    "\n",
    "_fixed_infer_nuclei =  {\n",
    "        \"name\": \"infer nuclei  (fixed parameters)\",\n",
    "        \"python::module\": \"infer_subc.organelles\",\n",
    "        \"python::function\": \"fixed_infer_nuclei\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "_fixed_infer_nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_function_spec_to_widget_json(\"fixed_infer_nuclei\",_fixed_infer_nuclei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_infer_nuclei =  {\n",
    "        \"name\": \"infer nuclei\",\n",
    "        \"python::module\": \"infer_subc.organelles\",\n",
    "        \"python::function\": \"infer_nuclei_fromlabel\",\n",
    "        \"parameters\": {\n",
    "                \"median_sz\": {\n",
    "                        \"widget_type\": \"slider\",\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"min\": 3,\n",
    "                        \"max\": 15,\n",
    "                        \"increment\": 1\n",
    "                },\n",
    "                \"gauss_sig\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.25,\n",
    "                        \"max\": 15.0,\n",
    "                        \"min\": 1.25,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"thresh_factor\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.05,\n",
    "                        \"max\": 1.2,\n",
    "                        \"min\": 0.6,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"thresh_min\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.05,\n",
    "                        \"max\": .9,\n",
    "                        \"min\": 0.0,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"thresh_max\": {\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"increment\": 0.05,\n",
    "                        \"max\": 1.0,\n",
    "                        \"min\": 0.1,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },\n",
    "                \"max_hole_w\": {\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"increment\": 1,\n",
    "                        \"max\": 40,\n",
    "                        \"min\": 4,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                },           \n",
    "                \"small_obj_w\": {\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"increment\": 1,\n",
    "                        \"max\": 50,\n",
    "                        \"min\": 1,\n",
    "                        \"widget_type\": \"slider\"\n",
    "                }\n",
    "        }\n",
    "}\n",
    "\n",
    "add_function_spec_to_widget_json(\"infer_nuclei_fromlabel\", _infer_nuclei, overwrite=True )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_median_filter_slice_by_slice =  {\n",
    "                \"name\": \"Median Smoothing Slice by Slice\",\n",
    "                \"python::module\": \"infer_subc.core.img\",\n",
    "                \"python::function\": \"median_filter_slice_by_slice\",\n",
    "                \"parameters\": {\n",
    "                    \"size\": {\n",
    "                        \"widget_type\": \"slider\",\n",
    "                        \"data_type\": \"int\",\n",
    "                        \"min\": 1,\n",
    "                        \"max\": 20,\n",
    "                        \"increment\": 1\n",
    "                    }\n",
    "                }\n",
    "            } \n",
    "add_function_spec_to_widget_json(\"median_filter_slice_by_slice\",_median_filter_slice_by_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_image_smoothing_gaussian_slice_by_slice = {\n",
    "        \"name\": \"Gaussian Smoothing Slice by Slice\",\n",
    "        \"python::module\": \"aicssegmentation.core.pre_processing_utils\",\n",
    "        \"python::function\": \"image_smoothing_gaussian_slice_by_slice\",\n",
    "        \"parameters\": {\n",
    "            \"sigma\": {\n",
    "                \"widget_type\": \"slider\",\n",
    "                \"data_type\": \"float\",\n",
    "                \"min\": 0.8,\n",
    "                \"max\": 20,\n",
    "                \"increment\": 0.2\n",
    "            }\n",
    "        }\n",
    "        }\n",
    "\n",
    "# json.dumps({\"image_smoothing_gaussian_slice_by_slice\": _image_smoothing_gaussian_slice_by_slice} )\n",
    "add_function_spec_to_widget_json(\"image_smoothing_gaussian_slice_by_slice\",_image_smoothing_gaussian_slice_by_slice)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# WARNING: not a good way to set to None\n",
    "_apply_log_li_threshold = {\n",
    "        \"name\": \"threshold log Li\",\n",
    "        \"python::module\": \"infer_subc.core.img\",\n",
    "        \"python::function\": \"apply_log_li_threshold\",\n",
    "        \"parameters\": {\n",
    "            \"thresh_factor\": {\n",
    "                \"widget_type\": \"slider\",\n",
    "                \"data_type\": \"float\",\n",
    "                \"min\": 0.3,\n",
    "                \"max\": 1.1,\n",
    "                \"increment\": 0.05\n",
    "            },\n",
    "            \"thresh_min\": {\n",
    "                \"widget_type\": \"slider\",\n",
    "                \"data_type\": \"float\",\n",
    "                \"min\": 0.0,\n",
    "                \"max\": 0.8,\n",
    "                \"increment\": 0.01\n",
    "            },\n",
    "            \"thresh_max\": {\n",
    "                \"widget_type\": \"slider\",\n",
    "                \"data_type\": \"float\",\n",
    "                \"min\": 0.3,\n",
    "                \"max\": 1.0,\n",
    "                \"increment\": 0.05\n",
    "            },\n",
    "        }\n",
    "        }\n",
    "\n",
    "# json.dumps({\"apply_log_li_threshold\": _apply_log_li_threshold} )\n",
    "add_function_spec_to_widget_json(\"apply_log_li_threshold\",_apply_log_li_threshold,overwrite=True)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # NU_labels = label(nuclei_object)\n",
    "\n",
    "_label =  {\n",
    "        \"name\": \"label objects\",\n",
    "        \"python::module\": \"skimage.measure\",\n",
    "        \"python::function\": \"label\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "# json.dumps({\"label\":_label})\n",
    "add_function_spec_to_widget_json(\"label\",_label)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  nulei_object = apply_mask(nuclei_object, soma_mask)\n",
    "\n",
    "_apply_mask=  {\n",
    "        \"name\": \"apply mask\",\n",
    "        \"python::module\": \"infer_subc.core.img\",\n",
    "        \"python::function\": \"apply_mask\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "# json.dumps({\"apply_mask\":_apply_mask})\n",
    "add_function_spec_to_widget_json(\"apply_mask\",_apply_mask)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # small_object_width = 45\n",
    "    # nuclei_object = size_filter_linear_size(nuclei_object, \n",
    "    #                                                             min_size= small_object_width**2, \n",
    "    #                                                             connectivity=1)\n",
    "\n",
    "\n",
    "_size_filter_linear_size = {\n",
    "        \"name\": \"Size Filter 2D\",\n",
    "        \"python::module\": \"infer_subc.core.img\",\n",
    "        \"python::function\": \"size_filter_linear_size\",\n",
    "        \"parameters\": {\n",
    "            \"min_size\": {\n",
    "                \"widget_type\": \"slider\",\n",
    "                \"data_type\": \"int\",\n",
    "                \"min\": 0,\n",
    "                \"max\": 500,\n",
    "                \"increment\": 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "# json.dumps({  \"size_filter_linear_size\":  _size_filter_linear_size   })\n",
    "\n",
    "add_function_spec_to_widget_json(\"size_filter_linear_size\",_size_filter_linear_size)        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "## Write workflow .json\n",
    "Now that we've added our function specs we can compose workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import NUC_CH\n",
    "\n",
    "\n",
    "def make_infer_nuclei_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer nuclei from linearly unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: np.ndarray\n",
    "        a 3d image containing all the channels\n",
    "\n",
    "    soma_mask: np.ndarray\n",
    "        mask\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    nuclei_object\n",
    "        mask defined extent of NU\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "   \n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "    step_name.append(\"1\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = NUC_CH) )\n",
    "    parent.append(0)\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    # nuclei = min_max_intensity_normalization(in_img[NUC_CH].copy() )\n",
    "    step_name.append(\"2\")\n",
    "    function_name.append(\"min_max_intensity_normalization\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(1)\n",
    "\n",
    "    # size = 4   \n",
    "    # nuclei = median_filter_slice_by_slice( \n",
    "    #                                                                 nuclei,\n",
    "    #                                                                 size=size  )\n",
    "    step_name.append(\"3\")\n",
    "    function_name.append(\"median_filter_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(size = 4 ))\n",
    "    parent.append(2)\n",
    "\n",
    "    # sigma = 1.34\n",
    "    # truncate_range = 3.0\n",
    "    # nuclei = image_smoothing_gaussian_slice_by_slice(  nuclei,\n",
    "    #                                                                                             sigma=sigma,\n",
    "    #                                                                                             truncate_range = truncate_range\n",
    "    #                                                                                             )\n",
    "    step_name.append(\"4\")\n",
    "    function_name.append(\"image_smoothing_gaussian_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict( sigma = 1.34 ))\n",
    "    parent.append(3)\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # threshold_factor = 0.9 \n",
    "    # thresh_min = .1\n",
    "    # thresh_max = 1.\n",
    "    # nuclei_object = apply_log_li_threshold(nuclei, threshold_factor=threshold_factor, thresh_min=thresh_min, thresh_max=thresh_max)\n",
    "    step_name.append(\"5\")\n",
    "    function_name.append(\"apply_log_li_threshold\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(thresh_factor = 0.9, \n",
    "                                                            thresh_min = .1,\n",
    "                                                            thresh_max = 1.))\n",
    "    parent.append(4)\n",
    "\n",
    "\n",
    "    # NU_labels = label(nuclei_object)\n",
    "    step_name.append(\"6\")\n",
    "    function_name.append(\"label\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(5)\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # hole_width = 5  \n",
    "    # nuclei_object = hole_filling(nuclei_object, hole_min=0, hole_max=hole_width**2, fill_2d=True)\n",
    "    step_name.append(\"6\")\n",
    "    function_name.append(\"hole_filling\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, hole_max=5**2, fill_2d=True))\n",
    "    parent.append(5)\n",
    "\n",
    "    # # EEEEEK I don't know how to compose where the mask comes from... \n",
    "    # nuclei_object = apply_mask(nuclei_object, soma_mask)\n",
    "\n",
    "    # small_object_width = 15\n",
    "    # nuclei_object = size_filter_linear_size(nuclei_object, \n",
    "    #                                                             min_size= small_object_width**2, \n",
    "    #                                                             connectivity=1)\n",
    "    step_name.append(\"7\")\n",
    "    function_name.append(\"size_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( min_size = 15**2  ))\n",
    "    parent.append(6)\n",
    "\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.directories import Directories\n",
    "import json\n",
    "\n",
    "def _write_workflow_json(wf_name, wf_dict):\n",
    "\n",
    "    # read all_functions.json into dict\n",
    "    # if not wf_name.startswith(\"conf\"):\n",
    "    #     wf_name = f\"conf_{wf_name}\"\n",
    "    path = Directories.get_structure_config_dir() / f\"{wf_name}.json\"\n",
    "\n",
    "    # re-write file\n",
    "    with open(path, \"w\") as file:\n",
    "        json.dump(wf_dict, file, indent=4, sort_keys=False)\n",
    "\n",
    "    return path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.organelles_config.helper import write_workflow_json\n",
    "\n",
    "infer_nuclei_dict = make_infer_nuclei_dict()\n",
    "\n",
    "write_workflow_json(\"conf_2.2.nuclei_stepbystep\", infer_nuclei_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.constants import NUC_CH\n",
    "\n",
    "\n",
    "def make_infer_nuclei_from_raw_dict():\n",
    "    \"\"\"\n",
    "    Procedure to infer nuclei from linearly unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: np.ndarray\n",
    "        a 3d image containing all the channels\n",
    "\n",
    "    soma_mask: np.ndarray\n",
    "        mask\n",
    "\n",
    "    Returns\n",
    "    -------------\n",
    "    nuclei_object\n",
    "        mask defined extent of NU\n",
    "\n",
    "    \"\"\"\n",
    "    step_name = []\n",
    "    function_name = []\n",
    "    category =[]\n",
    "    parameter_values = []\n",
    "    parent = []\n",
    "   \n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################   \n",
    "\n",
    "    step_name.append(\"1\")\n",
    "    function_name.append(\"fixed_get_optimal_Z_img\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(0)\n",
    "\n",
    "\n",
    "    step_name.append(\"2\")\n",
    "    function_name.append(\"fixed_infer_cellmask_fromaggr\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( None )\n",
    "    parent.append(1)\n",
    "\n",
    "    step_name.append(\"3\")\n",
    "    function_name.append(\"select_channel_from_raw\")\n",
    "    category.append(\"extraction\")\n",
    "    parameter_values.append( dict(chan = NUC_CH) )\n",
    "    parent.append(1)\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    # nuclei = min_max_intensity_normalization(in_img[NUC_CH].copy() )\n",
    "    step_name.append(\"4\")\n",
    "    function_name.append(\"min_max_intensity_normalization\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(3)\n",
    "\n",
    "    # size = 4   \n",
    "    # nuclei = median_filter_slice_by_slice( \n",
    "    #                                                                 nuclei,\n",
    "    #                                                                 size=size  )\n",
    "    step_name.append(\"5\")\n",
    "    function_name.append(\"median_filter_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict(size = 4 ))\n",
    "    parent.append(4)\n",
    "\n",
    "    # sigma = 1.34\n",
    "    # truncate_range = 3.0\n",
    "    # nuclei = image_smoothing_gaussian_slice_by_slice(  nuclei,\n",
    "    #                                                                                             sigma=sigma,\n",
    "    #                                                                                             truncate_range = truncate_range\n",
    "    #                                                                                             )\n",
    "    step_name.append(\"6\")\n",
    "    function_name.append(\"image_smoothing_gaussian_slice_by_slice\")\n",
    "    category.append(\"preprocessing\")\n",
    "    parameter_values.append(dict( sigma = 1.34 ))\n",
    "    parent.append(5)\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    # threshold_factor = 0.9 \n",
    "    # thresh_min = .1\n",
    "    # thresh_max = 1.\n",
    "    # nuclei_object = apply_log_li_threshold(nuclei, threshold_factor=threshold_factor, thresh_min=thresh_min, thresh_max=thresh_max)\n",
    "    step_name.append(\"7\")\n",
    "    function_name.append(\"apply_log_li_threshold\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(dict(thresh_factor = 0.9, \n",
    "                                                            thresh_min = .1,\n",
    "                                                            thresh_max = 1.))\n",
    "    parent.append(6)\n",
    "\n",
    "\n",
    "    # NU_labels = label(nuclei_object)\n",
    "    step_name.append(\"8\")\n",
    "    function_name.append(\"label\")\n",
    "    category.append(\"core\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append(7)\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # hole_width = 5  \n",
    "    # nuclei_object = hole_filling(nuclei_object, hole_min=0, hole_max=hole_width**2, fill_2d=True)\n",
    "    step_name.append(\"9\")\n",
    "    function_name.append(\"hole_filling\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( hole_min=0, hole_max=5**2, fill_2d=True))\n",
    "    parent.append(8)\n",
    "\n",
    "    step_name.append(\"10\")\n",
    "    function_name.append(\"apply_mask\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(None)\n",
    "    parent.append([9,2])\n",
    "\n",
    "\n",
    "    # small_object_width = 15\n",
    "    # nuclei_object = size_filter_linear_size(nuclei_object, \n",
    "    #                                                             min_size= small_object_width**2, \n",
    "    #                                                             connectivity=1)\n",
    "    step_name.append(\"11\")\n",
    "    function_name.append(\"size_filter_linear_size\")\n",
    "    category.append(\"postprocessing\")\n",
    "    parameter_values.append(dict( min_size = 15**2  ))\n",
    "    parent.append(10)\n",
    "\n",
    "    out_dict = dict()\n",
    "    for i,stepn in enumerate(step_name):\n",
    "        entry = dict(category=category[i],\n",
    "                            function=function_name[i],\n",
    "                            parameter_values=parameter_values[i],\n",
    "                            parent=parent[i]\n",
    "        )\n",
    "        if entry['parameter_values'] is None:\n",
    "            _ = entry.pop('parameter_values')\n",
    "        out_dict[stepn] = entry\n",
    "        \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.organelles_config.helper import write_workflow_json\n",
    "\n",
    "infer_nuclei_dict = make_infer_nuclei_from_raw_dict()\n",
    "\n",
    "write_workflow_json(\"conf_1.2.nuclei_stepbystep_from_raw\", infer_nuclei_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.organelles_config.helper import add_function_spec_to_widget_json\n",
    "\n",
    "_infer_nuclei =  {\n",
    "        \"name\": \"infer infer_nuclei_fromlabel\",\n",
    "        \"python::module\": \"infer_subc.organelles\",\n",
    "        \"python::function\": \"infer_nuclei_fromlabel\",\n",
    "        \"parameters\": None\n",
    "        }\n",
    "\n",
    "add_function_spec_to_widget_json(\"infer_nuclei_fromlabel\",_infer_nuclei)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "## SUMMARY\n",
    "\n",
    "The above details how the nuclei object is inferred.  \n",
    "\n",
    "### NEXT: INFER CYTOSOL\n",
    "\n",
    "proceed to [03_infer_cytoplasm.ipynb](./03_infer_cytoplasm.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napariNEW",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6148ef1fb015fb20f0b6da2ea61c87c6b848bdf3dabb03087e5d5cd0c4607e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
