{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Intracellular Object **Distribution** - part 2.3\n",
    "--------------------\n",
    "## **OBJECTIVE**\n",
    "### <input type=\"checkbox\"/> Quantify ***distribution*** of objects within the cell\n",
    "In this notebook, the logic for quantifying cellular ***distribution*** in XY and Z is outlined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## **Organelle Distribution Measurments**\n",
    "\n",
    "### summary of steps\n",
    "\n",
    "#### **PART 1Ô∏è‚É£: XY DISTRIBUTION**\n",
    "\n",
    "> ###### üìù **Here we are refering to the XY distribution as the spread of organelles from the nucleus out to the cell membrane. This is similar to the calculations done in [CellProfiler](https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.5/modules/measurement.html?highlight=distribution#module-cellprofiler.modules.measureobjectintensitydistribution)**\n",
    "\n",
    "- **`1`** - Create sum projections (summed on Z-axis)\n",
    "\n",
    "    - Make 2D sum projection of binary segmentations (cellmask, nucleus and Golgi body) and visualize\n",
    "\n",
    "    - define prototype`_create_masked_sum_projection` function\n",
    "\n",
    "    - compare to finalized `create_masked_sum_projection` function\n",
    "\n",
    "- **`2`** - Utilize [centrosome](https://github.com/CellProfiler/centrosome) to create concentric rings centered on the nucleus\n",
    "\n",
    "    - Create a mask representative of pixel distance from the edge of the cell\n",
    "\n",
    "    - Create a mask representative of how pixels are from the center of our \"centering object\"\n",
    "\n",
    "    - Ensure that each cell has a centering object and create a final XY mask\n",
    "\n",
    "    - Combine the two representations created above to produce one normalized representation of the distance between the centering object and the edge of the cell mask\n",
    "\n",
    "    - Define prototype `_get_normalized_distance_and_mask` function\n",
    "\n",
    "    - Compare to finalized `get_normalized_distance_and_mask` function\n",
    "\n",
    "- **`3`** - Create concentric rings and wedges based on the normalized distance image created above and collect measurements of object distribution within those rings\n",
    "\n",
    "    - Create a specified number of concentric rings from the normalized distances created above\n",
    "\n",
    "    - Create radial wedges separating each bin into 8 parts\n",
    "\n",
    "    - Collect measurements from each bin, including the variance between wedges, and summarize into a table\n",
    "\n",
    "    - Summarize the distribution data into one comprehensive table\n",
    "\n",
    "    - Define prototype `_get_concentric_distribution` function\n",
    "\n",
    "    - Run `_get_concentric_distribution` function (scaled)\n",
    "\n",
    "    - Compare to finalized `get_concentric_distribution` function\n",
    "\n",
    "- **`4`** - Collect measurement about the distribution the organelles within each bin using zernike features\n",
    "\n",
    "    - Specify the number of degress to use for calculating zernike features\n",
    "\n",
    "    - Define prototype `_zernike_polynomial` function\n",
    "\n",
    "    - Compare to finalized `zernike_polynomial` function\n",
    "\n",
    "    - Collect zernike meausurements and define prototype `_zernike_metrics` function\n",
    "\n",
    "    - Compare to finalized `zernike_metrics` function\n",
    "\n",
    "    - Create summary table of zernike features\n",
    "\n",
    "    - Define prototype `_get_zernike_metics` function\n",
    "\n",
    "    - Compare to finalized `get_zernike_metics` function\n",
    "\n",
    "- **`5`** - Combine XY_distirbution and zernike measurements into one dataframe\n",
    "\n",
    "    - Define prototype of comprehensive function `get_XY_distribution`\n",
    "\n",
    "    - Compare to finalized `get_XY_distribution` function\n",
    "    \n",
    "#### **PART 2Ô∏è‚É£: Z DISTRIBUTION**\n",
    "\n",
    "> ###### **Segment image in 3D; measure area fraction of each organelle per Z slice; these measurements will act as a frequency distribution of that organelle starting from the bottom of the cellmask (not including neurites) to the top of the cellmask; measurements: mean, median, and standard deviation of the frequency distribution**\n",
    "\n",
    "- **`1`** - Sum all True pixels in each Z slices (olong the X and Y axes)\n",
    "\n",
    "    - Sum Golgi body segmentation along the X and Y axes\n",
    "\n",
    "    - Define prototype `_create_masked_depth_projection` function\n",
    "\n",
    "    - Compare to finalized `create_masked_depth_projection` function\n",
    "\n",
    "- **`2`** - Summarize the data using the bin format\n",
    "\n",
    "    - List the bins (z-slices)\n",
    "\n",
    "    - Construct the dataframe of summarized Z distribution data\n",
    "\n",
    "    - Define prototype `_get_Z_distribution` function\n",
    "\n",
    "    - Compare to finalized `get_Z_distribution` function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IMPORTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block loads all of the necessary python packages and functions you will need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import napari\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image,\n",
    "                                        import_inferred_organelle,\n",
    "                                        list_image_files)\n",
    "\n",
    "from infer_subc.core.img import *\n",
    "from infer_subc.utils.stats import *\n",
    "from infer_subc.utils.stats_helpers import *\n",
    "from infer_subc.organelles import * \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LOAD AND READ IN IMAGE FOR PROCESSING**\n",
    "> ###### üìù **Specifically, this will include the raw image and the outputs from segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F6D1; &#x270D; **User Input Required:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the path to the directory that contains the input image folder.\n",
    "data_root_path = Path(os.getcwd()).parents[1] / \"sample_data\" /  \"example_astrocyte\"\n",
    "\n",
    "## Specify which subfolder that contains the input data and what the file type is. Ex) \".czi\" or \".tiff\"\n",
    "in_data_path = data_root_path / \"raw\"\n",
    "raw_img_type = \".tiff\"\n",
    "\n",
    "## Specify which subfolder contains the segmentation outputs and their file type\n",
    "seg_data_path = data_root_path / \"seg\"\n",
    "seg_img_type = \".tiff\"\n",
    "\n",
    "## Specify the name of the output folder where quantification results will be saved\n",
    "out_data_path = data_root_path / \"quant\"\n",
    "\n",
    "# Specify which file you'd like to segment from the img_file_list\n",
    "test_img_n = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path.exists(out_data_path):\n",
    "    Path.mkdir(out_data_path)\n",
    "    print(f\"making {out_data_path}\")\n",
    "\n",
    "raw_file_list = list_image_files(in_data_path, raw_img_type)\n",
    "seg_file_list = list_image_files(seg_data_path, seg_img_type)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.DataFrame({\"Image Name\":img_file_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_img_name = raw_file_list[test_img_n]\n",
    "\n",
    "raw_img_data, raw_meta_dict = read_czi_image(raw_img_name)\n",
    "\n",
    "channel_names = raw_meta_dict['name']\n",
    "img = raw_meta_dict['metadata']['aicsimage']\n",
    "scale = raw_meta_dict['scale']\n",
    "channel_axis = raw_meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each import, change the string to match the suffix on the segmentation files (i.e., the stuff following the \"-\")\n",
    "\n",
    "# masks\n",
    "masks_seg_names = ['masks','masks_A', 'masks_B']\n",
    "for m in masks_seg_names:\n",
    "    if m in [i.stem.split(\"-\")[-1] for i in seg_file_list]:\n",
    "        mask_seg = import_inferred_organelle(m, raw_meta_dict, seg_data_path, seg_img_type)\n",
    "        nuc_seg, cell_seg, cyto_seg = mask_seg\n",
    "        break\n",
    "\n",
    "if 'nuc' in [i.stem.split(\"-\")[-1] for i in seg_file_list]:\n",
    "    nuc_seg = import_inferred_organelle(\"nuc\", raw_meta_dict, seg_data_path, seg_img_type)\n",
    "    cell_seg = import_inferred_organelle(\"cell\", raw_meta_dict, seg_data_path, seg_img_type)\n",
    "    cyto_seg = import_inferred_organelle(\"cyto\", raw_meta_dict, seg_data_path, seg_img_type)\n",
    "\n",
    "#organelles\n",
    "lyso_seg = import_inferred_organelle(\"lyso\", raw_meta_dict, seg_data_path, seg_img_type)\n",
    "mito_seg = import_inferred_organelle(\"mito\", raw_meta_dict, seg_data_path, seg_img_type)\n",
    "golgi_seg = import_inferred_organelle(\"golgi\", raw_meta_dict, seg_data_path, seg_img_type)\n",
    "perox_seg = import_inferred_organelle(\"perox\", raw_meta_dict, seg_data_path, seg_img_type)\n",
    "ER_seg = import_inferred_organelle(\"ER\", raw_meta_dict, seg_data_path, seg_img_type)\n",
    "LD_seg = import_inferred_organelle(\"LD\", raw_meta_dict, seg_data_path, seg_img_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***PART 1Ô∏è‚É£: XY DISTRIBUTION***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`1` - Create sum projections**\n",
    "\n",
    "We will create a sum projection of the cell mask, nucleus, and each object (e.g., organelle) we want to measure the distribution of. Here we are using the golgi segmentation as an example. The cell mask and nucleus will be important for creating the distribution \"bins\" that will span from the nucleus to the cell periphery.\n",
    "\n",
    "> ***Sum projection***\n",
    ">\n",
    "> A sum projection adds together the voxel intensity at each XY position to produce a single XY plane representative of the entire Z intensity.\n",
    "> Here, we will be creating sum projections of the binary segmentations, so the \"intensity\" is representative of the number of voxels at each XY position that are \"True\", or object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make 2D sum projection of binary segmentations (cellmask, nucleus and Golgi body) and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell mask and nucleus projections\n",
    "test_cell_proj = cell_seg.astype(bool).sum(axis=0)\n",
    "\n",
    "nuc_masked = apply_mask(nuc_seg.astype(bool), cell_seg.astype(bool))\n",
    "test_nuc_proj = nuc_masked.sum(axis=0)\n",
    "\n",
    "# test organelle projection\n",
    "golgi_masked = apply_mask(golgi_seg.astype(bool), cell_seg.astype(bool))\n",
    "test_golgi_proj = golgi_masked.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer= napari.Viewer()\n",
    "viewer.add_image(test_cell_proj, colormap=\"gray\")\n",
    "viewer.add_image(test_nuc_proj, colormap=\"blue\")\n",
    "viewer.add_image(test_golgi_proj, colormap=\"yellow\")\n",
    "viewer.grid.enabled = True\n",
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- define prototype`_create_masked_sum_projection` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_masked_sum_projection(img_in:np.ndarray, mask:Union[np.ndarray, None]=None, to_bool:bool=True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    img_in:\n",
    "        3D (ZYX) np.ndarray that will be summed along the Z axis\n",
    "    mask:\n",
    "        Optional - mask of the region you want to include in the final sum projection\n",
    "    to_bool:\n",
    "        True = input image is created in a boolean image before sum projection (useful for segmentation images where each object is coded as a unique ID number; like after skimage.segmentation.label())\n",
    "        False = original input image is used for the sum projection\n",
    "    \"\"\"\n",
    "    img_out = img_in.astype(bool) if to_bool else img_in\n",
    "    if mask is not None:\n",
    "        img_out = apply_mask(img_out, mask)\n",
    "    \n",
    "    return img_out.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cell_proj_a = _create_masked_sum_projection(cell_seg)\n",
    "test_nuc_proj_a = _create_masked_sum_projection(nuc_seg, cell_seg.astype(bool))\n",
    "test_golgi_proj_a = _create_masked_sum_projection(golgi_seg, cell_seg.astype(bool))\n",
    "\n",
    "np.array_equal(test_cell_proj, test_cell_proj_a), np.array_equal(test_nuc_proj, test_nuc_proj_a), np.array_equal(test_golgi_proj, test_golgi_proj_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compare to finalized `create_masked_sum_projection` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.stats import create_masked_sum_projection\n",
    "\n",
    "test_cell_proj_final = create_masked_sum_projection(cell_seg)\n",
    "\n",
    "np.array_equal(test_cell_proj, test_cell_proj_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`2` - Utilize [centrosome](https://github.com/CellProfiler/centrosome) to create concentric rings centered on the nucleus**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a mask representative of pixel distance from the edge of the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create binary images of the outer bound (cell) for creating the concentric rings\n",
    "test_labels = (test_cell_proj_a>0).astype(np.uint16)\n",
    "\n",
    "# apply a euclidian distance transform for the cellmask projection; brightness represents the distance from the edge of the cell\n",
    "test_d_to_edge = centrosome.cpmorphology.distance_to_edge(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(test_d_to_edge*255, colormap='gist_earth')\n",
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a mask representative of how pixels are from the center of our \"centering object\"\n",
    "\n",
    "> ###### üìù **Here we are using the nucleus as the centering object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this lists the pixel counts for each cell mask in the image based on the number of unique centering objects\n",
    "test_center_objects = test_nuc_proj_a>0\n",
    "test_center_labels = label(test_center_objects)\n",
    "test_pixel_counts = centrosome.cpmorphology.fixup_scipy_ndimage_result(ndi_sum(np.ones(test_center_labels.shape), \n",
    "                                                                               test_center_labels, \n",
    "                                                                               np.arange(1, np.max(test_center_labels) + 1, dtype=np.int32)))\n",
    "test_good = test_pixel_counts > 0\n",
    "\n",
    "# get the XY coordinates (i,j) of the center of the centering object (nucleus in our case)\n",
    "test_i, test_j = (centrosome.cpmorphology.centers_of_labels(test_center_labels) + 0.5).astype(int)\n",
    "test_ig = test_i[test_good]\n",
    "test_jg = test_j[test_good]\n",
    "\n",
    "test_lg = np.arange(1, len(test_i) + 1)[test_good]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the propagation labels to the center or edge of the centering object\n",
    "\n",
    "# EXEMPLE 1: propogates distances out from the EDGE of the nucleus; brightest pixels are furthest away from nucleus\n",
    "test_cl, test_d_from_center = centrosome.propagate.propagate(np.zeros(test_center_labels.shape), test_center_labels, test_labels != 0, 1)\n",
    "test_cl[test_labels == 0] = 0\n",
    "\n",
    "\n",
    "# EXAMPLE 2: propogates distances out from the CENTER of the nucleus; brightest pixels are furthest away from nucleus\n",
    "# True = use center of centering to start bin creation; \n",
    "# False = use edge of centering object to propogate bins out\n",
    "test_center_on_nuc = True \n",
    "if test_center_on_nuc:\n",
    "    test_center_labels_center = np.zeros(test_center_labels.shape, int)\n",
    "    test_center_labels_center[test_ig, test_jg] = test_lg\n",
    "\n",
    "\n",
    "test_cl_center, test_d_from_center_center = centrosome.propagate.propagate(np.zeros(test_center_labels_center.shape), test_center_labels_center, test_labels != 0, 1)\n",
    "test_cl_center[test_labels == 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(test_d_from_center_center, colormap='gist_earth')\n",
    "viewer.add_image(test_d_from_center, colormap='gist_earth')\n",
    "viewer.grid.enabled = True\n",
    "viewer.reset_view()\n",
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensure that each cell has a centering object and create a final XY mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for missing centering objects within the cell mask; most important when there are more than one object (cell) in the image\n",
    "test_missing_mask = (test_labels != 0) & (test_cl == 0)\n",
    "test_missing_labels = np.unique(test_labels[test_missing_mask])\n",
    "\n",
    "if len(test_missing_labels):\n",
    "            print(\"WTF!!  how did we have missing labels?\")\n",
    "            test_all_centers = centrosome.cpmorphology.centers_of_labels(test_labels)\n",
    "            test_missing_i_centers, test_missing_j_centers = test_all_centers[:, test_missing_labels-1]\n",
    "            test_di = test_missing_i_centers[:, np.newaxis] - test_ig[np.newaxis, :]\n",
    "            test_dj = test_missing_j_centers[:, np.newaxis] - test_jg[np.newaxis, :]\n",
    "            test_missing_best = test_lg[np.argsort(test_di * test_di + test_dj * test_dj)[:, 0]]\n",
    "            test_best = np.zeros(np.max(test_labels) + 1, int)\n",
    "            test_best[test_missing_labels] = test_missing_best\n",
    "            test_cl[test_missing_mask] = test_best[test_labels[test_missing_mask]]\n",
    "\n",
    "            # Now compute the crow-flies distance to the centers of these pixels from whatever center was assigned to the object.\n",
    "            test_iii, test_jjj = np.mgrid[0 : test_labels.shape[0], 0 : test_labels.shape[1]]\n",
    "            test_di = test_iii[test_missing_mask] - test_i[test_cl[test_missing_mask] - 1]\n",
    "            test_dj = test_jjj[test_missing_mask] - test_j[test_cl[test_missing_mask] - 1]\n",
    "            test_d_from_center[test_missing_mask] = np.sqrt(test_di * test_di + test_dj * test_dj)\n",
    "\n",
    "# create the projection cell mask that appropriately includes a centering cell mask\n",
    "test_good_mask = test_cl > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Combine the two representations created above to produce one normalized representation of the distance between the centering object and the edge of the cell mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an object equal to the cellmask_proj with all pixel values equal to the X coordinate value (here called 'i') or Y coordinate (here called 'j')\n",
    "# then creating normalized distance out from center to edge of cell\n",
    "test_i_center = np.zeros(test_cl.shape)\n",
    "test_i_center[test_good_mask] = test_i[test_cl[test_good_mask] - 1]\n",
    "\n",
    "test_j_center = np.zeros(test_cl.shape)\n",
    "test_j_center[test_good_mask] = test_j[test_cl[test_good_mask] - 1]\n",
    "\n",
    "test_normalized_distance = np.zeros(test_labels.shape) # creat an empty array\n",
    "test_total_distance = test_d_from_center + test_d_to_edge # add the two distance arrays together\n",
    "test_normalized_distance[test_good_mask] = test_d_from_center[test_good_mask] / (test_total_distance[test_good_mask] + 0.001)\n",
    "\n",
    "\n",
    "# EXAMPLE 2A: INCLUDES the centering object after distances are propogate out from the CENTER of the centering object\n",
    "test_i_center_center = np.zeros(test_cl_center.shape)\n",
    "test_i_center_center[test_good_mask] = test_i[test_cl_center[test_good_mask] - 1]\n",
    "\n",
    "test_j_center_center = np.zeros(test_cl_center.shape)\n",
    "test_j_center_center[test_good_mask] = test_j[test_cl_center[test_good_mask] - 1]\n",
    "\n",
    "test_normalized_distance_center = np.zeros(test_labels.shape)\n",
    "test_total_distance_center = test_d_from_center_center + test_d_to_edge \n",
    "test_normalized_distance_center[test_good_mask] = test_d_from_center_center[test_good_mask] / ( test_total_distance_center[test_good_mask] + 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(test_normalized_distance_center, colormap='gist_earth')\n",
    "viewer.add_image(test_normalized_distance, colormap='gist_earth')\n",
    "viewer.reset_view()\n",
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define prototype `_get_normalized_distance_and_mask` function\n",
    "\n",
    "###### Combine all of the above code into a function to define the normalized distances from the centering object to the edge of the cell mask and create a final projection cell mask to use downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_normalized_distance_and_mask(labels: np.ndarray, \n",
    "                                      center_objects: Union[np.ndarray, None], \n",
    "                                      center_on: bool):\n",
    "    \"\"\"\n",
    "    helper for radial distribution\n",
    "    Parameters:\n",
    "    ----------\n",
    "    labels:\n",
    "        2D (YX) np.ndarray - normally the result of a binary ZYX segmentation of the cell mask after a sum projection across the Z dimension\n",
    "    center_object:\n",
    "        2D (YX) np.ndarray - normally the result of a binary ZYX segmentation of the nucleus after a sum projection across the Z dimension.\n",
    "        If no centering object is included, the center of the labels will be used.\n",
    "    center_on:\n",
    "        True = the center of the centering object will be used as the starting point to calculate the distance from the center\n",
    "        False = the edge of the centering object will be used as the starting point to calculate the distance from the center\n",
    "    \n",
    "    Output:\n",
    "    ----------\n",
    "    normalized_distance:\n",
    "        2D (YX) np.ndarray with intensity values representing the distance btween the edge of the \"labels\" and the centering object\n",
    "    good_mask:\n",
    "        mask of the areas that were included in the normalized_distance output\n",
    "    i_center\n",
    "    j_center\n",
    "    \"\"\"\n",
    "\n",
    "    d_to_edge = centrosome.cpmorphology.distance_to_edge(labels)\n",
    "\n",
    "    if center_objects is not None:\n",
    "        center_labels = label(center_objects)\n",
    "        pixel_counts = centrosome.cpmorphology.fixup_scipy_ndimage_result(ndi_sum(np.ones(center_labels.shape), \n",
    "                                                                                  center_labels, \n",
    "                                                                                  np.arange(1, np.max(center_labels) + 1, dtype=np.int32)))\n",
    "        good = pixel_counts > 0\n",
    "        i, j = (centrosome.cpmorphology.centers_of_labels(center_labels) + 0.5).astype(int)\n",
    "        ig = i[good]\n",
    "        jg = j[good]\n",
    "        lg = np.arange(1, len(i) + 1)[good]\n",
    "        \n",
    "        if center_on:  # Reduce the propagation labels to the centers of the centering objects\n",
    "            center_labels = np.zeros(center_labels.shape, int)\n",
    "            center_labels[ig, jg] = lg\n",
    "\n",
    "        cl, d_from_center = centrosome.propagate.propagate(np.zeros(center_labels.shape), center_labels, labels != 0, 1)\n",
    "        cl[labels == 0] = 0\n",
    "\n",
    "        missing_mask = (labels != 0) & (cl == 0)\n",
    "        missing_labels = np.unique(labels[missing_mask])\n",
    "        \n",
    "        if len(missing_labels):\n",
    "            print(\"WTF!!  how did we have missing labels?\")\n",
    "            all_centers = centrosome.cpmorphology.centers_of_labels(labels)\n",
    "            missing_i_centers, missing_j_centers = all_centers[:, missing_labels-1]\n",
    "            di = missing_i_centers[:, np.newaxis] - ig[np.newaxis, :]\n",
    "            dj = missing_j_centers[:, np.newaxis] - jg[np.newaxis, :]\n",
    "            missing_best = lg[np.argsort(di * di + dj * dj)[:, 0]]\n",
    "            best = np.zeros(np.max(labels) + 1, int)\n",
    "            best[missing_labels] = missing_best\n",
    "            cl[missing_mask] = best[labels[missing_mask]]\n",
    "\n",
    "            iii, jjj = np.mgrid[0 : labels.shape[0], 0 : labels.shape[1]]\n",
    "            di = iii[missing_mask] - i[cl[missing_mask] - 1]\n",
    "            dj = jjj[missing_mask] - j[cl[missing_mask] - 1]\n",
    "            d_from_center[missing_mask] = np.sqrt(di * di + dj * dj)\n",
    "\n",
    "        good_mask = cl > 0\n",
    "            \n",
    "    else:\n",
    "        i, j = centrosome.cpmorphology.maximum_position_of_labels(d_to_edge, labels, [1])\n",
    "        center_labels = np.zeros(labels.shape, int)\n",
    "        center_labels[i, j] = labels[i, j]\n",
    "        colors = centrosome.cpmorphology.color_labels(labels)\n",
    "        ncolors = np.max(colors)\n",
    "        d_from_center = np.zeros(labels.shape)\n",
    "        cl = np.zeros(labels.shape, int)\n",
    "\n",
    "        for color in range(1, ncolors + 1):\n",
    "            mask = colors == color\n",
    "            l, d = centrosome.propagate.propagate( np.zeros(center_labels.shape), center_labels, mask, 1)\n",
    "            d_from_center[mask] = d[mask]\n",
    "            cl[mask] = l[mask]\n",
    "\n",
    "        good_mask = cl > 0\n",
    "\n",
    "    i_center = np.zeros(cl.shape)\n",
    "    i_center[good_mask] = i[cl[good_mask] - 1]\n",
    "\n",
    "    j_center = np.zeros(cl.shape)\n",
    "    j_center[good_mask] = j[cl[good_mask] - 1]\n",
    "\n",
    "    normalized_distance = np.zeros(labels.shape)\n",
    "    total_distance = d_from_center + d_to_edge\n",
    "    normalized_distance[good_mask] = d_from_center[good_mask] / (total_distance[good_mask] + 0.001)\n",
    "    \n",
    "    return normalized_distance, good_mask, i_center, j_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_normalized_distance_a, test_good_mask_a, test_i_center_a, test_j_center_a = _get_normalized_distance_and_mask(labels=test_labels,\n",
    "                                                                                                                  center_objects=test_center_objects,\n",
    "                                                                                                                  center_on=False)\n",
    "\n",
    "np.array_equal(test_normalized_distance, test_normalized_distance_a), np.array_equal(test_good_mask, test_good_mask_a), np.array_equal(test_i_center, test_i_center_a), np.array_equal(test_j_center, test_j_center_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare to finalized `get_normalized_distance_and_mask` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.stats import get_normalized_distance_and_mask\n",
    "\n",
    "test_normalized_distance_final, test_good_mask_final, test_i_center_final, test_j_center_final = get_normalized_distance_and_mask(labels=test_labels,\n",
    "                                                                                                                  center_objects=test_center_objects,\n",
    "                                                                                                                  center_on=False)\n",
    "\n",
    "np.array_equal(test_normalized_distance, test_normalized_distance_final), np.array_equal(test_good_mask, test_good_mask_final), np.array_equal(test_i_center, test_i_center_final), np.array_equal(test_j_center, test_j_center_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`3` - Create concentric rings and wedges based on the normalized distance image created above and collect measurements of object distribution within those rings**\n",
    "\n",
    "The concentric rings (based on the normalized_distribution output above) will be our main \"bins\" to measure from. The wedges will divide each bin equally into 8 parts radiall (think pie slices out from the center of the centering object).\n",
    "\n",
    "See similar concept in [CellProfiler](https://cellprofiler-manual.s3.amazonaws.com/CellProfiler-4.2.5/modules/measurement.html?highlight=distribution#module-cellprofiler.modules.measureobjectintensitydistribution)\t\n",
    "   \n",
    "\n",
    "> ###### üìù **The logic was borrowed from CellProfiler, but alorithm somewhate simplified by making assumpitions of doing all estimates over a single cellmask (single cell).   Most of the code should be capable of performing the more complicated multi-object versions as CellProfiler does.  Although this functionality is untested the source code was left in this more complex format in case it might be updated for this functionality in the future**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a specified number of concentric rings from the normalized distances created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to divide the cell area into 5 bins taking into account our center_on and keep_center_as_bin choices above\n",
    "test_bin_count = 5\n",
    "\n",
    "# determine if you want to include the centering object as part of the area to measure distribution from or not\n",
    "test_keep_center_asbin = True\n",
    "\n",
    "test_good_mask_noNUC = test_good_mask_a>0\n",
    "test_good_mask_noNUC[test_center_objects] = 0\n",
    "\n",
    "\n",
    "# EXAMPLE 1A: centering object INCLUDED and distances from the EDGE\n",
    "test_bin_indexes = ((test_normalized_distance * (test_bin_count-1))+1).astype(int)\n",
    "test_bin_indexes[test_center_objects]=0\n",
    "test_bin_indexes[~test_good_mask]=0\n",
    "\n",
    "# # EXAMPLE 1B: centering object EXCLUDED and distances from the EDGE\n",
    "test_bin_indexes_noNUC = (test_normalized_distance * test_bin_count).astype(int)\n",
    "\n",
    "# # EXAMPLE 2A: centering object INCLUDED and distances from the CENTER\n",
    "test_bin_indexes_center = (test_normalized_distance_center * test_bin_count).astype(int) \n",
    "\n",
    "# # EXAMPLE 2B: centering object EXCLUDED and distances from the CENTER\n",
    "test_normalized_distance_normed = np.zeros_like(test_normalized_distance_center)\n",
    "test_normalized_distance_normed[test_good_mask_noNUC] = (test_normalized_distance_center[test_good_mask_noNUC] - test_normalized_distance_center[test_good_mask_noNUC].min())/(test_normalized_distance_center[test_good_mask_noNUC].max() - test_normalized_distance_center[test_good_mask_noNUC].min())\n",
    "\n",
    "test_bin_indexes_noNUC_center = (test_normalized_distance_normed * test_bin_count).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.add_image(test_bin_indexes_noNUC, colormap='red')\n",
    "viewer.add_image(test_bin_indexes, colormap='green')\n",
    "viewer.add_image(test_bin_indexes_noNUC_center, colormap='cyan') # as an example of what this looks like\n",
    "viewer.add_image(test_bin_indexes_center, colormap='magenta')\n",
    "viewer.grid.enabled = True\n",
    "viewer.reset_view()\n",
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create radial wedges separating each bin into 8 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting radial index for each pixel to create 8 wedges from center of centering object\n",
    "test_i, test_j = np.mgrid[0 : test_labels.shape[0], 0 : test_labels.shape[1]] # intensity gradients of pixels in X (top to bottom) and then Y (left to right)\n",
    "test_imask = test_i[test_good_mask] > test_i_center[test_good_mask]\n",
    "test_jmask = test_j[test_good_mask] > test_j_center[test_good_mask]\n",
    "test_absmask = abs(test_i[test_good_mask] - test_i_center[test_good_mask]) > abs(test_j[test_good_mask] - test_j_center[test_good_mask])\n",
    "test_radial_index = (test_imask.astype(int) + test_jmask.astype(int) * 2 + test_absmask.astype(int) * 4)\n",
    "\n",
    "test_radial_index_vis = np.zeros_like(test_good_mask, dtype=int)\n",
    "test_radial_index_vis[test_good_mask] = test_radial_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers.clear()\n",
    "viewer.grid.enabled = True\n",
    "viewer.add_image(test_good_mask + test_radial_index_vis)\n",
    "viewer.reset_view()\n",
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Collect measurements from each bin, including the variance between wedges, and summarize into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These measurements are only using the bins created from the edge of the centerin object and including the centering object area\n",
    "# number of pixels in the good mask\n",
    "test_ngood_pixels = np.sum(test_good_mask)\n",
    "\n",
    "test_good_labels = test_labels[test_good_mask]\n",
    "test_labels_and_bins = (test_good_labels - 1, test_bin_indexes[test_good_mask])\n",
    "test_nobjects = 1\n",
    "\n",
    "# get count of voxels in each bin from the following images\n",
    "test_histogram_cmsk = coo_matrix((test_cell_proj_a[test_good_mask], test_labels_and_bins), shape=(test_nobjects, test_bin_count)).toarray().squeeze().tolist()\n",
    "test_histogram_org = coo_matrix((test_golgi_proj_a[test_good_mask], test_labels_and_bins), shape=(test_nobjects, test_bin_count)).toarray().squeeze().tolist()\n",
    "test_histogram_center = coo_matrix((test_nuc_proj_a[test_good_mask], test_labels_and_bins), shape=(test_nobjects, test_bin_count)).toarray().squeeze().tolist()\n",
    "\n",
    "# QC: total voxel counts for the entire object\n",
    "# test_sum_by_object_cmsk = np.sum(test_histogram_cmsk, 1) # cell mask voxel count\n",
    "# test_sum_by_object_org = np.sum(test_histogram_org, 1)  # organelle voxel count\n",
    "# test_sum_by_object_nuc = np.sum(test_histogram_center, 1)  # nucleus voxel count\n",
    "\n",
    "# same concept, but with an empty array to calculate the number of pixels per bin\n",
    "test_pxl_per_bin = coo_matrix((np.ones(test_ngood_pixels), test_labels_and_bins), (test_nobjects, test_bin_count)).toarray().squeeze().tolist()\n",
    "test_total_pxls = np.sum(test_pxl_per_bin) # total pixels in the mask; QC: should equal the XY mask area\n",
    "\n",
    "# get the proportion of pixels in each bin (*100 to get percentage of cell pixels per bin)\n",
    "test_total_pixels_repeated = np.dstack([test_total_pxls] * (test_bin_count))[0]\n",
    "test_portion_of_total_mask_pxls = test_pxl_per_bin / test_total_pixels_repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeating the calculations above using the wedges instead of the bins\n",
    "test_labels_and_wedges = (test_good_labels - 1, test_radial_index_vis[test_good_mask])\n",
    "\n",
    "test_wedge_histogram_cmsk = coo_matrix((test_cell_proj_a[test_good_mask], test_labels_and_wedges), shape=(test_nobjects, 8)).toarray().squeeze().tolist()\n",
    "test_wedge_histogram_org = coo_matrix((test_golgi_proj_a[test_good_mask], test_labels_and_wedges), shape=(test_nobjects, 8)).toarray().squeeze().tolist()\n",
    "test_wedge_histogram_center = coo_matrix((test_nuc_proj_a[test_good_mask], test_labels_and_wedges), shape=(test_nobjects, 8)).toarray().squeeze().tolist()\n",
    "\n",
    "test_pxl_per_wedge = coo_matrix((np.ones(test_ngood_pixels), test_labels_and_wedges), (test_nobjects, 8)).toarray().squeeze().tolist()\n",
    "test_total_pxls_perwedge = np.sum(test_pxl_per_wedge) \n",
    "\n",
    "test_total_pixels_repeated_perwedge = np.dstack([test_total_pxls_perwedge] * (8))[0]\n",
    "test_portion_of_total_mask_pxls_perwedge = test_pxl_per_wedge / test_total_pixels_repeated_perwedge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_portion_of_total_mask_pxls_perwedge.squeeze().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting per bin measurements info\n",
    "test_bin_names =[]\n",
    "test_cv_cmsk = []\n",
    "test_cv_obj = []\n",
    "test_cv_center = []\n",
    "test_cmsk_wedge_perbin = []\n",
    "test_obj_wedge_perbin = []\n",
    "test_center_wedge_perbin = []\n",
    "test_pxl_cnt_wedge_perbin = []\n",
    "test_wedges_perbin = []\n",
    "\n",
    "for bin in range(test_bin_count):\n",
    "    test_bin_mask = test_good_mask & (test_bin_indexes == bin) # selecting the bin as a mask\n",
    "    test_bin_pixels = np.sum(test_bin_mask) # number of pixels in this bin for downstream calculations\n",
    "\n",
    "    test_bin_labels = test_labels[test_bin_mask] # selecting portion of the cellmask within this bin\n",
    "\n",
    "    test_bin_radial_index = test_radial_index[test_bin_indexes[test_good_mask] == bin] # selecting the portion of the wedges associated to this bin\n",
    "    test_labels_and_radii = (test_bin_labels - 1, test_bin_radial_index) # (i,j) for coo_matrix function taking into account the 8 wedges within this bin\n",
    "    test_pixel_count = coo_matrix((np.ones(test_bin_pixels), test_labels_and_radii), (test_nobjects, 8) ).toarray() # I think this is getting the number of pixels in each wedge\n",
    "\n",
    "    test_radial_counts_cmsk = coo_matrix((test_cell_proj_a[test_bin_mask], test_labels_and_radii), (test_nobjects, 8) ).toarray() # amount of cell mask voxels per wedge in this bin\n",
    "    test_radial_counts_obj = coo_matrix((test_golgi_proj_a[test_bin_mask], test_labels_and_radii), (test_nobjects, 8) ).toarray() # amount of object voxels per wedges in this bin\n",
    "    test_radial_counts_center = coo_matrix((test_nuc_proj_a[test_bin_mask], test_labels_and_radii), (test_nobjects, 8) ).toarray() # amount of centering object voxels per wedges in this bin\n",
    "\n",
    "    # safe gaurd against one of the wedges having an area of 0\n",
    "    # np.ma.masked_array - \"Masked values of True exclude the corresponding element from any computation.\"\n",
    "    test_mask = test_pixel_count == 0\n",
    "\n",
    "    test_radial_cmsk_norm = np.ma.masked_array(test_radial_counts_cmsk / test_pixel_count, test_mask)\n",
    "    test_radial_cv_cmsk = np.std(test_radial_cmsk_norm, 1) / np.mean(test_radial_cmsk_norm, 1)\n",
    "    test_radial_cv_cmsk[np.sum(~test_mask, 1) == 0] = 0\n",
    "    test_radial_cv_cmsk.mask = np.sum(~test_mask, 1) == 0\n",
    "\n",
    "    test_radial_obj_norm = np.ma.masked_array(test_radial_counts_obj / test_pixel_count, test_mask)\n",
    "    test_radial_cv_obj = np.std(test_radial_obj_norm, 1) / np.mean(test_radial_obj_norm, 1)\n",
    "    test_radial_cv_obj[np.sum(~test_mask, 1) == 0] = 0\n",
    "    test_radial_cv_obj.mask = np.sum(~test_mask, 1) == 0\n",
    "\n",
    "    test_radial_center_norm = np.ma.masked_array(test_radial_counts_center / test_pixel_count, test_mask)\n",
    "    test_radial_cv_center = np.std(test_radial_center_norm, 1) / np.mean(test_radial_center_norm, 1)\n",
    "    test_radial_cv_center[np.sum(~test_mask, 1) == 0] = 0\n",
    "    test_radial_cv_center.mask = np.sum(~test_mask, 1) == 0\n",
    "\n",
    "    test_bin_name = bin + 1 if bin > 0 else 1\n",
    "    test_wedges_name = np.ma.masked_array([it+1 for it in range(8)])\n",
    "\n",
    "    test_bin_names.append(test_bin_name)\n",
    "    test_cv_cmsk.append(float(np.mean(test_radial_cv_cmsk)))  #convert to float to make importing from csv more straightforward\n",
    "    test_cv_obj.append(float(np.mean(test_radial_cv_obj)))\n",
    "    test_cv_center.append(float(np.mean(test_radial_cv_center)))\n",
    "    test_cmsk_wedge_perbin.append(test_radial_counts_cmsk.squeeze().tolist())\n",
    "    test_obj_wedge_perbin.append(test_radial_counts_obj.squeeze().tolist())\n",
    "    test_center_wedge_perbin.append(test_radial_counts_center.squeeze().tolist())\n",
    "    test_pxl_cnt_wedge_perbin.append(test_pixel_count.squeeze().tolist())\n",
    "    test_wedges_perbin.append(test_wedges_name.data.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summarize the distribution data into one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_org_name = 'golgi'\n",
    "\n",
    "test_stat_tab=pd.DataFrame({'object': test_org_name,\n",
    "                            'XY_n_bins': test_bin_count,\n",
    "                            'XY_bins': [test_bin_names],\n",
    "                            'XY_mask_vox_cnt_perbin': [test_histogram_cmsk],\n",
    "                            'XY_obj_vox_cnt_perbin': [test_histogram_org],\n",
    "                            'XY_center_vox_cnt_perbin': [test_histogram_center],\n",
    "                            'XY_n_pix_perbin': [test_pxl_per_bin],\n",
    "                            'XY_portion_pix_perbin': [test_portion_of_total_mask_pxls.squeeze().tolist()],\n",
    "                            'XY_n_wedges': 8,\n",
    "                            'XY_wedges': str([it+1 for it in range(8)]),\n",
    "                            'XY_mask_vox_cnt_perwedge': [test_wedge_histogram_cmsk],\n",
    "                            'XY_obj_vox_cnt_perwedge': [test_wedge_histogram_org],\n",
    "                            'XY_center_vox_cnt_perwedge': [test_wedge_histogram_center],\n",
    "                            'XY_n_pix_perwedge': [test_pxl_per_wedge],\n",
    "                            'XY_portion_pix_perwedge': [test_portion_of_total_mask_pxls_perwedge.squeeze().tolist()],\n",
    "                            'XY_wedges_perbin': [test_wedges_perbin],\n",
    "                            'XY_mask_vox_cnt_wedges_perbin':[test_cmsk_wedge_perbin],\n",
    "                            'XY_obj_vox_cnt_wedges_perbin':[test_obj_wedge_perbin],\n",
    "                            'XY_center_vox_cnt_wedges_perbin': [test_center_wedge_perbin],\n",
    "                            'XY_n_pix_wedges_perbin': [test_pxl_cnt_wedge_perbin],\n",
    "                            'XY_mask_cv_perbin':[test_cv_cmsk],\n",
    "                            'XY_obj_cv_perbin':[test_cv_obj],\n",
    "                            'XY_center_cv_perbin': [test_cv_center]\n",
    "                            })\n",
    "\n",
    "# measurements affected by scale\n",
    "##### volume #####\n",
    "test_vol_mets = ['XY_mask_vox_cnt_perbin',\n",
    "            'XY_obj_vox_cnt_perbin',\n",
    "            'XY_center_vox_cnt_perbin',\n",
    "            'XY_mask_vox_cnt_perwedge',\n",
    "            'XY_obj_vox_cnt_perwedge',\n",
    "            'XY_center_vox_cnt_perwedge',\n",
    "            'XY_mask_vox_cnt_wedges_perbin',\n",
    "            'XY_obj_vox_cnt_wedges_perbin',\n",
    "            'XY_center_vox_cnt_wedges_perbin']\n",
    "\n",
    "##### area #####\n",
    "test_area_mets = ['XY_n_pix_perbin',\n",
    "             'XY_n_pix_perwedge',\n",
    "             'XY_n_pix_wedges_perbin']\n",
    "\n",
    "\"\"\" \n",
    "Measurements\n",
    "------------\n",
    "If scale is used, \"vox_cnt\" is replaced by \"vol\" and \"n_pix_ is replaced by \"area\" in the title below.\n",
    "\n",
    "object: the nickname of what is being measured (e.g., golgi, golgiXER, ER_img)\n",
    "XY_n_bins: number of bins\n",
    "XY_bins: list of bin number\n",
    "XY_mask_vox_cnt_perbin: number of voxels in the 3D cell mask per bin\n",
    "XY_obj_vox_cnt_perbin: number of voxels of the 3D object per bin\n",
    "XY_center_vox_cnt_perbin: number of voxels of the 3D centering object per bin\n",
    "XY_n_pix_perbin: number of pixels per bin in the XY mask\n",
    "XY_portion_pix_perbin: the portion of pixels in the XY mask per bin\n",
    "XY_n_wedges: number of wedges\n",
    "XY_wedges: list of wedge numbers\n",
    "XY_mask_vox_cnt_perwedge: number of voxels in the 3D cell mask per wedge\n",
    "XY_obj_vox_cnt_perwedge: number of voxels of the 3D object per wedge\n",
    "XY_center_vox_cnt_perwedge: number of voxels of the 3D centering object per wedge\n",
    "XY_n_pix_perwedge: number of pixels per wedge in the XY mask\n",
    "XY_portion_pix_perwedge: the portion of pixels in the XY mask per bin\n",
    "XY_wedges_perbin: list of wedges that have >0 pixels in the mask for all bins\n",
    "XY_mask_vox_cnt_wedges_perbin: number of voxels in the 3D cell mask per wedge per bin\n",
    "XY_obj_vox_cnt_wedges_perbin:number of voxels of the 3D object per wedge per bin\n",
    "XY_center_vox_cnt_wedges_perbin: number of voxels of the 3D centering object per wedge per bin\n",
    "XY_n_pix_wedges_perbin: number of pixels per wedge per bin in the XY mask\n",
    "XY_mask_cv_perbin: the coefficient of variance of the wedges within each bin for the mask\n",
    "XY_obj_cv_perbin: the coefficient of variance of the wedges within each bin for the object segmentation\n",
    "XY_center_cv_perbin: the coefficient of variance of the wedges within each bin for the centering object\n",
    "\"\"\"\n",
    "\n",
    "if scale is not None:\n",
    "    round_scale = (round(scale[0], 4), round(scale[1], 4), round(scale[2], 4))\n",
    "    test_stat_tab.insert(loc=1, column=\"scale\", value=f\"{round_scale}\")\n",
    "\n",
    "    for met in test_vol_mets:\n",
    "        test_stat_tab[met.replace('_vox_cnt_', \"_vol_\")] = [(np.float_(test_stat_tab[met][0]) * np.prod(scale)).squeeze().tolist()]\n",
    "    \n",
    "    for met in test_area_mets:\n",
    "        test_stat_tab[met.replace('_n_pix_', \"_area_\")] = [(np.float_(test_stat_tab[met][0]) * np.prod(scale[1:])).squeeze().tolist()]\n",
    "\n",
    "else: \n",
    "    test_stat_tab.insert(loc=2, column=\"scale\", value=f\"{tuple(np.ones(3))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stat_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define prototype `_get_concentric_distribution` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_concentric_distribution(\n",
    "        mask_proj: np.ndarray,\n",
    "        centering_proj: np.ndarray,\n",
    "        obj_proj: np.ndarray,\n",
    "        obj_name: str,\n",
    "        bin_count: int,\n",
    "        center_on: bool = False,\n",
    "        keep_center_as_bin: bool = True,\n",
    "        scale: Union[tuple, None]=None):\n",
    "    \"\"\"\n",
    "    Based on CellProfiler's measureobjectintensitydistribution. Measure the distribution of segmented objects within a masked area. \n",
    "    In our case, we will usually utilize this function to measure the amount of an organelle within the cell.\n",
    "    Radial bins are created out from a center point, usually the nucleus edge.\n",
    "\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    mask_proj: np.ndarray\n",
    "        a sum projection of the region you want to measure the distribution from where the \"intensity\" value of each pixel is equal \n",
    "        to the number of z slices where the binary cell mask is True\n",
    "    centering_proj: np.ndarray\n",
    "        a sum projection of the object you want to use as the center of the distribution where the \"intensity\" value of each pixel is \n",
    "        equal to the number of z slices where the binary nucleus mask is True\n",
    "    obj_proj: np.ndarray,\n",
    "        a sum projection of the stuff you want to measure where the \"intensity\" value of each pixel is equal to the number of z slices \n",
    "        where the binary organelle mask is True (for a segmented image) or the total intensity at that point (for a gray scale image)\n",
    "    obj_name: str,\n",
    "        the name or nickname of your object being measured; used for labeling columns in the dataframe\n",
    "    bin_count: int,\n",
    "        the number of concentric rings, or \"bins\", to create within the mask\n",
    "    center_on: bool = False,\n",
    "        True = distribute the bins from the center of the centering object\n",
    "        False = distribute the bins from the edge of the centering object\n",
    "    keep_center_as_bin: bool = True\n",
    "        True = include the centering object area when creating the bins\n",
    "        False = do not include the centering object area when creating the bins\n",
    "    scale: Union[tuple, None]=None\n",
    "        a tuple of floats representing the real-world dimensions for each image dimension (ZYX)\n",
    "        \n",
    "\n",
    "    Measurements\n",
    "    ------------\n",
    "    If scale is used, \"vox_cnt\" is replaced by \"vol\" and \"n_pix_ is replaced by \"area\" in the title below.\n",
    "\n",
    "    object: the nickname of what is being measured (e.g., golgi, golgiXER, ER_img)\n",
    "    XY_n_bins: number of bins\n",
    "    XY_bins: list of bin number\n",
    "    XY_mask_vox_cnt_perbin: number of voxels in the 3D cell mask per bin\n",
    "    XY_obj_vox_cnt_perbin: number of voxels of the 3D object per bin\n",
    "    XY_center_vox_cnt_perbin: number of voxels of the 3D centering object per bin\n",
    "    XY_n_pix_perbin: number of pixels per bin in the XY mask\n",
    "    XY_portion_pix_perbin: the portion of pixels in the XY mask per bin\n",
    "    XY_n_wedges: number of wedges\n",
    "    XY_wedges: list of wedge numbers\n",
    "    XY_mask_vox_cnt_perwedge: number of voxels in the 3D cell mask per wedge\n",
    "    XY_obj_vox_cnt_perwedge: number of voxels of the 3D object per wedge\n",
    "    XY_center_vox_cnt_perwedge: number of voxels of the 3D centering object per wedge\n",
    "    XY_n_pix_perwedge: number of pixels per wedge in the XY mask\n",
    "    XY_portion_pix_perwedge: the portion of pixels in the XY mask per bin\n",
    "    XY_wedges_perbin: list of wedges that have >0 pixels in the mask for all bins\n",
    "    XY_mask_vox_cnt_wedges_perbin: number of voxels in the 3D cell mask per wedge per bin\n",
    "    XY_obj_vox_cnt_wedges_perbin:number of voxels of the 3D object per wedge per bin\n",
    "    XY_center_vox_cnt_wedges_perbin: number of voxels of the 3D centering object per wedge per bin\n",
    "    XY_n_pix_wedges_perbin: number of pixels per wedge per bin in the XY mask\n",
    "    XY_mask_cv_perbin: the coefficient of variance of the wedges within each bin for the mask\n",
    "    XY_obj_cv_perbin: the coefficient of variance of the wedges within each bin for the object segmentation\n",
    "    XY_center_cv_perbin: the coefficient of variance of the wedges within each bin for the centering object\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    tab: (pd.DataFrame) table of measurements of the object distribution\n",
    "    bin_array: (np.ndarray) mask of the concentric rings to measure distribution from\n",
    "    wedge_array: (np.ndarray) mask of the wedges (pie slices) that divide each bin into 8 parts\n",
    "    \"\"\"\n",
    "    # other parameters that will stay constant\n",
    "    nobjects = 1\n",
    "\n",
    "    # create binary arrays\n",
    "    center_objects = centering_proj>0 \n",
    "    mask = (mask_proj>0).astype(np.uint16)\n",
    "\n",
    "\n",
    "    ################   ################\n",
    "    ## compute distances and make bins and wedges masks\n",
    "    ################   ################\n",
    "    # created normalized distances\n",
    "    normalized_distance, good_mask, i_center, j_center = get_normalized_distance_and_mask(labels=mask, center_objects=center_objects, center_on=center_on)\n",
    "    if normalized_distance is None:\n",
    "        print('WTF!!  normalized_distance returned wrong')\n",
    "\n",
    "    # create bin mask array\n",
    "    if keep_center_as_bin:\n",
    "        if center_on:\n",
    "            bin_array = (normalized_distance * bin_count).astype(int)\n",
    "        else:\n",
    "            bin_array= ((normalized_distance * (bin_count-1))+1).astype(int)\n",
    "            bin_array[center_objects]=0\n",
    "            bin_array[~good_mask]=0\n",
    "    else:\n",
    "        good_mask[center_objects]=0\n",
    "        if center_on:\n",
    "            normalized_distance[good_mask] = (normalized_distance[good_mask] - normalized_distance[good_mask].min())/(normalized_distance[good_mask].max() - normalized_distance[good_mask].min())\n",
    "        bin_array = (normalized_distance * bin_count).astype(int)\n",
    "            \n",
    "    bin_array[bin_array > bin_count] = bin_count\n",
    "    \n",
    "    # create wedges mask array\n",
    "    i, j = np.mgrid[0 : mask.shape[0], 0 : mask.shape[1]]\n",
    "    imask = i[good_mask] > i_center[good_mask]\n",
    "    jmask = j[good_mask] > j_center[good_mask]\n",
    "    absmask = abs(i[good_mask] - i_center[good_mask]) > abs(j[good_mask] - j_center[good_mask])\n",
    "    radial_index = (imask.astype(int) + jmask.astype(int) * 2 + absmask.astype(int) * 4)\n",
    "\n",
    "    wedge_array = np.zeros_like(good_mask, dtype=int)\n",
    "    wedge_array[good_mask] = radial_index\n",
    "    \n",
    "\n",
    "    ################   ################\n",
    "    ## get histograms\n",
    "    ################   ################\n",
    "    ngood_pixels = np.sum(good_mask)\n",
    "    good_labels = mask[good_mask]\n",
    "\n",
    "    # whole cell bin and wedge measurements\n",
    "    mask_arrays = [bin_array, wedge_array]\n",
    "    sections = [bin_count, 8]\n",
    "    types = ['bin', 'wedge']\n",
    "\n",
    "    met_dict = {}\n",
    "\n",
    "    for array, num, name in zip(mask_arrays, sections, types):\n",
    "        labels_and_bins = (good_labels - 1, array[good_mask])\n",
    "\n",
    "        met_dict[f\"XY_mask_vox_cnt_per{name}\"] = [coo_matrix((mask_proj[good_mask], labels_and_bins), shape=(nobjects, num)).toarray().squeeze().tolist()]\n",
    "        met_dict[f\"XY_obj_vox_cnt_per{name}\"] = [coo_matrix((obj_proj[good_mask], labels_and_bins), shape=(nobjects, num)).toarray().squeeze().tolist()]\n",
    "        met_dict[f\"XY_center_vox_cnt_per{name}\"] = [coo_matrix((centering_proj[good_mask], labels_and_bins), shape=(nobjects, num)).toarray().squeeze().tolist()]\n",
    "        n_pixels = [coo_matrix((np.ones(ngood_pixels), labels_and_bins), (nobjects, num)).toarray().squeeze().tolist()]\n",
    "        met_dict[f\"XY_n_pix_per{name}\"] = n_pixels\n",
    "\n",
    "        total_pixels = np.sum(n_pixels, 1)\n",
    "        total_repeated = np.dstack([total_pixels] * (num))[0]\n",
    "        met_dict[f\"XY_portion_pix_per{name}\"] = [(n_pixels / total_repeated).squeeze().tolist()]\n",
    "\n",
    "\n",
    "    # per wedge per bin measurements\n",
    "    bin_names =[]\n",
    "    cv_mask = []\n",
    "    cv_obj = []\n",
    "    cv_center = []\n",
    "    mask_wedge_perbin = []\n",
    "    obj_wedge_perbin = []\n",
    "    center_wedge_perbin = []\n",
    "    pxl_cnt_wedge_perbin = []\n",
    "    wedges_perbin = []\n",
    "\n",
    "    for bin in range(bin_count):\n",
    "        bin_mask = good_mask & (bin_array == bin)\n",
    "        bin_pixels = np.sum(bin_mask)\n",
    "\n",
    "        bin_labels = mask[bin_mask]\n",
    "\n",
    "        bin_radial_index = radial_index[bin_array[good_mask] == bin]\n",
    "        labels_and_radii = (bin_labels - 1, bin_radial_index)\n",
    "\n",
    "        radial_counts_mask = coo_matrix((mask_proj[bin_mask], labels_and_radii), (nobjects, 8) ).toarray()\n",
    "        radial_counts_obj = coo_matrix((obj_proj[bin_mask], labels_and_radii), (nobjects, 8)).toarray()\n",
    "        radial_counts_center = coo_matrix((centering_proj[bin_mask], labels_and_radii), (nobjects, 8)).toarray()\n",
    "        pixel_count = coo_matrix((np.ones(bin_pixels), labels_and_radii), (nobjects, 8)).toarray()\n",
    "\n",
    "        n_mask = pixel_count == 0\n",
    "\n",
    "        radial_counts = [radial_counts_mask, radial_counts_obj, radial_counts_center]\n",
    "        radial_cvs = []\n",
    "        for count in radial_counts:\n",
    "            radial_norm = np.ma.masked_array(count / pixel_count, n_mask)\n",
    "            radial_cv = np.std(radial_norm, 1) / np.mean(radial_norm, 1)\n",
    "            radial_cv[np.sum(~n_mask, 1) == 0] = 0\n",
    "            radial_cv.mask = np.sum(~n_mask, 1) == 0\n",
    "            radial_cvs.append(radial_cv)\n",
    "\n",
    "        bin_name = bin + 1 if bin > 0 else 1\n",
    "        wedges_perbin_name = np.ma.masked_array([it+1 for it in range(8)])\n",
    "\n",
    "        bin_names.append(bin_name)\n",
    "        cv_mask.append(float(np.mean(radial_cvs[0])))\n",
    "        cv_obj.append(float(np.mean(radial_cvs[1])))\n",
    "        cv_center.append(float(np.mean(radial_cvs[2])))\n",
    "        mask_wedge_perbin.append(radial_counts[0].squeeze().tolist())\n",
    "        obj_wedge_perbin.append(radial_counts[1].squeeze().tolist())\n",
    "        center_wedge_perbin.append(radial_counts[2].squeeze().tolist())\n",
    "        pxl_cnt_wedge_perbin.append(pixel_count.squeeze().tolist())\n",
    "        wedges_perbin.append(wedges_perbin_name.data.squeeze().tolist())\n",
    "    \n",
    "\n",
    "    ################   ################\n",
    "    ## create data table and account for scale\n",
    "    ################   ################\n",
    "    met_dict_1 = {'object': obj_name,\n",
    "                  'XY_n_bins': bin_count,\n",
    "                  'XY_bins': [bin_names]}\n",
    "    met_dict_2 = dict(list(met_dict.items())[:5])\n",
    "    met_dict_3 = {'XY_n_wedges': 8,\n",
    "                  'XY_wedges': str([it+1 for it in range(8)])}\n",
    "    met_dict_4 = dict(list(met_dict.items())[5:])\n",
    "    met_dict_5 = {'XY_wedges_perbin': [wedges_perbin],\n",
    "                  'XY_mask_vox_cnt_wedges_perbin':[mask_wedge_perbin],\n",
    "                  'XY_obj_vox_cnt_wedges_perbin':[obj_wedge_perbin],\n",
    "                  'XY_center_vox_cnt_wedges_perbin': [center_wedge_perbin],\n",
    "                  'XY_n_pix_wedges_perbin': [pxl_cnt_wedge_perbin],\n",
    "                  'XY_mask_cv_perbin':[cv_mask],\n",
    "                  'XY_obj_cv_perbin':[cv_obj],\n",
    "                  'XY_center_cv_perbin': [cv_center]}\n",
    "    \n",
    "    dict_combined = dict(itertools.chain(met_dict_1.items(), met_dict_2.items(), met_dict_3.items(), met_dict_4.items(), met_dict_5.items()))\n",
    "    tab = pd.DataFrame(dict_combined)\n",
    "\n",
    "    # account for scale\n",
    "    if scale is not None:\n",
    "        round_scale = (round(scale[0], 4), round(scale[1], 4), round(scale[2], 4))\n",
    "        tab.insert(loc=1, column=\"scale\", value=f\"{round_scale}\")\n",
    "        \n",
    "        # measurements affected by scale\n",
    "        vol_mets = ['XY_mask_vox_cnt_perbin', 'XY_obj_vox_cnt_perbin', 'XY_center_vox_cnt_perbin', 'XY_mask_vox_cnt_perwedge', 'XY_obj_vox_cnt_perwedge',\n",
    "                    'XY_center_vox_cnt_perwedge', 'XY_mask_vox_cnt_wedges_perbin', 'XY_obj_vox_cnt_wedges_perbin', 'XY_center_vox_cnt_wedges_perbin']\n",
    "        area_mets = ['XY_n_pix_perbin', 'XY_n_pix_perwedge', 'XY_n_pix_wedges_perbin']\n",
    "\n",
    "        for met in vol_mets:\n",
    "            tab[met.replace('_vox_cnt_', \"_vol_\")] = [(np.float_(tab[met][0]) * np.prod(scale)).squeeze().tolist()]\n",
    "        for met in area_mets:\n",
    "            tab[met.replace('_n_pix_', \"_area_\")] = [(np.float_(tab[met][0]) * np.prod(scale[1:])).squeeze().tolist()]\n",
    "\n",
    "    else: \n",
    "        tab.insert(loc=2, column=\"scale\", value=f\"{tuple(np.ones(3))}\")\n",
    "\n",
    "    return tab, bin_array, wedge_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run `_get_concentric_distribution` function (scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats_tab_a, test_bin_indexes_a, test_wedge_indexes_a = _get_concentric_distribution(mask_proj=test_cell_proj_a, \n",
    "                                                                                            centering_proj=test_nuc_proj_a, \n",
    "                                                                                            obj_proj=test_golgi_proj_a, \n",
    "                                                                                            obj_name='golgi', \n",
    "                                                                                            scale=scale,\n",
    "                                                                                            bin_count=5, \n",
    "                                                                                            center_on=False,\n",
    "                                                                                            keep_center_as_bin=True)\n",
    "\n",
    "results = {}\n",
    "for col in test_stats_tab_a.columns:\n",
    "    results[col] = test_stats_tab_a[col][0]==test_stat_tab[col][0]\n",
    "\n",
    "results, np.array_equal(test_bin_indexes_a,  test_bin_indexes), np.array_equal(test_wedge_indexes_a,  test_radial_index_vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats_tab_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of organelles within bins and wedges \n",
    "fourdim_bins = []\n",
    "for bin in range(test_bin_count):\n",
    "    bin_image_2d = test_bin_indexes_a == bin\n",
    "    bin_image_2d = apply_mask(bin_image_2d, test_good_mask)\n",
    "    bin_image_4d = np.tile(bin_image_2d, (raw_img_data.shape[0], raw_img_data.shape[1],1,1))\n",
    "    fourdim_bins.append(bin_image_4d)\n",
    "fourdim_bins = np.array(fourdim_bins)\n",
    "\n",
    "viewer.layers.clear()\n",
    "\n",
    "colors = [\"blue\",\"green\",\"yellow\",\"bop orange\",\"gray\"]\n",
    "for bin in range(test_bin_count):\n",
    "    viewer.add_image(raw_img_data[3] * fourdim_bins[bin][5],\n",
    "                        colormap=colors[bin],\n",
    "                        blending=\"additive\",\n",
    "                        scale=scale,contrast_limits=([0, 10000]),\n",
    "                        rotate = (5, 5, 0))\n",
    "viewer.grid.enabled=False\n",
    "viewer.reset_view()\n",
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare to finalized `get_concentric_distribution` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.stats import get_concentric_distribution\n",
    "\n",
    "test_stats_tab_final, test_bin_indexes_final, test_wedge_indexes_final = get_concentric_distribution(mask_proj=test_cell_proj_a, \n",
    "                                                                                                     centering_proj=test_nuc_proj_a, \n",
    "                                                                                                     obj_proj=test_golgi_proj_a, \n",
    "                                                                                                     obj_name='golgi', \n",
    "                                                                                                     scale=scale,\n",
    "                                                                                                     bin_count=5, \n",
    "                                                                                                     center_on=False,\n",
    "                                                                                                     keep_center_as_bin=True)\n",
    "\n",
    "test_stats_tab_a.equals(test_stats_tab_final), np.array_equal(test_bin_indexes_a,  test_bin_indexes_final), np.array_equal(test_wedge_indexes_a,  test_wedge_indexes_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`4` - Collect measurement about the distribution the organelles within each bin using zernike features**\n",
    "\n",
    "> ###### The Zernike features characterize the distribution of intensity across the object. For instance, Zernike 1,1 has a high value if the intensity is low on one side of the object and high on the other. The zernike magnitudes feature records the rotationally invariant degree magnitude of the moment and the zernike phase feature gives the moment‚Äôs orientation.\n",
    "\n",
    "> ###### The logic was borrowed from CellProfiler, but alorithm greatly simplified by making assumpitions of doing all estimates over a single cellmask (single cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specify the number of degress to use for calculating zernike features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = label(test_cell_proj_a>0)\n",
    "\n",
    "# get the zernike indexes based on the number of degrees chosen\n",
    "test_zernike_degree = 9\n",
    "test_zernike_indexes = centrosome.zernike.get_zernike_indexes( test_zernike_degree + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the center of the cell mask and the radius of the minimum enclosed circle\n",
    "test_ij, test_r = centrosome.cpmorphology.minimum_enclosing_circle( test_labels )\n",
    "\n",
    "# create a gradient of intensities in X and Y\n",
    "test_iii, test_jjj = np.mgrid[0 : test_labels.shape[0], 0 : test_labels.shape[1]]\n",
    "\n",
    "# normalize those values using the center of the cell and radius calculated above\n",
    "test_iii = (test_iii-test_ij[0][0] ) / test_r\n",
    "test_jjj = (test_jjj-test_ij[0][1] ) / test_r\n",
    "\n",
    "# create the zernike polynomials\n",
    "test_z = centrosome.zernike.construct_zernike_polynomials(test_iii, test_jjj, test_zernike_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define prototype `_zernike_polynomial` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _zernike_polynomial(labels, zernike_is):\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    # First, get a table of centers and radii of minimum enclosing\n",
    "    # circles for the cellmask\n",
    "    ij, r = centrosome.cpmorphology.minimum_enclosing_circle( labels )\n",
    "    # Then compute x and y, the position of each labeled pixel\n",
    "    # within a unit circle around the object\n",
    "    iii, jjj = np.mgrid[0 : labels.shape[0], 0 : labels.shape[1]]\n",
    "\n",
    "    # translate+scale\n",
    "    iii = (iii-ij[0][0] ) / r\n",
    "    jjj = (jjj-ij[0][1] ) / r\n",
    "\n",
    "    z = centrosome.zernike.construct_zernike_polynomials(\n",
    "        iii, jjj, zernike_is\n",
    "    )\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z_a = _zernike_polynomial(test_labels, test_zernike_indexes)\n",
    "\n",
    "np.array_equal(test_z, test_z_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare to finalized `zernike_polynomial` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.stats import zernike_polynomial\n",
    "\n",
    "test_z_final = zernike_polynomial(test_labels, test_zernike_indexes)\n",
    "\n",
    "np.array_equal(test_z, test_z_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Collect zernike meausurements and define prototype `_zernike_metrics` function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting zernike measurements for golgi example\n",
    "test_vr = np.sum(test_golgi_proj_a[:,:,np.newaxis]*test_z.real, axis=(0,1))\n",
    "test_vi = np.sum(test_golgi_proj_a[:,:,np.newaxis]*test_z.imag, axis=(0,1))    \n",
    "test_magnitude = np.sqrt(test_vr * test_vr + test_vi * test_vi) / test_golgi_proj.sum()\n",
    "test_phase = np.arctan2(test_vr, test_vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _zernike_metrics(pixels, z):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    vr = np.sum(pixels[:,:,np.newaxis]*z.real, axis=(0,1))\n",
    "    vi = np.sum(pixels[:,:,np.newaxis]*z.imag, axis=(0,1))    \n",
    "    magnitude = np.sqrt(vr * vr + vi * vi) / pixels.sum()\n",
    "    phase = np.arctan2(vr, vi)\n",
    "    return magnitude, phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collecting zernike measurements for cell and nucleus too\n",
    "test_z_cm = _zernike_metrics(test_cell_proj_a, test_z)\n",
    "test_z_nuc = _zernike_metrics(test_nuc_proj_a, test_z)\n",
    "test_z_golgi = _zernike_metrics(test_golgi_proj_a, test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(test_z_golgi[0], test_magnitude), np.array_equal(test_z_golgi[1], test_phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare to finalized `zernike_metrics` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.stats import zernike_metrics\n",
    "\n",
    "test_z_golgi_final = zernike_metrics(test_golgi_proj_a, test_z)\n",
    "\n",
    "np.array_equal(test_z_golgi, test_z_golgi_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create summary table of zernike features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nm_labels = [f\"{n}_{m}\" for (n, m) in (zernike_indexes)\n",
    "test_z_stats_tab = pd.DataFrame({'object':'golgi',\n",
    "                            'zernike_n':[test_zernike_indexes[:,0].tolist()],\n",
    "                            'zernike_m':[test_zernike_indexes[:,1].tolist()],\n",
    "                            'zernike_mask_mag':[test_z_cm[0].tolist()],\n",
    "                            'zernike_mask_phs':[test_z_cm[1].tolist()],   \n",
    "                            'zernike_obj_mag':[test_z_golgi_final[0].tolist()],\n",
    "                            'zernike_obj_phs':[test_z_golgi_final[1].tolist()],\n",
    "                            'zernike_center_mag':[test_z_nuc[0].tolist()],\n",
    "                            'zernike_center_phs':[test_z_nuc[1].tolist()]})\n",
    "\n",
    "test_z_stats_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define prototype `_get_zernike_metrics` function\n",
    "\n",
    "###### Based on the prototyping above, define the function to quantify and summarize the zernike features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_zernike_metrics(        \n",
    "        cellmask_proj: np.ndarray,\n",
    "        nucleus_proj: Union[np.ndarray, None], \n",
    "        org_proj: np.ndarray,\n",
    "        organelle_name: str,\n",
    "        zernike_degree: int = 9 ):\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    labels = label(cellmask_proj>0) #extent as 0,1 rather than bool\n",
    "    zernike_indexes = centrosome.zernike.get_zernike_indexes( zernike_degree + 1)\n",
    "\n",
    "\n",
    "    z = zernike_polynomial(labels, zernike_indexes)\n",
    "\n",
    "    z_cm = zernike_metrics(cellmask_proj, z)\n",
    "    z_org = zernike_metrics(org_proj, z)\n",
    "    z_nuc = zernike_metrics(nucleus_proj, z)\n",
    "\n",
    "\n",
    "\n",
    "    # nm_labels = [f\"{n}_{m}\" for (n, m) in (zernike_indexes)\n",
    "    stats_tab = pd.DataFrame({'object':organelle_name,\n",
    "                                'zernike_n':[zernike_indexes[:,0].tolist()],\n",
    "                                'zernike_m':[zernike_indexes[:,1].tolist()],\n",
    "                                'zernike_mask_mag':[z_cm[0].tolist()],\n",
    "                                'zernike_mask_phs':[z_cm[1].tolist()],   \n",
    "                                'zernike_obj_mag':[z_org[0].tolist()],\n",
    "                                'zernike_obj_phs':[z_org[1].tolist()],\n",
    "                                'zernike_center_mag':[z_nuc[0].tolist()],\n",
    "                                'zernike_center_phs':[z_nuc[1].tolist()]})\n",
    "\n",
    "    return stats_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z_stats_tab_a = _get_zernike_metrics(test_cell_proj_a, test_nuc_proj_a, test_golgi_proj_a, 'golgi', 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_z_stats_tab.equals(test_z_stats_tab_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare to finalized `get_zernike_metics` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.stats import get_zernike_metrics\n",
    "\n",
    "test_z_stats_tab_final = get_zernike_metrics(test_cell_proj_a, test_nuc_proj_a, test_golgi_proj_a, 'golgi', 9)\n",
    "\n",
    "test_z_stats_tab_final.equals(test_z_stats_tab_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_combined_tab = pd.merge(test_stats_tab_final, test_z_stats_tab_final, on=\"object\")\n",
    "\n",
    "test_combined_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`5` - Combine XY distirbution and zernike measurements into one dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define prototype of comprehensive function `get_XY_distribution`\n",
    "\n",
    "> ###### üìù **Based on the prototyping above, define the function to create the sum projections, create the normalized bins from centering object out to the edge of the cell, measure the distribution in the cell, and the zernike distribution within the bins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_XY_distribution(        \n",
    "        mask: np.ndarray,\n",
    "        centering_obj: np.ndarray,\n",
    "        obj:np.ndarray,\n",
    "        obj_name: str,\n",
    "        scale: Union[tuple, None]=None,\n",
    "        num_bins: Union[int, None] = 5,\n",
    "        center_on: bool = False,\n",
    "        keep_center_as_bin: bool = True,\n",
    "        zernike_degrees: Union[int, None] = None):\n",
    "\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ----------\n",
    "    mask_obj: np.ndarray,\n",
    "        a binary 3D (ZYX) np.ndarray of the area that will be measured from\n",
    "    centering_obj: np.ndarray\n",
    "        a binary 3D (ZYX) np.ndarray of the object that will be used as the center of the concentric rins (\"bins\")\n",
    "    obj: np.ndarray\n",
    "        a 3D (ZYX) np.ndarray image of what will be measured within the masked area\n",
    "    obj_name: str\n",
    "        the name or nickname for the obj being measured; this will appear as a column in the output datasheet\n",
    "    scale: Union[tuple, None]=None\n",
    "        a tuple that contains the real world dimensions for each dimension in the image (Z, Y, X)\n",
    "    num_bins: Union[int,None] = None\n",
    "        the number of concentric rings to draw between the centering object and edge of the mask; None will result in 5 bins\n",
    "    center_on: bool = False\n",
    "        True = distribute the bins from the center of the centering object\n",
    "        False = distribute the bins from the edge of the centering object\n",
    "    keep_center_as_bin: bool = True\n",
    "        True = include the centering object area when creating the bins\n",
    "        False = do not include the centering object area when creating the bins\n",
    "    zernike_degrees: Union[int,None] = None\n",
    "        the number of zernike degrees to include for the zernike shape descriptors; if None, the zernike measurements will not \n",
    "        be included in the output\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    XY_metrics:\n",
    "        a pandas Dataframe of bin, wedge, and zernike measurements\n",
    "    dist_bin_mask:\n",
    "        an np.ndarray mask of the concentric ring bins\n",
    "    dist_wedge_mask \n",
    "        an np.ndarray mask of the 8 radial wedges\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mask_proj = create_masked_sum_projection(mask)\n",
    "    center_proj = create_masked_sum_projection(centering_obj,mask.astype(bool))\n",
    "    obj_proj = create_masked_sum_projection(obj,mask.astype(bool))\n",
    " \n",
    "\n",
    "    XY_metrics, dist_bin_mask, dist_wedge_mask = get_concentric_distribution(mask_proj=mask_proj, \n",
    "                                                        centering_proj=center_proj, \n",
    "                                                        obj_proj=obj_proj, \n",
    "                                                        obj_name=obj_name, \n",
    "                                                        scale=scale,\n",
    "                                                        bin_count=num_bins, \n",
    "                                                        center_on=center_on,\n",
    "                                                        keep_center_as_bin=keep_center_as_bin)\n",
    "    \n",
    "    if zernike_degrees is not None:\n",
    "        zernike_metrics = get_zernike_metrics(cellmask_proj=mask_proj, \n",
    "                                            org_proj=obj_proj,\n",
    "                                            organelle_name=obj_name, \n",
    "                                            nucleus_proj=center_proj, \n",
    "                                            zernike_degree=zernike_degrees)\n",
    "        \n",
    "        XY_metrics = pd.merge(XY_metrics, zernike_metrics, on=\"object\")\n",
    "\n",
    "    return XY_metrics, dist_bin_mask, dist_wedge_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_XY_metrics, test_dist_bins, test_dist_wedges = _get_XY_distribution(mask = cell_seg,\n",
    "                                                                        centering_obj = nuc_seg,\n",
    "                                                                        obj = golgi_seg,\n",
    "                                                                        obj_name = 'golgi',\n",
    "                                                                        scale = scale,\n",
    "                                                                        num_bins = 5,\n",
    "                                                                        center_on = False,\n",
    "                                                                        keep_center_as_bin = True,\n",
    "                                                                        zernike_degrees = 9)\n",
    "\n",
    "test_XY_metrics.equals(test_combined_tab), np.array_equal(test_dist_bins, test_bin_indexes_a), np.array_equal(test_dist_wedges, test_radial_index_vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare to finalized `get_XY_distribution` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.stats import get_XY_distribution\n",
    "\n",
    "test_XY_metrics_final, test_dist_bins_final, test_dist_wedges_final = get_XY_distribution(mask = cell_seg,\n",
    "                                                                                          centering_obj = nuc_seg,\n",
    "                                                                                          obj = golgi_seg,\n",
    "                                                                                          obj_name = 'golgi',\n",
    "                                                                                          scale = scale,\n",
    "                                                                                          num_bins = 5,\n",
    "                                                                                          center_on = False,\n",
    "                                                                                          keep_center_as_bin = True,\n",
    "                                                                                          zernike_degrees = 9)\n",
    "\n",
    "test_XY_metrics_final.equals(test_combined_tab), np.array_equal(test_dist_bins, test_dist_bins_final), np.array_equal(test_dist_wedges, test_dist_wedges_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***PART 2Ô∏è‚É£: Z DISTRIBUTION***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`1` - Sum all True pixels in each Z slices (olong the X and Y axes)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sum Golgi body segmentation along the X and Y axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_golgi_for_Zdist = golgi_seg.astype(bool)\n",
    "\n",
    "test_golgi_for_Zdist_masked = apply_mask(test_golgi_for_Zdist, cell_seg)\n",
    "\n",
    "test_golgi_for_Zdist_masked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_golgi_Zdist = test_golgi_for_Zdist_masked.sum(axis=(1,2))\n",
    "test_golgi_Zdist.shape, test_golgi_Zdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define prototype `_create_masked_depth_projection` function\n",
    "\n",
    "###### Based on the prototyping above, sum the True values along XY for every Z slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_masked_depth_projection(img_in:np.ndarray, mask:Union[np.ndarray, None]=None, to_bool:bool=True) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    create a masked projection by summing together all XY pixels per Z plane/slice\n",
    "    \"\"\"\n",
    "    img_out = img_in.astype(bool) if to_bool else img_in\n",
    "    if mask is not None:\n",
    "        img_out = apply_mask(img_out, mask)\n",
    "    \n",
    "    return img_out.sum(axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golgi_Zdist_final = _create_masked_depth_projection(golgi_seg, cell_seg)\n",
    "cell_Zdist_final = _create_masked_depth_projection(cell_seg)\n",
    "nuc_Zdist_final = _create_masked_depth_projection(nuc_seg, cell_seg)\n",
    "\n",
    "np.array_equal(test_golgi_Zdist, golgi_Zdist_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare to finalized `create_masked_depth_projection` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.stats import create_masked_depth_projection\n",
    "\n",
    "golgi_Zdist_final_a = create_masked_depth_projection(golgi_seg, cell_seg)\n",
    "\n",
    "np.array_equal(golgi_Zdist_final_a, golgi_Zdist_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`2` - Summarize the data using the bin format**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- List the bins (z-slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list the \"bins\" which in this case as the z-slices\n",
    "test_z_bins = [i for i in range(cell_seg.shape[0])]\n",
    "test_z_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construct the dataframe of summarized Z distribution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the Z distribution data in a table\n",
    "organelle_name = 'golgi'\n",
    "test_zdist_stats_tab = pd.DataFrame({'object':organelle_name,\n",
    "                        'Z_n_slices':cell_seg.shape[0],\n",
    "                        'Z_slices':[test_z_bins],\n",
    "                        'Z_mask_vox_cnt':[cell_Zdist_final.tolist()],\n",
    "                        'Z_obj_vox_cnt':[golgi_Zdist_final.tolist()],\n",
    "                        'Z_center_vox_cnt':[nuc_Zdist_final.tolist()]})\n",
    "\n",
    "if scale is not None:\n",
    "    round_scale = (round(scale[0], 4), round(scale[1], 4), round(scale[2], 4))\n",
    "    test_zdist_stats_tab.insert(loc=1, column=\"scale\", value=f\"{round_scale}\")\n",
    "\n",
    "    test_zdist_stats_tab['Z_height'] = cell_seg.shape[0] * scale[0]\n",
    "    test_zdist_stats_tab['Z_mask_volume'] = [(cell_Zdist_final * np.prod(scale)).tolist()]\n",
    "    test_zdist_stats_tab['Z_obj_volume'] = [(golgi_Zdist_final * np.prod(scale)).tolist()]\n",
    "    test_zdist_stats_tab['Z_center_volume'] = [(nuc_Zdist_final * np.prod(scale)).tolist()]\n",
    "else: \n",
    "    test_zdist_stats_tab.insert(loc=2, column=\"scale\", value=f\"{tuple(np.ones(3))}\")\n",
    "\n",
    "\n",
    "test_zdist_stats_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define prototype `_get_Z_distribution` function\n",
    "\n",
    "###### **Based on the prototyping above, create projections along XY for each Z slice and sum the True pixels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_Z_distribution(        \n",
    "        mask: np.ndarray,\n",
    "        obj:np.ndarray,\n",
    "        obj_name: str,\n",
    "        center_obj: Union[np.ndarray, None],\n",
    "        scale: Union[tuple, None] = None\n",
    "        ):\n",
    "    \"\"\"\n",
    "    quantification of distribution along the Z axis; all XY pixels are summed together per Z slice and then quantified\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    mask_obj: np.ndarray,\n",
    "        a binary 3D (ZYX) np.ndarray of the area that will be measured from\n",
    "    obj: np.ndarray\n",
    "        a 3D (ZYX) np.ndarray image of what will be measured within the masked area\n",
    "    obj_name: str\n",
    "        the name or nickname for the obj being measured; this will appear as a column in the output datasheet\n",
    "    centering_obj: np.ndarray\n",
    "        optional - a binary 3D (ZYX) np.ndarray utilized as the center/reference point of the area; for cells, this is usually the nucleus\n",
    "    scale: Union[tuple, None]=None\n",
    "        a tuple that contains the real world dimensions for each dimension in the image (Z, Y, X)\n",
    "\n",
    "    Returns\n",
    "    -----------\n",
    "    Z_tab:\n",
    "        a pandas Dataframe of measurements for each z slice\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # flattened\n",
    "    mask_proj = create_masked_depth_projection(mask)\n",
    "    obj_proj = create_masked_depth_projection(obj, mask.astype(bool))\n",
    "    center_proj = create_masked_depth_projection(center_obj, mask.astype(bool)) if center_obj is not None else None\n",
    "\n",
    "    Zdist_tab = pd.DataFrame({'object':obj_name,\n",
    "                            'Z_n_slices':mask.shape[0],\n",
    "                            'Z_slices':[[i for i in range(mask.shape[0])]],\n",
    "                            'Z_mask_vox_cnt':[mask_proj.tolist()],\n",
    "                            'Z_obj_vox_cnt':[obj_proj.tolist()],\n",
    "                            'Z_center_vox_cnt':[center_proj.tolist()]})\n",
    "    \n",
    "    if scale is not None:\n",
    "        round_scale = (round(scale[0], 4), round(scale[1], 4), round(scale[2], 4))\n",
    "        Zdist_tab.insert(loc=1, column=\"scale\", value=f\"{round_scale}\")\n",
    "\n",
    "        Zdist_tab['Z_height'] = mask.shape[0] * scale[0]\n",
    "        Zdist_tab['Z_mask_volume'] = [(mask_proj * np.prod(scale)).tolist()]\n",
    "        Zdist_tab['Z_obj_volume'] = [(obj_proj * np.prod(scale)).tolist()]\n",
    "        Zdist_tab['Z_center_volume'] = [(center_proj * np.prod(scale)).tolist()]\n",
    "    else: \n",
    "        Zdist_tab.insert(loc=2, column=\"scale\", value=f\"{tuple(np.ones(3))}\")\n",
    "\n",
    "    return Zdist_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zdist_stats_tab_final = _get_Z_distribution(mask = cell_seg,\n",
    "                                            obj = golgi_seg,\n",
    "                                            obj_name = 'golgi',\n",
    "                                            center_obj = nuc_seg,\n",
    "                                            scale = scale)\n",
    "\n",
    "test_zdist_stats_tab.equals(zdist_stats_tab_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compare to finalized `get_Z_distribution` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infer_subc.utils.stats import get_Z_distribution\n",
    "\n",
    "zdist_stats_tab_final_a = get_Z_distribution(mask = cell_seg,\n",
    "                                             obj = golgi_seg,\n",
    "                                             obj_name = 'golgi',\n",
    "                                             center_obj = nuc_seg,\n",
    "                                             scale = scale)\n",
    "\n",
    "zdist_stats_tab_final_a.equals(zdist_stats_tab_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer-subc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
