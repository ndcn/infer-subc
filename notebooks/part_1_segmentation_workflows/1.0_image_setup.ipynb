{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Pipeline **Setup**\n",
    "--------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OVERVIEW**\n",
    "\n",
    "The first thing we need to be able to do is access the image files and interact with them (e.g., read the metadata)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F4D6; **How to:** \n",
    "\n",
    "Advance through each block of code by pressing `Shift`+`Enter`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **IMPORTS**\n",
    "\n",
    "The convention with notebooks (and python in general) is to import the nescessary packages as the first thing.\n",
    "\n",
    "\n",
    "We are using `napari` for visualization, and `scipy` `ndimage` and `skimage` for analyzing the image files.  The underlying data format are `numpy` `ndarrays` and tools from  Allen Institute for Cell Science.\n",
    "\n",
    "> ###### ðŸ“ **There are a few convences used here worth explanation.  Note the `imports.py` and `constants.py` files in the base level of the `infer_subc` module.  These provide shortcuts for keeping track of imports and constants.  cf. the bottom of the imports below.  A second thing to note is the use of the \"magics\" `%load_ext autoreload` `%autoreload 2`, which tells the notebook to reload any changes made in the source code of the module on change; hence, avoid re-executing the imports.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block loads all of the necessary python packages and functions you will need for this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import napari\n",
    "import pandas as pd\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image,\n",
    "                                    list_image_files,\n",
    "                                    sample_input,\n",
    "                                    export_ome_tiff)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LOAD AND READ IN IMAGE FOR PROCESSING**\n",
    "Read the image and metadata into memory as an ndarray and dictionary from the `.czi` or `.tiff` files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### â¬‡ï¸ **Downloading Sample Data**\n",
    ">\n",
    "> **If you would like to test this and the following notebooks in parts 1 and 2 with sample data, follow the steps below to download the raw sample images before beginning.**\n",
    ">\n",
    "> **Both of the example images were in the recent preprint titled [Neurons and astrocytes have distinct organelle signatures and responses to stress](https://www.biorxiv.org/content/10.1101/2024.10.30.621066v1)**\n",
    ">\n",
    "> Click the links to download the raw microscopy images\n",
    ">\n",
    "> ###### âš ï¸ These files will begin downloading automatically when the links are clicked âš ï¸\n",
    ">\n",
    "> Example Neuron File: [20230727_C2-121_unconditioned_well 10_cell 4_25nM TG_Linear unmixing_0_cmle.ome.tiff](https://www.ebi.ac.uk/biostudies/files/S-BIAD1445/Neuron%20and%20astrocyte%20organelle%20signatures%20dataset/Primary%20rat%20neuron%20data/Z-stacks/replicate3_C2-121/C2-121_deconvolution/20230727_C2-121_conditioned_well%204_cell%203_untreated_Linear%20unmixing_0_cmle.ome.tiff) (ðŸ’¾ 2.16 GB)\n",
    ">\n",
    "> After downloading the example neuron file, move the .tiff image to the corresponding directory in the sample data folder.\n",
    ">\n",
    ">\n",
    "> `infer-subc\\sample_data\\example_neuron\\raw`\n",
    ">\n",
    "> Example Astrocyte File: [05052022_astro_control_2_Linear unmixing_0_cmle.ome](https://www.ebi.ac.uk/biostudies/files/S-BIAD1445/Neuron%20and%20astrocyte%20organelle%20signatures%20dataset/Primary%20rat%20astrocyte%20data/Z-stacks/replicate2_VD-0505/VD-0505_deconvolution/05052022_astro_control_2_Linear%20unmixing_0_cmle.ome.tiff) (ðŸ’¾ 1.14 GB)\n",
    ">\n",
    "> After downloading the example astrocyte file, move the .tiff image to the corresponding directory in the sample data folder.\n",
    ">\n",
    ">\n",
    "> `infer-subc\\sample_data\\example_astrocyte\\raw`\n",
    ">\n",
    ">\n",
    "> ###### ðŸ’¾ You can now run all of the notebooks in infer-subc without editing the \"&#x1F6D1; &#x270D; **User Input Required:**\" fields. After running all of the notebooks in part 1, and completing quantification in part 2, the sample data folder will around 14 GB in size. Ensure that there is enough space on your drive to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F6D1; &#x270D; **User Input Required:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER INPUT REQUIRED ###\n",
    "# If using the sample data, select which cell type you would like analyze (\"neuron\" or \"astrocyte\"):\n",
    "# If not using the sample data, set cell_type to None\n",
    "sample_data_type = \"neuron\"\n",
    "\n",
    "# If you are not using the sample data, please edit \"USER SPECIFIED\" as necessary.\n",
    "## Define the path to the directory that contains the input image folder.\n",
    "data_root_path = Path(\"USER SPECIFIED\")\n",
    "\n",
    "# Specify the file type of your raw data that will be analyzed. Ex) \".czi\" or \".tiff\"\n",
    "im_type = \"USER SPECIFIED\"\n",
    "\n",
    "## Specify which subfolder that contains the input data and the input data file extension\n",
    "in_data_path = data_root_path / \"USER SPECIFIED\"\n",
    "\n",
    "## Specify the output folder to save the segmentation outputs if.\n",
    "## If its not already created, the code below will creat it for you\n",
    "out_data_path = data_root_path / \"USER SPECIFIED\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If sample_data_type is set to \"neuron\" or \"astrocyte\", then the sample data is used and the directories are set\n",
    "if sample_data_type != None:\n",
    "    raw_dirs = [Path(os.getcwd()).parents[1] / \"sample_data\" /  \"example_neuron\" / \"raw\",\n",
    "                Path(os.getcwd()).parents[1] / \"sample_data\" /  \"example_astrocyte\" / \"raw\"]\n",
    "\n",
    "# Copy the raw images to batch processing folder for quantification in part 2\n",
    "    for dir in raw_dirs:\n",
    "        f_list = list_image_files(dir,\".tiff\")\n",
    "        for f in f_list:\n",
    "            f_img, meta_f = read_czi_image(f)\n",
    "            export_ome_tiff(data_in = f_img,\n",
    "                        img_name = f.stem.split(\".\")[-2],\n",
    "                        out_path = str(Path(os.getcwd()).parents[1]) + \"/sample_data/batch_example/raw/\",\n",
    "                        meta_in = meta_f,\n",
    "                        channel_names = meta_f['metadata']['aicsimage'].channel_names)\n",
    "\n",
    "    data_root_path, im_type, in_data_path, out_data_path = sample_input(sample_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c:\\Users\\redre\\Documents\\CohenLab\\MSI-3D-analysis\\infer-subc\\sample_data\\example_astrocyte\\raw\\05052022_astro_control_2_Linear unmixing_0_cmle.ome.tiff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                Image Name\n",
       "0  c:\\Users\\redre\\Documents\\CohenLab\\MSI-3D-analysis\\infer-subc\\sample_data\\example_astrocyte\\raw\\05052022_astro_control_2_Linear unmixing_0_cmle.ome.tiff"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the output directory to save the segmentation outputs in.\n",
    "if not Path.exists(out_data_path):\n",
    "    Path.mkdir(out_data_path)\n",
    "    print(f\"making {out_data_path}\")\n",
    "\n",
    "# Create a list of the file paths for each image in the input folder. Select test image path.\n",
    "img_file_list = list_image_files(in_data_path,im_type)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.DataFrame({\"Image Name\":img_file_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F6D1; &#x270D; **User Input Required:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on the output table above, select the file you'd like to examine.\n",
    "test_img_n = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata information\n",
      "Channel names: ['20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:0', '20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:1', '20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:2', '20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:3', '20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:4', '20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome :: Channel:5']\n",
      "Image name: 20230727_C2-121_conditioned_well 4_cell 3_untreated_Linear unmixing_0_cmle.ome\n",
      "Scale: (0.410594, 0.079947, 0.079947)\n",
      "Channel axis: 0\n",
      "\n",
      "Proceed to Napari window to view your selected image.\n"
     ]
    }
   ],
   "source": [
    "# Read in the image and metadata as an ndarray and dictionary from the test image selected above. \n",
    "test_img_name = img_file_list[test_img_n]\n",
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "# Define some of the metadata features.\n",
    "channel_names = meta_dict['name']\n",
    "img = str(test_img_name.stem)\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']\n",
    "\n",
    "print(\"Metadata information\")\n",
    "print(f\"Channel names: {channel_names}\")\n",
    "print(f\"Image name: {img}\")\n",
    "print(f\"Scale: {scale}\")\n",
    "print(f\"Channel axis: {channel_axis}\")\n",
    "\n",
    "# Visualize the image in the Napari window\n",
    "viewer = napari.Viewer(title = f\"Example Image: {img}\")\n",
    "viewer.add_image(img_data)\n",
    "print(\"\\nProceed to Napari window to view your selected image.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "### NEXT:  INFER MASKS\n",
    "\n",
    "proceed to:\n",
    "\n",
    "[**Alternative Workflow (A)**](./1.1a_infer_masks_from-composite_single_cell.ipynb) - an alternative workflow for images with only cytoplasmic organelles, NO **nuclei** or **cell membrane** makers, one cell per field of view\n",
    "\n",
    "[**Alternative Workflow (B)**](./1.1b_infer_masks_from-composite_multiple-cells.ipynb) - an alternative workflow for images with only cytoplasmic organelles, NO **nuclei** or **cell membrane** makers, and more than one cell per field of view\n",
    "\n",
    "> ###### **Sample Data not yet applicable with 1**\n",
    "\n",
    "[**Default Workflow (1)**](./1.1_infer_masks_from-composite_with_nuc.ipynb) - for images with cytoplasmic organelles, a **nuclei** marker, no **cell membrane** makers, and more than one cell per field of view\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer-subc-sample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
