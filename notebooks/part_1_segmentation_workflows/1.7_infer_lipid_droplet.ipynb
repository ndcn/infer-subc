{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer ***lipid droplet*** - part 7️⃣\n",
    "\n",
    "--------------\n",
    "\n",
    "## OBJECTIVE \n",
    "### <input type=\"checkbox\"/> Infer sub-cellular component ***lipid droplets***\n",
    "Segment the ***lipid droplets*** from a single channel (neutrolipid dye). This workflow was optimized for images of the fluorescently dye BODIPY. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## infer ***LD*** \n",
    "### summary of steps \n",
    "\n",
    "➡️ **EXTRACTION**\n",
    "- **`STEP 1`** - Select a channel for segmentation\n",
    "\n",
    "  - select single channel containing the lipid droplet marker (channel number = user input)\n",
    "\n",
    "**PRE-PROCESSING**\n",
    "- **`STEP 2`** - Rescale and smooth image\n",
    "\n",
    "  - rescale intensity of composite image (min=0, max=1)\n",
    "  - median filter (median size = user input)\n",
    "  - gaussian filter (sigma = user input)\n",
    "\n",
    "**CORE PROCESSING**\n",
    "- **`STEP 3`** - Apply basic threshold\n",
    "\n",
    "  - apply threshold of the user's choice (`otsu`, `li`, `triangle`, `median` or `ave_tri_med`) (thresholding method, thresholding options = user input)\n",
    "\n",
    "**POST-PROCESSING**\n",
    "- **`STEP 4`** - Remove small holes and objects\n",
    "\n",
    "  - fill holes (hole size = user input)\n",
    "  - remove small objects (object size = user input)\n",
    "  - filter method (method = user input)\n",
    "\n",
    "**POST-POST-PROCESSING**\n",
    "- **`STEP 5`** - Label objects\n",
    "\n",
    "  - label unique lipid droplet objects based on connectivity\n",
    "\n",
    "**EXPORT** ➡️\n",
    "- save labeled ***lipid droplet*** (LD) as unsigned integer 16-bit tif files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## **IMPORTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block loads all of the necessary python packages and functions you will need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import napari\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image,\n",
    "                                     export_inferred_organelle,\n",
    "                                     list_image_files)\n",
    "\n",
    "from infer_subc.core.img import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LOAD AND READ IN IMAGE FOR PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F6D1; &#x270D; **User Input Required:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file type of your raw data that will be analyzed. Ex) \".czi\" or \".tiff\"\n",
    "im_type = \".tiff\"\n",
    "\n",
    "## Define the path to the directory that contains the input image folder.\n",
    "data_root_path = Path(os.getcwd()).parents[1] / \"sample_data\" /  \"example_neuron\"\n",
    "\n",
    "## Specify which subfolder that contains the input data\n",
    "in_data_path = data_root_path / \"raw\"\n",
    "\n",
    "## Specify the output folder\n",
    "out_data_path = data_root_path / \"seg\"\n",
    "\n",
    "# Specify which file you'd like to segment from the img_file_list\n",
    "test_img_n = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path.exists(out_data_path):\n",
    "    Path.mkdir(out_data_path)\n",
    "    print(f\"making {out_data_path}\")\n",
    "\n",
    "img_file_list = list_image_files(in_data_path,im_type)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.DataFrame({\"Image Name\":img_file_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_name = img_file_list[test_img_n]\n",
    "\n",
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***EXTRACTION prototype - LD***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 1` - Select a channel for segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- select single channel containing the lipid droplet marker (channel number = user input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "LD_CH = 0\n",
    "raw_LD = select_channel_from_raw(img_data, LD_CH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***PRE-PROCESSING prototype - LD***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 2` - Rescale and smooth image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rescale intensity of composite image (min=0, max=1)\n",
    "- median filter (median size = user input)\n",
    "- gaussian filter (sigma = user input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "median_sz = 0\n",
    "gauss_sig = 0\n",
    "\n",
    "struct_img =  scale_and_smooth(raw_LD,\n",
    "                               median_size = median_sz, \n",
    "                               gauss_sigma = gauss_sig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CORE-PROCESSING prototype - LD***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 3` -  Apply basic threshold**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply threshold of the user's choice (`otsu`, `li`, `triangle`, `median` or `ave_tri_med`) (thresholding method, thresholding options = user input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "method = \"otsu\"\n",
    "threshold_factor = 1\n",
    "thresh_min = 0.120\n",
    "thresh_max = 1\n",
    "otsu_thresholded = apply_threshold(struct_img, \n",
    "                                   method= method, \n",
    "                                   thresh_factor=threshold_factor, \n",
    "                                   thresh_min=thresh_min, \n",
    "                                   thresh_max=thresh_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***POST-PROCESSING prototype - LD***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 4` - Remove small holes and objects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fill holes (hole size = user input)\n",
    "- remove small objects (object size = user input)\n",
    "- filter method (method = user input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "hole_min_width = 0\n",
    "hole_max_width = 0\n",
    "\n",
    "small_object_width = 1\n",
    "\n",
    "fill_filter_method = \"3D\"\n",
    "\n",
    "cleaned_img2 = fill_and_filter_linear_size(otsu_thresholded, \n",
    "                                           hole_min=hole_min_width, \n",
    "                                           hole_max=hole_max_width, \n",
    "                                           min_size=small_object_width,\n",
    "                                           method=fill_filter_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***POST-POST-PROCESSING prototype - LD***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 5` - Label objects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- label unique lipid droplet objects based on connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# LABELING\n",
    "###################\n",
    "LD_labels = label_uint16(cleaned_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LD_labels.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualize with `napari` 1**\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(title = \"lipid droplet\",\n",
    "                       ndisplay=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(\n",
    "    struct_img,\n",
    "    scale = scale,\n",
    "    name = \"LD Intensities\")    \n",
    "\n",
    "viewer.add_image(\n",
    "    cleaned_img2,\n",
    "    scale = scale,\n",
    "    opacity=0.3,\n",
    "    name = \"LD Segmentation\")\n",
    "\n",
    "viewer.add_labels(\n",
    "    LD_labels,\n",
    "    scale = scale,\n",
    "    opacity=0.3,\n",
    "    name = \"LD Labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***EXTRACTION prototype - LD***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_n = export_inferred_organelle(LD_labels, \"LD\", meta_dict, out_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether or not to include the segmentation in the batch processing performed in part 2 of infer-subc (quantification)\n",
    "to_batch = True\n",
    "if to_batch:\n",
    "    out_file_b = export_inferred_organelle(LD_labels,\n",
    "                                           \"LD\",\n",
    "                                           meta_dict,\n",
    "                                           Path(os.getcwd()).parents[1] / \"sample_data\" /  \"batch_example\" / \"seg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Define `_infer_LD` function**\n",
    "\n",
    "> ###### 📝 **these functions mainly serve for downstream prototyping in the notebooks. Each step above has an independent function that is implemented in the plugin for easy of use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  infer_LD\n",
    "##########################\n",
    "def _infer_LD(\n",
    "            in_img: np.ndarray,\n",
    "            LD_ch: str,\n",
    "            median_sz: int,\n",
    "            gauss_sig: float,\n",
    "            method: str,\n",
    "            thresh_factor: float,\n",
    "            thresh_min: float,\n",
    "            thresh_max: float,\n",
    "            min_hole_w: int,\n",
    "            max_hole_w: int,\n",
    "            small_obj_w: int,\n",
    "            fill_filter_method: str\n",
    "            ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to infer peroxisome from linearly unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: \n",
    "        a 3d image containing all the channels\n",
    "    median_sz: \n",
    "        width of median filter for signal\n",
    "    gauss_sig: \n",
    "        sigma for gaussian smoothing of  signal\n",
    "    method: \n",
    "        method for applying threshold.  \"otsu\"  or \"li\", \"triangle\", \"median\", \"ave\", \"sauvola\",\"multi_otsu\",\"muiltiotsu\"\n",
    "    thresh_factor:\n",
    "        scaling value for threshold\n",
    "    thresh_min:\n",
    "        absolute minumum for threshold\n",
    "    thresh_max:\n",
    "        absolute maximum for threshold\n",
    "    max_hole_w: \n",
    "        hole filling cutoff for lipid post-processing\n",
    "    small_obj_w: \n",
    "        minimu object size cutoff for lipid post-processing\n",
    "    Returns\n",
    "    -------------\n",
    "    peroxi_object\n",
    "        mask defined extent of peroxisome object\n",
    "    \"\"\"\n",
    "\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################    \n",
    "    lipid = select_channel_from_raw(in_img, LD_ch)\n",
    "    \n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################                         \n",
    "    lipid =  scale_and_smooth(lipid,\n",
    "                              median_size = median_sz, \n",
    "                              gauss_sigma = gauss_sig)\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    bw = apply_threshold(lipid, \n",
    "                        method= method, \n",
    "                        thresh_factor=thresh_factor, \n",
    "                        thresh_min=thresh_min, \n",
    "                        thresh_max=thresh_max)\n",
    "\n",
    "\n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ###################\n",
    "    # min_hole_w = 0\n",
    "    struct_obj = fill_and_filter_linear_size(bw, \n",
    "                                             hole_min=min_hole_w, \n",
    "                                             hole_max=max_hole_w, \n",
    "                                             min_size=small_obj_w,\n",
    "                                             method=fill_filter_method)\n",
    "\n",
    "    ###################\n",
    "    # LABELING\n",
    "    ###################\n",
    "    struct_obj1 = label_uint16(struct_obj)\n",
    "\n",
    "    return struct_obj1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test  `infer_LD` function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LD_obj =  _infer_LD(\n",
    "        img_data,\n",
    "        LD_CH,  \n",
    "        median_sz, \n",
    "        gauss_sig, \n",
    "        method, \n",
    "        threshold_factor, \n",
    "        thresh_min, \n",
    "        thresh_max, \n",
    "        hole_min_width,\n",
    "        hole_max_width, \n",
    "        small_object_width,\n",
    "        fill_filter_method) \n",
    "\n",
    "_LD_obj.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(LD_labels == _LD_obj)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualize with `napari` 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(\n",
    "    _LD_obj,\n",
    "    scale = scale,\n",
    "    opacity=0.3,\n",
    "    name = \"LD Object\",\n",
    "    colormap='hsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------  \n",
    "###  **VOILÀ, All segementations are complete!!! 🎉🎉🎉**\n",
    "\n",
    "### NEXT: Quantification\n",
    "\n",
    "proceed to quantification folder\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer-subc-sample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
