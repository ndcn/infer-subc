{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infer ***endoplasmic reticulum (ER)*** - part 6Ô∏è‚É£\n",
    "\n",
    "--------------\n",
    "## **OBJECTIVE** \n",
    "### <input type=\"checkbox\"/> Infer sub-cellular component  ***ER***  \n",
    "Segment the ***ER*** from a single channel (membrane marker). This workflow was optimized for images of fluorescently tagged Sec61beta, a membrane protein. An instance segmentation is not done here as we assume the ER is one coninuous organelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## infer ***ER***\n",
    "### summary of steps \n",
    "\n",
    "‚û°Ô∏è **EXTRACTION**\n",
    "- **`STEP 1`** - Select a channel for segmentation\n",
    "\n",
    "    - select single channel containing the ER marker (channel number = user input)\n",
    "\n",
    "**PRE-PROCESSING**\n",
    "- **`STEP 2`** - Rescale and smooth image\n",
    "\n",
    "  - rescale intensity of composite image (min=0, max=1)\n",
    "  - median filter (median size = user input)\n",
    "  - gaussian filter (sigma = user input)\n",
    "\n",
    "**CORE-PROCESSING**\n",
    "- **`STEP 3`** - Global + local thresholding (AICSSeg ‚Äì MO)\n",
    "\n",
    "    - apply MO thresholding method from the Allen Cell [aicssegmentation](https://github.com/AllenCell/aics-segmentation) package (threshold options = user input)\n",
    "\n",
    "- **`STEP 4`** - ‚ÄòFilament‚Äô threshold method (AICSSeg)\n",
    "\n",
    "  - apply \"filament\"/\"vessel\" thresholding method (for tubular objects) from the Allen Cell [aicssegmentation](https://github.com/AllenCell/aics-segmentation) package (size scale and threshold cutoff = user input)\n",
    "\n",
    "- **`STEP 5`** - Combine Segmentations (logical or)\n",
    "\n",
    "  - combine the two segmentations with logical *OR*\n",
    "\n",
    "**POST-PROCESSING**\n",
    "- **`STEP 6`** - Remove small holes and objects\n",
    "\n",
    "  - fill holes (hole size = user input)\n",
    "  - remove small objects (object size = user input)\n",
    "  - filter method (method = user input)\n",
    "\n",
    "**POST-POST-PROCESSING**\n",
    "- **`STEP 7`** - Create one object (as unt16)\n",
    "\n",
    "  - label all ER \"objects\" 1/True\n",
    "\n",
    "**EXPORT** ‚û°Ô∏è \n",
    "- save labeled ***ER*** (ER) as unsigned integer 16-bit tif files\n",
    "\n",
    "\n",
    "> ###### **The Allen Cell Segmenter procedure included an edge proserving smoothing method followed by the \"filament\" thresholding method (find the Sec61b script [here](https://github.com/AllenCell/aics-segmentation/blob/main/aicssegmentation/structure_wrapper/seg_sec61b.py)). We have opted to also include to MO threshold method as it segments densely packed ER better**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "## **IMPORTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**\n",
    "\n",
    "&#x1F453; **FYI:** This code block loads all of the necessary python packages and functions you will need for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top level imports\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import napari\n",
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "from infer_subc.core.file_io import (read_czi_image,\n",
    "                                     export_inferred_organelle,\n",
    "                                     list_image_files,\n",
    "                                     sample_input)\n",
    "\n",
    "from infer_subc.core.img import *\n",
    " \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LOAD AND READ IN IMAGE FOR PROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F6D1; &#x270D; **User Input Required:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USER INPUT REQUIRED ###\n",
    "# If using the sample data, select which cell type you would like analyze (\"neuron\" or \"astrocyte\"):\n",
    "# If not using the sample data, set cell_type to None\n",
    "sample_data_type = \"neuron\"\n",
    "\n",
    "# Specify which file you'd like to segment from the img_file_list\n",
    "test_img_n = 0\n",
    "\n",
    "# If you are not using the sample data, please edit \"USER SPECIFIED\" as necessary.\n",
    "## Define the path to the directory that contains the input image folder.\n",
    "data_root_path = Path(\"USER SPECIFIED\")\n",
    "\n",
    "# Specify the file type of your raw data that will be analyzed. Ex) \".czi\" or \".tiff\"\n",
    "im_type = \"USER SPECIFIED\"\n",
    "\n",
    "## Specify which subfolder that contains the input data and the input data file extension\n",
    "in_data_path = data_root_path / \"USER SPECIFIED\"\n",
    "\n",
    "## Specify the output folder to save the segmentation outputs if.\n",
    "## If its not already created, the code below will creat it for you\n",
    "out_data_path = data_root_path / \"USER SPECIFIED\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If sample_data_type is set to \"neuron\" or \"astrocyte\", then the sample data is used and the directories are set\n",
    "if sample_data_type != None:\n",
    "    data_root_path, im_type, in_data_path, out_data_path = sample_input(sample_data_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path.exists(out_data_path):\n",
    "    Path.mkdir(out_data_path)\n",
    "    print(f\"making {out_data_path}\")\n",
    "\n",
    "img_file_list = list_image_files(in_data_path,im_type)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.DataFrame({\"Image Name\":img_file_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_name = img_file_list[test_img_n]\n",
    "\n",
    "img_data,meta_dict = read_czi_image(test_img_name)\n",
    "\n",
    "channel_names = meta_dict['name']\n",
    "img = meta_dict['metadata']['aicsimage']\n",
    "scale = meta_dict['scale']\n",
    "channel_axis = meta_dict['channel_axis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***EXTRACTION prototype - ER***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 1` - Select a channel for segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- select single channel containing the ER marker (channel number = user input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# INPUT\n",
    "###################\n",
    "ER_CH = 1\n",
    "raw_ER = select_channel_from_raw(img_data, ER_CH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***PRE-PROCESSING prototype - ER***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 2` - Rescale and smooth image**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- rescale intensity of composite image (min=0, max=1)\n",
    "- median filter (median size = user input)\n",
    "- gaussian filter (sigma = user input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# PRE_PROCESSING\n",
    "###################\n",
    "median_sz = 0\n",
    "gauss_sig = 0\n",
    "\n",
    "struct_img = scale_and_smooth(raw_ER,\n",
    "                              median_size = median_sz, \n",
    "                              gauss_sigma = gauss_sig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***CORE-PROCESSING prototype - ER***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 3` - Global + local thresholding (AICSSeg ‚Äì MO)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply MO thresholding method from the Allen Cell [aicssegmentation](https://github.com/AllenCell/aics-segmentation) package (threshold options = user input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# CORE_PROCESSING\n",
    "###################\n",
    "# segment the ER with this global and local thresholding method\n",
    "thresh_method = 'tri'\n",
    "cell_wise_min_area = 1200\n",
    "thresh_adj = 0.5\n",
    "\n",
    "bw_MO_test = masked_object_thresh(struct_img,\n",
    "                          global_method=thresh_method, \n",
    "                          cutoff_size=cell_wise_min_area, \n",
    "                          local_adjust=thresh_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 4` - ‚ÄòFilament‚Äô threshold method (AICSSeg)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- apply \"filament\"/\"vessel\" thresholding method (for tubular objects) from the Allen Cell [aicssegmentation](https://github.com/AllenCell/aics-segmentation) package (size scale and threshold cutoff = user input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the 2D or 3D versions of the AICSsegmentation filament filter with multiple scales\n",
    "fil_scale_1 = .5\n",
    "fil_cut_1 = 0.001\n",
    "\n",
    "fil_scale_2 = 1\n",
    "fil_cut_2 = 0.001\n",
    "\n",
    "fil_scale_3 = 0\n",
    "fil_cut_3 = 0\n",
    "\n",
    "fil_method = \"3D\"\n",
    "\n",
    "bw_filament_test = filament_filter_3(struct_img,\n",
    "                                    fil_scale_1,\n",
    "                                    fil_cut_1,\n",
    "                                    fil_scale_2,\n",
    "                                    fil_cut_2,\n",
    "                                    fil_scale_3,\n",
    "                                    fil_cut_3,\n",
    "                                    fil_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 5`- Combine Segmentations (logical or)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- combine the two segmentations with logical *OR*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two segmentations together\n",
    "bw_test = np.logical_or(bw_MO_test, bw_filament_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***POST-PROCESSING prototype - ER***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 6` - Remove small holes and objects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fill holes (hole size = user input)\n",
    "- remove small objects (object size = user input)\n",
    "- filter method (method = user input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# POST_PROCESSING\n",
    "###################\n",
    "hole_min_width = 0\n",
    "hole_max_width = 0\n",
    "\n",
    "small_object_width = 1\n",
    "\n",
    "fill_filter_method = \"3D\"\n",
    "\n",
    "cleaned_img2 = fill_and_filter_linear_size(bw_test, \n",
    "                                           hole_min=hole_min_width, \n",
    "                                           hole_max=hole_max_width, \n",
    "                                           min_size=small_object_width,\n",
    "                                           method=fill_filter_method)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***POST-POST-PROCESSING prototype - ER***\n",
    "\n",
    "> ###### We assume that the ER is one continuous object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`STEP 7` - Create one object (as unt16)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- label all ER \"objects\" 1/True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "# LABELING\n",
    "###################\n",
    "ER_labels = label_bool_as_uint16(cleaned_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ER_labels.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualize with `napari` 1**\n",
    "Visualize the first-pass segmentation and labeling with `napari`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer(title = \"ER\",\n",
    "                       ndisplay=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(\n",
    "    struct_img,\n",
    "    scale = scale,\n",
    "    name = \"ER Intensities\")\n",
    "\n",
    "viewer.add_image(\n",
    "    cleaned_img2,\n",
    "    scale = scale,\n",
    "    opacity=0.3,\n",
    "    name = \"ER Segmentation\")\n",
    "\n",
    "viewer.add_labels(\n",
    "    ER_labels,\n",
    "    scale = scale,\n",
    "    opacity=0.3,\n",
    "    name = \"ER Labels\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***EXTRACTION prototype - ER***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- save labeled ***ER*** (ER) as unsigned integer 16-bit tif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file_n = export_inferred_organelle(ER_labels, \"ER\", meta_dict, out_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F6D1; &#x270D; **User Input Required:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## When using the sample data in part 2, quantification is carried out on both the neuron and astrocyte data through\n",
    "## batch processing. to_batch = True copies the segmentation to the batch processing file location in addition to the\n",
    "## segmentation folder.\n",
    "\n",
    "to_batch = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### &#x1F3C3; **Run code; no user input required**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_batch and sample_data_type == 'neuron' or sample_data_type == 'astrocyte':\n",
    "    out_file_b = export_inferred_organelle(ER_labels, \"ER\", meta_dict, Path(os.getcwd()).parents[1] / \"sample_data\" /  \"batch_example\" / \"seg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define `_infer_ER` function**\n",
    "\n",
    "> ###### **üìù these functions mainly serve for downstream prototyping in the notebooks. Each step above has an independent function that is implemented in the plugin for easy of use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "#  infer_ER\n",
    "##########################\n",
    "def _infer_ER(\n",
    "              in_img: np.ndarray,\n",
    "              ER_ch: int,\n",
    "              median_sz: int,\n",
    "              gauss_sig: float,\n",
    "              MO_thresh_method: str,\n",
    "              MO_cutoff_size: float,\n",
    "              MO_thresh_adj: float,\n",
    "              fil_scale_1: float,\n",
    "              fil_cut_1: float,\n",
    "              fil_scale_2: float, \n",
    "              fil_cut_2: float, \n",
    "              fil_scale_3: float, \n",
    "              fil_cut_3: float,\n",
    "              fil_method: str,\n",
    "              min_hole_w: int,\n",
    "              max_hole_w: int,\n",
    "              small_obj_w: int,\n",
    "              fill_filter_method: str\n",
    "              ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Procedure to infer peroxisome from linearly unmixed input.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    in_img: \n",
    "        a 3d image containing all the channels\n",
    "    median_sz: \n",
    "        width of median filter for signal\n",
    "    gauss_sig: \n",
    "        sigma for gaussian smoothing of  signal\n",
    "    filament_scale: \n",
    "        scale (log_sigma) for filament filter\n",
    "    filament_cut: \n",
    "        threshold for filament fitered threshold\n",
    "    small_obj_w: \n",
    "        minimu object size cutoff for nuclei post-processing\n",
    "    Returns\n",
    "    -------------\n",
    "    peroxi_object\n",
    "        mask defined extent of peroxisome object\n",
    "    \"\"\"\n",
    "\n",
    "    ###################\n",
    "    # EXTRACT\n",
    "    ###################    \n",
    "    ER = select_channel_from_raw(in_img, ER_ch)\n",
    "\n",
    "    ###################\n",
    "    # PRE_PROCESSING\n",
    "    ###################    \n",
    "    # er = normalized_edge_preserving_smoothing(er)\n",
    "    struct_img =  scale_and_smooth(ER,\n",
    "                                   median_size = median_sz, \n",
    "                                   gauss_sigma = gauss_sig)\n",
    "\n",
    "    ###################\n",
    "    # CORE_PROCESSING\n",
    "    ###################\n",
    "    bw1 = masked_object_thresh(struct_img, \n",
    "                                    global_method=MO_thresh_method, \n",
    "                                    cutoff_size=MO_cutoff_size, \n",
    "                                    local_adjust=MO_thresh_adj)\n",
    "\n",
    "    bw2 = filament_filter_3(struct_img, fil_scale_1, fil_cut_1, fil_scale_2, fil_cut_2, fil_scale_3, fil_cut_3, fil_method)\n",
    "\n",
    "    struct_obj = np.logical_or(bw1, bw2)\n",
    "    \n",
    "    ###################\n",
    "    # POST_PROCESSING\n",
    "    ################### \n",
    "    struct_obj = fill_and_filter_linear_size(struct_obj, \n",
    "                                             hole_min=min_hole_w, \n",
    "                                             hole_max=max_hole_w, \n",
    "                                             min_size=small_obj_w,\n",
    "                                             method=fill_filter_method)\n",
    "\n",
    "    ###################\n",
    "    # LABELING\n",
    "    ###################\n",
    "    \n",
    "    # ENSURE THAT there is ONLY ONE ER\n",
    "    struct_obj = label_bool_as_uint16(struct_obj)\n",
    "\n",
    "    return struct_obj "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test  `_infer_ER` function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ER_object =  _infer_ER(\n",
    "        img_data,\n",
    "        ER_CH,\n",
    "        median_sz,\n",
    "        gauss_sig,\n",
    "        thresh_method,\n",
    "        cell_wise_min_area,\n",
    "        thresh_adj,\n",
    "        fil_scale_1,\n",
    "        fil_cut_1,\n",
    "        fil_scale_2,\n",
    "        fil_cut_2,\n",
    "        fil_scale_3,\n",
    "        fil_cut_3,\n",
    "        fil_method,\n",
    "        hole_min_width,\n",
    "        hole_max_width,\n",
    "        small_object_width,\n",
    "        fill_filter_method)\n",
    "\n",
    "_ER_object.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(ER_labels == _ER_object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualize with `napari` 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_labels(\n",
    "    _ER_object,\n",
    "    scale = scale,\n",
    "    opacity=0.3,\n",
    "    name = \"ER Object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbscreenshot(viewer, canvas_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### NEXT: INFER LIPID DROPLET\n",
    "\n",
    "proceed to [1.7_infer_lipid_droplet.ipynb](./1.7_infer_lipid_droplet.ipynb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "infer-subc-sample",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
