{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to infer_subc","text":"<p><code>infer_subc</code> aims to create a simple and extensible workflow of image analysis leveraging scipy image, and napari for reproducable analysis with an intuitive interface. </p> <p>This is a simple repo to collect code and documentations from the pilot project kicking off as part of the CZI Neurodegeneration Challenge Network (NDCN) Data Science Concierge program.  The PILOT study is a collaboration with Cohen lab at UNC (website, github) to migrate a multispectral imaging dataset of iPSCs which identifies sub-cellular components to a scalable cloud-based pipeline.  </p>"},{"location":"#overview","title":"Overview","text":"<p>In general we ware interested in making segmentations which are the inferred organelles for each cell.   Procedurally we will need to define some masking ROIs which correspond to the cellmask, wholecell (cellmask + dendrites) and cytoplasm (cellmask minus nucleus.)  THerefore we need to first infer nuclei, cellmask, and cytoplasm as the first steps.  </p> <p>From there the organelle segmentations are largely independent, and we will employ the cytoplasm (or cellmask for the nucleus segmentation) as a mask when collecting statistics about the individual organelle objects. </p> <p>Notebooks  found here provide the template</p>"},{"location":"#sub-cellular-object-inference-pipeline-overview","title":"Sub-Cellular object Inference PIPELINE OVERVIEW","text":""},{"location":"#goal-infer-sub-cellular-components-in-order-to-understand-interactome","title":"GOAL:  Infer sub-cellular components in order to understand interactome","text":"<p>To measure shape, position, size, and interaction of eight organelles/cellular components (Nuclei (NU), Lysosomes (LS),Mitochondria (MT), Golgi (GL), Peroxisomes (PO), Endoplasmic Reticulum (ER), Lipid Droplet (LD), and CELLMASK) during differentiation of iPSCs, in order to understand the Interactome / Spatiotemporal coordination.</p>"},{"location":"#summary-of-objectives","title":"summary of OBJECTIVES \u2705","text":"<ul> <li>robust inference of subcellular objects:</li> <li> <p>Nescessary masks and nuclei</p> <ul> <li> </li> <li> </li> <li> </li> </ul> </li> <li> <p>individual organelles</p> <ul> <li> </li> <li> </li> <li> </li> <li> </li> <li> </li> <li> </li> </ul> </li> </ul>"},{"location":"#1-infer-nuclei","title":"1\ufe0f\u20e3. infer NUCLEI","text":""},{"location":"#2-infer-cellmask-steps-2-9-depend-on-establishing-a-good-solution-here","title":"2\ufe0f\u20e3. Infer CELLMASK (\ud83d\udea8\ud83d\udea8\ud83d\udea8\ud83d\udea8 Steps 2-9 depend on establishing a good solution here.)","text":""},{"location":"#3-infer-cytoplasm","title":"3\ufe0f\u20e3. Infer CYTOPLASM","text":""},{"location":"#4-infer-lysosomes","title":"4\ufe0f\u20e3. Infer LYSOSOMES","text":""},{"location":"#5-infer-mitochondria","title":"5\ufe0f\u20e3. Infer MITOCHONDRIA","text":""},{"location":"#6-infer-golgi-complex","title":"6\ufe0f\u20e3. Infer GOLGI complex","text":""},{"location":"#7-infer-peroxisomes","title":"7\ufe0f\u20e3. Infer PEROXISOMES","text":""},{"location":"#8-infer-endoplasmic-reticulum","title":"8\ufe0f\u20e3. Infer ENDOPLASMIC RETICULUM","text":""},{"location":"#9-infer-lb","title":"9\ufe0f\u20e3. Infer LB","text":""},{"location":"#frameworks-resources","title":"FRAMEWORKS &amp; RESOURCES","text":""},{"location":"#note-pipeline-tool-and-design-choices","title":"NOTE: PIPELINE TOOL AND DESIGN CHOICES?","text":"<p>Early in the develepmont we chose to leverage the Allen Cell &amp; Structure Segmenter and napari plugin.   Although the logic of our multi-channel organelle segmentations required us to fork and modify their code, we hope it porvides a stable, but evolving base which will help manage accumulationof technical debt.   In addition to the overall logic, we particulary leverage their <code>workflow</code> paradigm which is crucial for leveraging the napari plugin interface of widgets to the segmentation workflows.</p>"},{"location":"#the-allen-cell-structure-segmenter","title":"\u200bThe Allen Cell &amp; Structure Segmenter","text":"<p>\u200bThe Allen Cell &amp; Structure Segmenter is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images: <code>aicssegmentation</code> package.  This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.</p> <p>For full documentation visit github.io.com/infer_subc. Robust inference of subcellular objects:</p>"},{"location":"config/","title":"install + config","text":"<p>environment</p> <p>mkdocks note</p>"},{"location":"framework/","title":"reproducable imaging framework \ud83d\udea7 WIP \ud83d\udea7","text":"<p>\ud83d\udea7 WIP \ud83d\udea7 </p> <p>SCohenLab 2D Image Processing  </p> <p>Pipelines are [GET A GOOD DEFINITION / LINK].  They enable repoducability and scalabillity.</p>"},{"location":"framework/#pipeline-framework-overview","title":"PIPELINE FRAMEWORK OVERVIEW","text":"<p>As a general framework for our data processing pipeline we are defining 4 steps: 1. GOAL SETTING \u270d 2. DATA CREATION 3. IMAGE PROCESSING  \u2699\ufe0f\ud83e\ude7b\ud83d\udd2c 4. QUANTIFICATION \ud83d\udccf\ud83d\udcd0\ud83e\uddee</p>"},{"location":"framework/#1-goal-setting","title":"1. GOAL SETTING \u270d","text":"<p>Here we make explicit what we are trying to accomplish.</p>"},{"location":"framework/#goal-infer-sub-cellular-components-in-order-to-understand-interactome","title":"GOAL:  Infer sub-cellular components in order to understand interactome","text":"<p>To measure shape, position, size, and interaction of eight organelles/cellular components (Nuclei (NU), Lysosomes (LS),Mitochondria (MT), Golgi (GL), Peroxisomes (PO), Endoplasmic Reticulum (ER), Lipid Droplet (LD), and CELLMASK) during differentiation of iPSCs, in order to understand the Interactome / Spatiotemporal coordination.</p> <p>As part of goal setting we will also enumerate the specific tasks that need to be done to reach the goal.</p>"},{"location":"framework/#summary-of-objectives","title":"summary of OBJECTIVES \u2705","text":"<ul> <li>robust inference of subcellular objects:</li> <li>1\ufe0f\u20e3-cellmask</li> <li>2\ufe0f\u20e3-nuclei</li> <li>3\ufe0f\u20e3-cytoplasm</li> <li>4\ufe0f\u20e3-lysosome</li> <li>5\ufe0f\u20e3-mitochondria</li> <li>6\ufe0f\u20e3-golgi</li> <li>7\ufe0f\u20e3-peroxisome</li> <li>8\ufe0f\u20e3-endoplasmic reticulum</li> <li>9\ufe0f\u20e3-lipid body</li> </ul>"},{"location":"framework/#2-data-creation","title":"2. DATA CREATION","text":"<p>The second step is to get the data.  Capturing the data could be either from running the experiment, or mining a database.   Implicitly we need to also capture all the assumptions and methodologies, or meta-data.</p> <p>METHODS:\ud83d\udcda\ud83d\udcda</p> <p>iPSC lines prepared and visualized on Zeiss Microscopes. 32 channel multispectral images collected.  Linear Unmixing in  ZEN Blue software with target emission spectra yields 8 channel image outputs.  Channels correspond to: Nuclei (NU), Lysosomes (LS),Mitochondria (MT), Golgi (GL), Peroxisomes (PO), Endoplasmic Reticulum (ER), Lipid Droplet (LD), and a \u201cresidual\u201d signal.</p> <p>Meta-DATA \ud83c\udffa (artifacts)  - Microcope settings  - OME scheme - Experimenter observations - Sample, bio-replicate, image numbers, condition values, etc  - Dates  - File structure, naming conventions  - etc.</p>"},{"location":"framework/#data-linearly-un-mixed-flourescence-images-in-czi-files","title":"DATA: linearly un-mixed flourescence images in .czi files","text":"<p>The bulk of the code in this repo is to solve this step:  processing the \"raw\" data to infer the locations of sub-cellular oranelles.</p>"},{"location":"framework/#3-image-processing","title":"3. IMAGE PROCESSING  \u2699\ufe0f\ud83e\ude7b\ud83d\udd2c","text":""},{"location":"framework/#inference-of-sub-cellular-objects","title":"INFERENCE OF SUB-CELLULAR OBJECTS","text":"<p>The imported images have already been pre-processed to transform the 32 channel spectral measuremnts into \"linearly unmixed\" images which estimate independently labeled sub-cellular components.  Thes 7 channels (plus a residual \"non-linear\" signal) will be used to infer the shapes and extents of these sub-cellular components.  A single \"optimal\" Z slice is chosen for each image for subsequent 2D analysis. We will perform computational image analysis on the pictures to segment (or binarize) the components of interest for measurement.  In other procedures we can used these labels as \"ground truth\" labels to train machine learning models to automatically perform the inference of these objects. Pseudo-independent processing of the imported multi-channel image to acheive each of the 9 objecives stated above.  i.e. infering: NUCLEI, CELLMASK, CYTOPLASM, LYSOSOME, MITOCHONDRIA, GOLGI COMPLEX, PEROZISOMES, ENDOPLASMIC RETICULUM, and LIPID BODIES</p>"},{"location":"framework/#general-flow-for-infering-objects-via-segmentation","title":"General flow for infering objects via segmentation","text":"<ul> <li>(extraction) </li> <li>Pre-processing \ud83c\udf12</li> <li>Core-processing (thresholding) \ud83c\udf15</li> <li>Post-processing  \ud83c\udf18</li> <li>(post-postprocessing) </li> </ul>"},{"location":"framework/#qc-wip-depricated","title":"~~QC \ud83d\udea7 WIP \ud83d\udea7~~ DEPRICATED","text":"<p>Finally, once we have inferred the organelle objects, we need to quantify them. These statistics, and the relationships among them will constitute the \"interactome\".</p>"},{"location":"framework/#4-quantification","title":"4. QUANTIFICATION \ud83d\udccf\ud83d\udcd0\ud83e\uddee","text":"<p>SUBCELLULAR COMPONENT METRICS - general   -  extent    -  size   -  position -  contacts (cross-stats) -  radial projection and depth stats    - radial distribution (in cytosol)   - depth distribution   - zernike moments</p>"},{"location":"framework/#additional-considerations","title":"ADDITIONAL CONSIDERATIONS","text":""},{"location":"framework/#note-pipeline-tool-and-design-choices","title":"NOTE: PIPELINE TOOL AND DESIGN CHOICES?","text":"<p>We want to leverage the Allen Cell &amp; Structure Segmenter.  It has been wrapped as a napari-plugin but fore the workflow we are proving out here we will want to call the <code>aicssegmentation</code> package directly.</p>"},{"location":"framework/#the-allen-cell-structure-segmenter","title":"\u200bThe Allen Cell &amp; Structure Segmenter","text":"<p>\u200bThe Allen Cell &amp; Structure Segmenter is a Python-based open source toolkit developed at the Allen Institute for Cell Science for 3D segmentation of intracellular structures in fluorescence microscope images. This toolkit brings together classic image segmentation and iterative deep learning workflows first to generate initial high-quality 3D intracellular structure segmentations and then to easily curate these results to generate the ground truths for building robust and accurate deep learning models. The toolkit takes advantage of the high replicate 3D live cell image data collected at the Allen Institute for Cell Science of over 30 endogenous fluorescently tagged human induced pluripotent stem cell (hiPSC) lines. Each cell line represents a different intracellular structure with one or more distinct localization patterns within undifferentiated hiPS cells and hiPSC-derived cardiomyocytes.</p> <p>More details about Segmenter can be found at https://allencell.org/segmenter In order to leverage the A</p>"},{"location":"pipeline/","title":"general worfklow / data pipeline","text":"<p>\ud83d\udea7 WIP \ud83d\udea7 </p>"},{"location":"pipeline/#putative-workflow","title":"PUTATIVE WORKFLOW","text":""},{"location":"pipeline/#workflow-editor-plugin","title":"WORKFLOW EDITOR PLUGIN","text":"<ul> <li>FINE-TUNE SEGMENTATIONS</li> <li>export workflow.jsons<ul> <li>masks:</li> <li>nuclei</li> <li>cellmask</li> <li>cytoplasm</li> <li>organelles:</li> <li>lyso</li> <li>mito</li> <li>golgi</li> <li>perox</li> <li>ER</li> <li>LD</li> </ul> </li> </ul>"},{"location":"pipeline/#batchprocess-workflow","title":"BATCHPROCESS WORKFLOW","text":"<ul> <li>BATCH PROCESS</li> <li>load workflow.jsons for: </li> <li>masks<ul> <li>export: masks .tiff as stack (nuclei, cellmask, cytoplasm)</li> </ul> </li> <li>organelles<ul> <li>export individual .tiffs</li> </ul> </li> </ul>"},{"location":"pipeline/#notebook-or-future-plugin","title":"NOTEBOOK ~~OR FUTURE PLUGIN~~","text":"<ul> <li>COLLECT ORGANELLE STATS</li> <li>extract masks.tiffs as individual<ul> <li>nuclei, cellmask, cytoplasm</li> </ul> </li> <li>collect regionprops for all organelles<ul> <li>export .csvs</li> </ul> </li> </ul>"},{"location":"infer_subc/organelles/","title":"organelles sub-module","text":"<p>The code in this sub-module have the routines to perform a (hopefully) robust inference of subcellular objects:</p> <ul> <li>1\ufe0f\u20e3-cellmask</li> <li>2\ufe0f\u20e3-nuclei</li> <li>3\ufe0f\u20e3-cytoplasm</li> <li>4\ufe0f\u20e3-lysosome</li> <li>5\ufe0f\u20e3-mitochondria</li> <li>6\ufe0f\u20e3-golgi</li> <li>7\ufe0f\u20e3-peroxisome</li> <li>8\ufe0f\u20e3-endoplasmic reticulum</li> <li>9\ufe0f\u20e3-lipid body</li> </ul> <p>From the results of the  1\ufe0f\u20e3-cellmask, 2\ufe0f\u20e3-nuclei, the  3\ufe0f\u20e3-cytoplasm, a mask of the cytoplasm for each cell of interest is derived.</p> <p>By \"inference of sub-cellular objects\" we mean assigning each pixel to belonging to an organell as estimated from the florescence image in the apropriate channel.  This is done here by image processing and thresholding.</p>"},{"location":"infer_subc/organelles/#organelles-submodule","title":"<code>organelles</code> submodule","text":""},{"location":"infer_subc/overview/","title":"overview","text":""},{"location":"infer_subc/overview/#infer_subc","title":"infer_subc","text":"<p>This module contains code to segment organelles from multi-channel images generated by SCohenLab.   The \"raw\" data files are the output of linear unmixing of multi-spectral imaging capture in their lab.</p> <p>NOTE:  this is designed to work with a second repo <code>organelle-segmenter-plugin</code> which instantiates a plugin for napari.</p> <p>In addition to the python based module there are a series of expository Jupyter notebooks which demonstrate the logic and development of the library.</p>"},{"location":"infer_subc/overview/#organelles","title":"organelles","text":"<p>These are function to infer each specific organelles from their respective channels: Nuclei, Cellmask (Cell Membrane TBD), Lysosome, Mitochondria, Golgi, Peroxisome, Endoplasmic Reticulum, and Lipid bodies.</p>"},{"location":"infer_subc/overview/#core","title":"core","text":"<p>This submodule contains functions for handling the file systems and input / output, as well as the core image processing.  The bulk of the image processing functions are simple wrappers to <code>scipy</code> and <code>numpy</code> image processing functions as well as functions from the Allen Cell Segmentation (<code>aicssegmentaion</code>) library.  <code>utils.img</code> contains most of the specific image processing routines employed in segmentation, while <code>utils.file_io</code> handles loading and saving the data files.</p>"},{"location":"infer_subc/overview/#utils","title":"utils","text":"<p>This submodule contains functions for handling the file systems and input / output, as well as the core image processing.  The bulk of the image processing functions are simple wrappers to <code>scipy</code> and <code>numpy</code> image processing functions as well as functions from the Allen Cell Segmentation (<code>aicssegmentaion</code>) library.  <code>utils.img</code> contains most of the specific image processing routines employed in segmentation, while <code>utils.file_io</code> handles loading and saving the data files.</p>"},{"location":"infer_subc/overview/#workflows","title":"workflows","text":"<p>This submodule (hard forked from <code>aicssegmentation</code>) works with the napari plugin to provide interactive GUI control of the segmentaitons.</p>"},{"location":"infer_subc/overview/#etc","title":"etc","text":""},{"location":"infer_subc/overview/#batch","title":"batch","text":"<p>This submodule contains functions to process each multi-channel/spectral image to infer ALL organelles</p>"},{"location":"infer_subc/overview/#constants-exceptions","title":"constants, exceptions","text":""},{"location":"infer_subc/workflow/","title":"infer_subc/workflows","text":"<p>Code for classes which interface with the sibling napari plugin repo <code>organelle-segmenter-plugin</code> documented at ndcn.github.io/organelle-segmenter-plugin</p>"},{"location":"infer_subc/workflow/#infer_subcworkflow-for-napari-plugin","title":"infer_subc/workflow for napari plugin","text":"<p>The <code>workflow</code> sub-module is designed to interface with this repo (<code>infer_subc</code>) and the sibling napari plugin repo organelle-segmenter-plugin</p>"},{"location":"infer_subc/workflow/#workflow-sub-modules","title":"workflow sub-modules","text":""},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow.Workflow","title":"<code>Workflow</code>","text":"<p>Represents an executable aics-segmentation workflow This class provides the functionality to run a workflow using an image input according to the steps defined in its WorkflowDefinition.</p> Source code in <code>infer_subc/workflow/workflow.py</code> <pre><code>class Workflow:\n\"\"\"\n    Represents an executable aics-segmentation workflow\n    This class provides the functionality to run a workflow using an image input\n    according to the steps defined in its WorkflowDefinition.\n    \"\"\"\n\n    def __init__(self, workflow_definition: WorkflowDefinition, input_image: np.ndarray):\n        if workflow_definition is None:\n            raise ArgumentNullError(\"workflow_definition\")\n        if input_image is None:\n            raise ArgumentNullError(\"input_image\")\n        self._definition: WorkflowDefinition = workflow_definition\n        self._starting_image: np.ndarray = input_image\n        self._next_step: int = 0  # Next step to execute\n        self._results: List = list()  # Store most recent step results\n\n    @property\n    def workflow_definition(self) -&gt; WorkflowDefinition:\n        return self._definition\n\n    def reset(self):\n\"\"\"\n        Reset the workflow so it can be run again\n        \"\"\"\n        self._next_step = 0\n        self._results = list()\n\n    def get_next_step(self) -&gt; WorkflowStep:\n\"\"\"\n        Get the next step to be performed\n\n        Params:\n            none: None\n\n        Returns\n            (WorkflowStep): next WorkflowStep object to perform on image\n            None if all steps have already been executed\n        \"\"\"\n        if self._next_step &gt;= len(self._definition.steps):\n            return None\n        return self._definition.steps[self._next_step]\n\n    def execute_next(self, parameters: Dict[str, Any] = None) -&gt; np.ndarray:\n\"\"\"\n        Execute the next workflow step.\n\n        Params:\n            parameters: Optional dictionary of parameter inputs to use when executing the step\n                        If parameters are not provided, the step's default parameters will be used\n\n        Returns\n            result (np.ndarray): resultant image from running the\n            next workflow step\n        \"\"\"\n\n        step = self.get_next_step()\n\n        log.info(f\"Executing step #{step.step_number}\")\n        # Pick which image to perform the workflow step on\n        image: np.ndarray = None\n\n        if self._next_step == 0:\n            # First image, so use the starting image for the next workflow step\n            image = [self._starting_image]\n        elif self.is_done():\n            # No more workflow steps to perform\n            # TODO: what to do if done with workflow\n            #  but execute_next is prompted?\n            # printing message for now\n            log.info(\"No steps left to run\")\n        else:\n            image = list()\n            for i in step.parent:\n                res = self.get_result(i - 1)  # parents are 1 indexed\n                image.append(res)\n\n        result: np.ndarray = self.get_next_step().execute(image, parameters or step.parameter_values)\n        self._results.append(result)\n\n        # Only increment after running step\n        self._next_step += 1\n        return result\n\n    # TODO maybe change this to match the step number instead?\n    #      Review when we implement rerunning single workflow steps\n    def get_result(self, step_index: int) -&gt; np.ndarray:\n\"\"\"\n        Get the result image for a workflow step.\n\n        You must call execute() on the workflow step in order to\n        produce a result first before calling this function.\n\n        Params:\n            step_index (int): index of the WorkflowStep in the\n            workflowengine to get the result image of.\n\n        Returns\n            self.image (np.ndarray): Result of performing workflow step\n                                     on the given image\n                                     None if step has not been executed yet.\n        \"\"\"\n        if step_index &lt; 0:\n            return self._starting_image\n        if step_index &gt;= len(self._results):\n            return None  # returns None if the WorkflowStep has not been executed.\n\n        return self._results[step_index]\n\n    def get_most_recent_result(self) -&gt; np.ndarray:\n\"\"\"\n        Get the result from the last executed WorkflowStep.\n\n        Params:\n           none: None\n\n        Returns\n            (np.ndarray): Result of the last executed WorkflowStep,\n                            returns the starting image if no Workflowsteps have\n                            been run.\n        \"\"\"\n        if self._next_step == 0:\n            return self._starting_image  # TODO does this behavior make sense? Return None instead?\n        else:\n            return self.get_result(self._next_step - 1)\n\n    def execute_all(self) -&gt; np.ndarray:\n\"\"\"\n        Execute all steps in the Workflow\n        Note: default parameters will be used to execute the steps. To execute a step\n              with user-provided parameters, use execute_next()\n\n        Params:\n            none: None\n\n        Returns\n            (np.ndarray): Result of the final WorkflowStep.\n        \"\"\"\n        self.reset()\n        while not self.is_done():\n            self.execute_next()\n        return self.get_most_recent_result()\n\n    def execute_step(self, i: int, parameters: Dict[str, Any], selected_image: List[Image]) -&gt; np.ndarray:\n\"\"\"\n\n        Args:\n            i: step number (0 indexed) that you want to run\n\n        Returns\n\n        \"\"\"\n        # TODO: discuss using selected layer for all types\n        step_to_run = self._definition.steps[i]\n\n        image = [i.data for i in selected_image]\n        result: np.ndarray = step_to_run.execute(image, parameters or step_to_run.parameter_values)\n\n        if len(self._results) &lt;= i:\n            # this is the first time running this step\n            self._results.append(result)\n        else:\n            # this step has been run before so replacing old value\n            self._results[i] = result\n\n        return result\n\n    def is_done(self) -&gt; bool:\n\"\"\"\n        Check if all WorkflowSteps have been executed.\n\n        Params:\n            none: None\n\n        Returns\n            (bool): True if all WorkflowSteps have been executed, False if not\n        \"\"\"\n        return self._next_step &gt;= len(self._definition.steps)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow.Workflow.execute_all","title":"<code>execute_all()</code>","text":"<p>Execute all steps in the Workflow</p> default parameters will be used to execute the steps. To execute a step <p>with user-provided parameters, use execute_next()</p> <p>Parameters:</p> Name Type Description Default <code>none</code> <p>None</p> required <p>Returns     (np.ndarray): Result of the final WorkflowStep.</p> Source code in <code>infer_subc/workflow/workflow.py</code> <pre><code>def execute_all(self) -&gt; np.ndarray:\n\"\"\"\n    Execute all steps in the Workflow\n    Note: default parameters will be used to execute the steps. To execute a step\n          with user-provided parameters, use execute_next()\n\n    Params:\n        none: None\n\n    Returns\n        (np.ndarray): Result of the final WorkflowStep.\n    \"\"\"\n    self.reset()\n    while not self.is_done():\n        self.execute_next()\n    return self.get_most_recent_result()\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow.Workflow.execute_next","title":"<code>execute_next(parameters=None)</code>","text":"<p>Execute the next workflow step.</p> <p>Parameters:</p> Name Type Description Default <code>parameters</code> <code>Dict[str, Any]</code> <p>Optional dictionary of parameter inputs to use when executing the step         If parameters are not provided, the step's default parameters will be used</p> <code>None</code> <p>Returns     result (np.ndarray): resultant image from running the     next workflow step</p> Source code in <code>infer_subc/workflow/workflow.py</code> <pre><code>def execute_next(self, parameters: Dict[str, Any] = None) -&gt; np.ndarray:\n\"\"\"\n    Execute the next workflow step.\n\n    Params:\n        parameters: Optional dictionary of parameter inputs to use when executing the step\n                    If parameters are not provided, the step's default parameters will be used\n\n    Returns\n        result (np.ndarray): resultant image from running the\n        next workflow step\n    \"\"\"\n\n    step = self.get_next_step()\n\n    log.info(f\"Executing step #{step.step_number}\")\n    # Pick which image to perform the workflow step on\n    image: np.ndarray = None\n\n    if self._next_step == 0:\n        # First image, so use the starting image for the next workflow step\n        image = [self._starting_image]\n    elif self.is_done():\n        # No more workflow steps to perform\n        # TODO: what to do if done with workflow\n        #  but execute_next is prompted?\n        # printing message for now\n        log.info(\"No steps left to run\")\n    else:\n        image = list()\n        for i in step.parent:\n            res = self.get_result(i - 1)  # parents are 1 indexed\n            image.append(res)\n\n    result: np.ndarray = self.get_next_step().execute(image, parameters or step.parameter_values)\n    self._results.append(result)\n\n    # Only increment after running step\n    self._next_step += 1\n    return result\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow.Workflow.execute_step","title":"<code>execute_step(i, parameters, selected_image)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>i</code> <code>int</code> <p>step number (0 indexed) that you want to run</p> required <p>Returns</p> Source code in <code>infer_subc/workflow/workflow.py</code> <pre><code>def execute_step(self, i: int, parameters: Dict[str, Any], selected_image: List[Image]) -&gt; np.ndarray:\n\"\"\"\n\n    Args:\n        i: step number (0 indexed) that you want to run\n\n    Returns\n\n    \"\"\"\n    # TODO: discuss using selected layer for all types\n    step_to_run = self._definition.steps[i]\n\n    image = [i.data for i in selected_image]\n    result: np.ndarray = step_to_run.execute(image, parameters or step_to_run.parameter_values)\n\n    if len(self._results) &lt;= i:\n        # this is the first time running this step\n        self._results.append(result)\n    else:\n        # this step has been run before so replacing old value\n        self._results[i] = result\n\n    return result\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow.Workflow.get_most_recent_result","title":"<code>get_most_recent_result()</code>","text":"<p>Get the result from the last executed WorkflowStep.</p> <p>Parameters:</p> Name Type Description Default <code>none</code> <p>None</p> required <p>Returns     (np.ndarray): Result of the last executed WorkflowStep,                     returns the starting image if no Workflowsteps have                     been run.</p> Source code in <code>infer_subc/workflow/workflow.py</code> <pre><code>def get_most_recent_result(self) -&gt; np.ndarray:\n\"\"\"\n    Get the result from the last executed WorkflowStep.\n\n    Params:\n       none: None\n\n    Returns\n        (np.ndarray): Result of the last executed WorkflowStep,\n                        returns the starting image if no Workflowsteps have\n                        been run.\n    \"\"\"\n    if self._next_step == 0:\n        return self._starting_image  # TODO does this behavior make sense? Return None instead?\n    else:\n        return self.get_result(self._next_step - 1)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow.Workflow.get_next_step","title":"<code>get_next_step()</code>","text":"<p>Get the next step to be performed</p> <p>Parameters:</p> Name Type Description Default <code>none</code> <p>None</p> required <p>Returns     (WorkflowStep): next WorkflowStep object to perform on image     None if all steps have already been executed</p> Source code in <code>infer_subc/workflow/workflow.py</code> <pre><code>def get_next_step(self) -&gt; WorkflowStep:\n\"\"\"\n    Get the next step to be performed\n\n    Params:\n        none: None\n\n    Returns\n        (WorkflowStep): next WorkflowStep object to perform on image\n        None if all steps have already been executed\n    \"\"\"\n    if self._next_step &gt;= len(self._definition.steps):\n        return None\n    return self._definition.steps[self._next_step]\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow.Workflow.get_result","title":"<code>get_result(step_index)</code>","text":"<p>Get the result image for a workflow step.</p> <p>You must call execute() on the workflow step in order to produce a result first before calling this function.</p> <p>Parameters:</p> Name Type Description Default <code>step_index</code> <code>int</code> <p>index of the WorkflowStep in the</p> required <p>Returns     self.image (np.ndarray): Result of performing workflow step                              on the given image                              None if step has not been executed yet.</p> Source code in <code>infer_subc/workflow/workflow.py</code> <pre><code>def get_result(self, step_index: int) -&gt; np.ndarray:\n\"\"\"\n    Get the result image for a workflow step.\n\n    You must call execute() on the workflow step in order to\n    produce a result first before calling this function.\n\n    Params:\n        step_index (int): index of the WorkflowStep in the\n        workflowengine to get the result image of.\n\n    Returns\n        self.image (np.ndarray): Result of performing workflow step\n                                 on the given image\n                                 None if step has not been executed yet.\n    \"\"\"\n    if step_index &lt; 0:\n        return self._starting_image\n    if step_index &gt;= len(self._results):\n        return None  # returns None if the WorkflowStep has not been executed.\n\n    return self._results[step_index]\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow.Workflow.is_done","title":"<code>is_done()</code>","text":"<p>Check if all WorkflowSteps have been executed.</p> <p>Parameters:</p> Name Type Description Default <code>none</code> <p>None</p> required <p>Returns     (bool): True if all WorkflowSteps have been executed, False if not</p> Source code in <code>infer_subc/workflow/workflow.py</code> <pre><code>def is_done(self) -&gt; bool:\n\"\"\"\n    Check if all WorkflowSteps have been executed.\n\n    Params:\n        none: None\n\n    Returns\n        (bool): True if all WorkflowSteps have been executed, False if not\n    \"\"\"\n    return self._next_step &gt;= len(self._definition.steps)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow.Workflow.reset","title":"<code>reset()</code>","text":"<p>Reset the workflow so it can be run again</p> Source code in <code>infer_subc/workflow/workflow.py</code> <pre><code>def reset(self):\n\"\"\"\n    Reset the workflow so it can be run again\n    \"\"\"\n    self._next_step = 0\n    self._results = list()\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_config.ConfigurationException","title":"<code>ConfigurationException</code>","text":"<p>         Bases: <code>Exception</code></p> <p>Raised when errors are encountered reading from Configuration files</p> Source code in <code>infer_subc/workflow/workflow_config.py</code> <pre><code>class ConfigurationException(Exception):\n\"\"\"\n    Raised when errors are encountered reading from Configuration files\n    \"\"\"\n\n    pass\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_config.WorkflowConfig","title":"<code>WorkflowConfig</code>","text":"<p>Provides access to structure workflow configuration</p> Source code in <code>infer_subc/workflow/workflow_config.py</code> <pre><code>class WorkflowConfig:\n\"\"\"\n    Provides access to structure workflow configuration\n    \"\"\"\n\n    def __init__(self):\n        self._all_functions = None\n        self._available_workflow_names = None\n\n    def get_available_workflows(self) -&gt; List[str]:\n\"\"\"\n        Get the list of all workflows available through configuration\n        \"\"\"\n        if self._available_workflow_names is None:\n            json_list = sorted(Directories.get_structure_config_dir().glob(\"conf_*.json\"))\n            self._available_workflow_names = [p.stem[5:] for p in json_list]\n\n        return self._available_workflow_names\n\n    def get_all_functions(self) -&gt; List[SegmenterFunction]:\n\"\"\"\n        Get the list of all available Functions from configuration\n        \"\"\"\n        if self._all_functions is None:\n            path = Directories.get_structure_config_dir() / \"all_functions.json\"\n\n            try:\n                with open(path) as file:\n                    obj = json.load(file)\n                    self._all_functions = self._all_functions_decoder(obj)\n            except Exception as ex:\n                raise ConfigurationException(f\"Error reading json configuration from {path}\") from ex\n\n        return self._all_functions\n\n    def get_workflow_definition(self, workflow_name: str) -&gt; WorkflowDefinition:  # PrebuiltWorkflowDefinition:\n\"\"\"\n        Get a WorkflowDefinition for the given workflow from the corresponding\n        prebuilt json structure config\n        \"\"\"\n        if workflow_name is None or len(workflow_name.strip()) == 0:\n            raise ValueError(\"workflow_name cannot be empty\")\n\n        if workflow_name not in self.get_available_workflows():\n            raise ValueError(f\"No workflow configuration available for {workflow_name}\")\n\n        path = Directories.get_structure_config_dir() / f\"conf_{workflow_name}.json\"\n\n        return self.get_workflow_definition_from_config_file(path, workflow_name, prebuilt=True)\n\n    def get_workflow_definition_from_config_file(\n        self, file_path: Path, workflow_name: str = None, prebuilt: bool = False\n    ) -&gt; WorkflowDefinition:\n\"\"\"\n        Get a WorkflowDefinition based off the given json configuration file\n        \"\"\"\n        if file_path.suffix.lower() != \".json\":\n            raise ValueError(\"Workflow configuration file must be a json file with .json file extension.\")\n\n        with open(file_path) as file:\n            try:\n                obj = json.load(file)\n                # print(obj)\n                return self._workflow_decoder(obj, workflow_name or file_path.stem, prebuilt)\n            except Exception as ex:\n                raise ConfigurationException(f\"Error reading json configuration from {file_path}\") from ex\n\n    def save_workflow_definition_as_json(self, workflow_definition: WorkflowDefinition, output_file_path: Path):\n\"\"\"\n        Save a WorkflowDefinition as a json config file\n        \"\"\"\n        if output_file_path.suffix.lower() != \".json\":\n            raise ValueError(\"Workflow configuration file save path must have a .json extension.\")\n\n        with open(output_file_path, \"w\") as file:\n            json.dump(self._workflow_encoder(workflow_definition), file, indent=4, sort_keys=True)\n\n    def _all_functions_decoder(self, obj: Dict) -&gt; List[SegmenterFunction]:\n\"\"\"\n        Decode Functions config (all_functions.json)\n        \"\"\"\n\n        def build_function_parameter(name: str, data: Dict):\n            return FunctionParameter(\n                name=name,\n                widget_type=WidgetType.from_str(data[\"widget_type\"]),\n                data_type=data[\"data_type\"],\n                min_value=data.get(\"min\", None),\n                max_value=data.get(\"max\", None),\n                increment=data.get(\"increment\", None),\n                options=data.get(\"options\", None),\n            )\n\n        functions = list()\n        for function_k, function_v in obj.items():\n            function = SegmenterFunction(\n                name=function_k,\n                display_name=function_v[\"name\"],\n                function=function_v[\"python::function\"],\n                module=function_v[\"python::module\"],\n            )\n\n            if function_v.get(\"parameters\") is not None and len(function_v[\"parameters\"]) &gt; 0:\n                params = dict()\n\n                for param_k, param_v in function_v[\"parameters\"].items():\n                    param_name = param_k\n                    params[param_name] = list()\n\n                    if isinstance(param_v, dict):\n                        params[param_name].append(build_function_parameter(param_name, param_v))\n                    elif isinstance(param_v, list):\n                        for item in param_v:\n                            params[param_name].append(build_function_parameter(param_name, item))\n\n                function.parameters = params\n\n            functions.append(function)\n\n        return functions\n\n    def _workflow_decoder(self, obj: Dict, workflow_name: str, prebuilt: bool = False) -&gt; WorkflowDefinition:\n\"\"\"\n        Decode Workflow config (conf_{workflow_name}.json)\n        \"\"\"\n        functions = self.get_all_functions()\n        steps: List[WorkflowStep] = list()\n        for step_k, step_v in obj.items():\n            # print(f\"step_k{step_k}  - step_v{step_v}\")\n\n            step_number = int(step_k)\n            function_id = step_v[\"function\"]\n            function = next(filter(lambda f: f.name == function_id, functions), None)\n\n            if function is None:\n                raise ConfigurationException(\n                    f\"Could not find a Segmenter function matching the function identifier &lt;{function_id}&gt;.\"\n                )\n\n            if isinstance(step_v[\"parent\"], list):\n                parent = step_v[\"parent\"]\n            else:\n                parent = [step_v[\"parent\"]]\n\n            step = WorkflowStep(\n                category=WorkflowStepCategory.from_str(step_v[\"category\"]),\n                function=function,\n                step_number=step_number,\n                parent=parent,\n            )\n\n            if step_v.get(\"parameter_values\") is not None and len(step_v[\"parameter_values\"]) &gt; 0:\n                param_defaults = dict()\n\n                for param_k, param_v in step_v[\"parameter_values\"].items():\n                    param_name = param_k\n                    param_defaults[param_name] = param_v\n\n                step.parameter_values = param_defaults\n            # print(f\"adding step {step_number}\")\n            steps.append(step)\n\n        steps.sort(key=lambda s: s.step_number)\n\n        return WorkflowDefinition(workflow_name, steps, prebuilt=prebuilt)\n\n    def _workflow_encoder(self, workflow_definition: WorkflowDefinition) -&gt; Dict:\n\"\"\"\n        Encode a WorkflowDefinition to a json dictionary\n        \"\"\"\n\n        # TODO add header / version ?\n        result = dict()\n        for step in workflow_definition.steps:\n            step_number = str(step.step_number)\n            parent = step.parent[0] if len(step.parent) == 1 else step.parent\n\n            step_dict = {\n                step_number: {\"function\": step.function.name, \"category\": step.category.value, \"parent\": parent}\n            }\n            if step.parameter_values is not None:\n                step_dict[step_number].update({\"parameter_values\": step.parameter_values})\n\n            result.update(step_dict)\n\n        return result\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_config.WorkflowConfig.get_all_functions","title":"<code>get_all_functions()</code>","text":"<p>Get the list of all available Functions from configuration</p> Source code in <code>infer_subc/workflow/workflow_config.py</code> <pre><code>def get_all_functions(self) -&gt; List[SegmenterFunction]:\n\"\"\"\n    Get the list of all available Functions from configuration\n    \"\"\"\n    if self._all_functions is None:\n        path = Directories.get_structure_config_dir() / \"all_functions.json\"\n\n        try:\n            with open(path) as file:\n                obj = json.load(file)\n                self._all_functions = self._all_functions_decoder(obj)\n        except Exception as ex:\n            raise ConfigurationException(f\"Error reading json configuration from {path}\") from ex\n\n    return self._all_functions\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_config.WorkflowConfig.get_available_workflows","title":"<code>get_available_workflows()</code>","text":"<p>Get the list of all workflows available through configuration</p> Source code in <code>infer_subc/workflow/workflow_config.py</code> <pre><code>def get_available_workflows(self) -&gt; List[str]:\n\"\"\"\n    Get the list of all workflows available through configuration\n    \"\"\"\n    if self._available_workflow_names is None:\n        json_list = sorted(Directories.get_structure_config_dir().glob(\"conf_*.json\"))\n        self._available_workflow_names = [p.stem[5:] for p in json_list]\n\n    return self._available_workflow_names\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_config.WorkflowConfig.get_workflow_definition","title":"<code>get_workflow_definition(workflow_name)</code>","text":"<p>Get a WorkflowDefinition for the given workflow from the corresponding prebuilt json structure config</p> Source code in <code>infer_subc/workflow/workflow_config.py</code> <pre><code>def get_workflow_definition(self, workflow_name: str) -&gt; WorkflowDefinition:  # PrebuiltWorkflowDefinition:\n\"\"\"\n    Get a WorkflowDefinition for the given workflow from the corresponding\n    prebuilt json structure config\n    \"\"\"\n    if workflow_name is None or len(workflow_name.strip()) == 0:\n        raise ValueError(\"workflow_name cannot be empty\")\n\n    if workflow_name not in self.get_available_workflows():\n        raise ValueError(f\"No workflow configuration available for {workflow_name}\")\n\n    path = Directories.get_structure_config_dir() / f\"conf_{workflow_name}.json\"\n\n    return self.get_workflow_definition_from_config_file(path, workflow_name, prebuilt=True)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_config.WorkflowConfig.get_workflow_definition_from_config_file","title":"<code>get_workflow_definition_from_config_file(file_path, workflow_name=None, prebuilt=False)</code>","text":"<p>Get a WorkflowDefinition based off the given json configuration file</p> Source code in <code>infer_subc/workflow/workflow_config.py</code> <pre><code>def get_workflow_definition_from_config_file(\n    self, file_path: Path, workflow_name: str = None, prebuilt: bool = False\n) -&gt; WorkflowDefinition:\n\"\"\"\n    Get a WorkflowDefinition based off the given json configuration file\n    \"\"\"\n    if file_path.suffix.lower() != \".json\":\n        raise ValueError(\"Workflow configuration file must be a json file with .json file extension.\")\n\n    with open(file_path) as file:\n        try:\n            obj = json.load(file)\n            # print(obj)\n            return self._workflow_decoder(obj, workflow_name or file_path.stem, prebuilt)\n        except Exception as ex:\n            raise ConfigurationException(f\"Error reading json configuration from {file_path}\") from ex\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_config.WorkflowConfig.save_workflow_definition_as_json","title":"<code>save_workflow_definition_as_json(workflow_definition, output_file_path)</code>","text":"<p>Save a WorkflowDefinition as a json config file</p> Source code in <code>infer_subc/workflow/workflow_config.py</code> <pre><code>def save_workflow_definition_as_json(self, workflow_definition: WorkflowDefinition, output_file_path: Path):\n\"\"\"\n    Save a WorkflowDefinition as a json config file\n    \"\"\"\n    if output_file_path.suffix.lower() != \".json\":\n        raise ValueError(\"Workflow configuration file save path must have a .json extension.\")\n\n    with open(output_file_path, \"w\") as file:\n        json.dump(self._workflow_encoder(workflow_definition), file, indent=4, sort_keys=True)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_definition.SegmentationWrap","title":"<code>SegmentationWrap</code>  <code>dataclass</code>","text":"<p>Simple dataclass wrapper for segmentations of organelles  + masks TODO: make a nice reppr</p> Source code in <code>infer_subc/workflow/workflow_definition.py</code> <pre><code>@dataclass\nclass SegmentationWrap:\n\"\"\"\n    Simple dataclass wrapper for segmentations of organelles  + masks\n    TODO: make a nice reppr\n    \"\"\"\n\n    name: str\n    image: np.ndarray\n    meta: Dict[str, Any]\n    raw_meta: Tuple[Dict[str, Any], Union[Dict[str, Any], List]]\n    channel_names: List[str]\n    channels: List[int]\n    segmentations: List[np.ndarray]\n    masks: List[np.ndarray]\n    mask_names: List[int]\n\n    def __init__(self, name: str, image: np.ndarray, meta: Dict[str, Any]):\n        self.name = name\n        self.image = image\n        self.meta = meta\n        # self.raw_meta = get_raw_meta_data(meta)\n\n    def add_mask(self, name: str, mask: np.ndarray):\n        self.mask_names.append(name)\n        self.masks.append(mask)\n\n    def add_segmentation(self, name: str, segmentation: np.ndarray, channel: int):\n        self.channel_names.append(name)\n        self.channels.append(channel)\n        self.segmentations.append(segmentation)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_definition.WorkflowDefinition","title":"<code>WorkflowDefinition</code>  <code>dataclass</code>","text":"<p>Definition of a custom aics-segmentation Workflow loaded from file.</p> <p>This class only defines the workflow (i.e. the workflow characteristics and steps) and is used either for building an executable Workflow object or to access information about the Workflow without needing to execute it</p> Source code in <code>infer_subc/workflow/workflow_definition.py</code> <pre><code>@dataclass\nclass WorkflowDefinition:\n\"\"\"\n    Definition of a custom aics-segmentation Workflow loaded from file.\n\n    This class only defines the workflow (i.e. the workflow characteristics and steps)\n    and is used either for building an executable Workflow object\n    or to access information about the Workflow without needing to execute it\n    \"\"\"\n\n    name: str\n    steps: List[WorkflowStep]\n    prebuilt: bool\n\n    def __init__(self, name: str, steps: List[WorkflowStep], prebuilt: bool = True):\n        self.name = name\n        self.steps = steps\n        self.prebuilt = prebuilt\n        self.from_file = True\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_engine.WorkflowEngine","title":"<code>WorkflowEngine</code>","text":"<p>aicssegmentation workflow engine Use this class to access and execute aicssegmentation structure workflows</p> Source code in <code>infer_subc/workflow/workflow_engine.py</code> <pre><code>class WorkflowEngine:\n\"\"\"\n    aicssegmentation workflow engine\n    Use this class to access and execute aicssegmentation structure workflows\n    \"\"\"\n\n    def __init__(self, workflow_config: WorkflowConfig = None):\n        self._workflow_config = workflow_config or WorkflowConfig()\n        self._workflow_definitions = self._load_workflow_definitions()\n\n    @property\n    def workflow_definitions(self) -&gt; List[WorkflowDefinition]:\n\"\"\"\n        List of all workflow definitions\n        \"\"\"\n        return self._workflow_definitions\n\n    def get_executable_workflow(self, workflow_name: str, input_image: np.ndarray) -&gt; Workflow:\n\"\"\"\n        Get an executable workflow object\n\n        inputs:\n            workflow_name (str): Name of the workflow to load\n            input_image (ndarray): input image for the workflow to execute on\n        \"\"\"\n        if workflow_name is None:\n            raise ArgumentNullError(\"workflow_name\")\n        if input_image is None:\n            raise ArgumentNullError(\"input_image\")\n\n        definition = self._get_workflow_definition(workflow_name)\n\n        return Workflow(definition, input_image)\n\n    # JAH: add segmentation_name ... do i need it?\n    def add_workflow(self, file_path: Union[Path, str], workflow_name: Union[str, None] = None) -&gt; WorkflowDefinition:\n\"\"\"\n        add WorkflowDefinition to list from a configuration file\n        \"\"\"\n        defn = self._workflow_config.get_workflow_definition_from_config_file(\n            Path(file_path), workflow_name, prebuilt=False\n        )\n        self._workflow_definitions += [defn]\n\n    def get_executable_batch_workflow(\n        self,\n        workflow_name: str,\n        input_dir: str,\n        output_dir: str,\n        segmentation_name: str,\n        channel_index: int = -1,\n    ):\n\"\"\"\n        Get an executable BatchWorkflow object\n\n        inputs:\n            workflow_name (str): Name of the workflow to load\n            input_dir (str|Path): Directory containing input files for the batch processing\n            output_dir (str|Path): Output directory for the batch processing\n            channel_index (int): Index of the channel to process in each image (usually a structure channel)\n        \"\"\"\n        if workflow_name is None:\n            raise ArgumentNullError(\"workflow_name\")\n        if segmentation_name is None:\n            raise ArgumentNullError(\"segmentation_name\")\n        if input_dir is None:\n            raise ArgumentNullError(\"input_dir\")\n        if output_dir is None:\n            raise ArgumentNullError(\"output_dir\")\n\n        definition = self._get_workflow_definition(workflow_name)\n\n        return BatchWorkflow(definition, input_dir, output_dir, segmentation_name, channel_index)\n\n    def get_executable_workflow_from_config_file(\n        self, file_path: Union[str, Path], input_image: np.ndarray\n    ) -&gt; Workflow:\n\"\"\"\n        Get an executable workflow object from a configuration file\n\n        inputs:\n            file_path (str|Path): Path to the workflow configuration file\n            input_image (ndarray): input image for the workflow to execute on\n        \"\"\"\n        if input_image is None:\n            raise ArgumentNullError(\"input_image\")\n        if file_path is None:\n            raise ArgumentNullError(\"file_path\")\n\n        definition = self._workflow_config.get_workflow_definition_from_config_file(Path(file_path))\n        return Workflow(definition, input_image)\n\n    # JAH: add segmentation_name ... do i need it?\n    def get_executable_batch_workflow_from_config_file(\n        self,\n        file_path: Union[str, Path],\n        input_dir: Union[str, Path],\n        output_dir: Union[str, Path],\n        segmentation_name: str,\n        channel_index: int = -1,\n    ):\n\"\"\"\n        Get an executable batch workflow object from a configuration file\n\n        inputs:\n            file_path (str|Path): Path to the workflow configuration file\n            input_dir (str|Path): Directory containing input files for the batch processing\n            output_dir (str|Path): Output directory for the batch processing\n            channel_index (int): Index of the channel to process in each image (usually a structure channel)\n        \"\"\"\n        if file_path is None:\n            raise ArgumentNullError(\"file_path\")\n        if segmentation_name is None:\n            raise ArgumentNullError(\"segmentation_name\")\n        if input_dir is None:\n            raise ArgumentNullError(\"input_dir\")\n        if output_dir is None:\n            raise ArgumentNullError(\"output_dir\")\n\n        definition = self._workflow_config.get_workflow_definition_from_config_file(Path(file_path))\n        return BatchWorkflow(definition, input_dir, output_dir, segmentation_name, channel_index)\n\n    # JAH: add segmentation_name ... do i need it?\n    def get_executable_batch_workflows_from_config_file(\n        self,\n        file_path: Union[List[str], List[Path]],\n        input_dir: Union[str, Path],\n        output_dir: Union[str, Path],\n        segmentation_names: List[str],\n        channel_index: int = -1,\n    ):\n\"\"\"\n        Get an executable batch workflow object from a configuration file\n\n        inputs:\n            file_path (str|Path): Path to the workflow configuration file\n            input_dir (str|Path): Directory containing input files for the batch processing\n            output_dir (str|Path): Output directory for the batch processing\n            channel_index (int): Index of the channel to process in each image (usually a structure channel)\n        \"\"\"\n        if file_path is None:\n            raise ArgumentNullError(\"file_path\")\n        if segmentation_names is None:\n            raise ArgumentNullError(\"segmentation_name\")\n        if input_dir is None:\n            raise ArgumentNullError(\"input_dir\")\n        if output_dir is None:\n            raise ArgumentNullError(\"output_dir\")\n\n        definitions = [self._workflow_config.get_workflow_definition_from_config_file(Path(fn)) for fn in file_path]\n        return BatchWorkflow(definitions, input_dir, output_dir, segmentation_names, channel_index)\n\n        # return [\n        #     self.get_executable_batch_workflow_from_config_file(fp, input_dir, output_dir, nm, channel_index)\n        #     for fp, nm in zip(file_path, segmentation_names)\n        # ]\n\n        # b_wfls = []\n        # for wf,s_nm in zip(file_path,segmentation_name):\n        #     definition = self._workflow_config.get_workflow_definition_from_config_file(Path(wf))\n        #     b_wfls.append(BatchWorkflow(definition, input_dir, output_dir, s_nm, channel_index))\n        # return b_wfls\n\n    def save_workflow_definition(self, workflow_definition: WorkflowDefinition, output_file_path: Union[str, Path]):\n        if workflow_definition is None:\n            raise ArgumentNullError(\"workflow_definition\")\n        if output_file_path is None:\n            raise ArgumentNullError(\"file_path\")\n\n        self._workflow_config.save_workflow_definition_as_json(workflow_definition, output_file_path)\n\n    def _load_workflow_definitions(self) -&gt; List[WorkflowDefinition]:\n        definitions = list()\n        available_workflows = self._workflow_config.get_available_workflows()\n        for name in available_workflows:\n            definitions.append(self._workflow_config.get_workflow_definition(name))\n        return definitions\n\n    def _get_workflow_definition(self, workflow_name: str) -&gt; WorkflowDefinition:\n        definition = next(filter(lambda d: d.name == workflow_name, self._workflow_definitions), None)\n        if definition is None:\n            raise ValueError(\n                f\"No available workflow definition found for {workflow_name}. Specify a valid workflow name.\"\n            )\n\n        return definition\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_engine.WorkflowEngine.workflow_definitions","title":"<code>workflow_definitions: List[WorkflowDefinition]</code>  <code>property</code>","text":"<p>List of all workflow definitions</p>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_engine.WorkflowEngine.add_workflow","title":"<code>add_workflow(file_path, workflow_name=None)</code>","text":"<p>add WorkflowDefinition to list from a configuration file</p> Source code in <code>infer_subc/workflow/workflow_engine.py</code> <pre><code>def add_workflow(self, file_path: Union[Path, str], workflow_name: Union[str, None] = None) -&gt; WorkflowDefinition:\n\"\"\"\n    add WorkflowDefinition to list from a configuration file\n    \"\"\"\n    defn = self._workflow_config.get_workflow_definition_from_config_file(\n        Path(file_path), workflow_name, prebuilt=False\n    )\n    self._workflow_definitions += [defn]\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_engine.WorkflowEngine.get_executable_batch_workflow","title":"<code>get_executable_batch_workflow(workflow_name, input_dir, output_dir, segmentation_name, channel_index=-1)</code>","text":"<p>Get an executable BatchWorkflow object</p> inputs <p>workflow_name (str): Name of the workflow to load input_dir (str|Path): Directory containing input files for the batch processing output_dir (str|Path): Output directory for the batch processing channel_index (int): Index of the channel to process in each image (usually a structure channel)</p> Source code in <code>infer_subc/workflow/workflow_engine.py</code> <pre><code>def get_executable_batch_workflow(\n    self,\n    workflow_name: str,\n    input_dir: str,\n    output_dir: str,\n    segmentation_name: str,\n    channel_index: int = -1,\n):\n\"\"\"\n    Get an executable BatchWorkflow object\n\n    inputs:\n        workflow_name (str): Name of the workflow to load\n        input_dir (str|Path): Directory containing input files for the batch processing\n        output_dir (str|Path): Output directory for the batch processing\n        channel_index (int): Index of the channel to process in each image (usually a structure channel)\n    \"\"\"\n    if workflow_name is None:\n        raise ArgumentNullError(\"workflow_name\")\n    if segmentation_name is None:\n        raise ArgumentNullError(\"segmentation_name\")\n    if input_dir is None:\n        raise ArgumentNullError(\"input_dir\")\n    if output_dir is None:\n        raise ArgumentNullError(\"output_dir\")\n\n    definition = self._get_workflow_definition(workflow_name)\n\n    return BatchWorkflow(definition, input_dir, output_dir, segmentation_name, channel_index)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_engine.WorkflowEngine.get_executable_batch_workflow_from_config_file","title":"<code>get_executable_batch_workflow_from_config_file(file_path, input_dir, output_dir, segmentation_name, channel_index=-1)</code>","text":"<p>Get an executable batch workflow object from a configuration file</p> inputs <p>file_path (str|Path): Path to the workflow configuration file input_dir (str|Path): Directory containing input files for the batch processing output_dir (str|Path): Output directory for the batch processing channel_index (int): Index of the channel to process in each image (usually a structure channel)</p> Source code in <code>infer_subc/workflow/workflow_engine.py</code> <pre><code>def get_executable_batch_workflow_from_config_file(\n    self,\n    file_path: Union[str, Path],\n    input_dir: Union[str, Path],\n    output_dir: Union[str, Path],\n    segmentation_name: str,\n    channel_index: int = -1,\n):\n\"\"\"\n    Get an executable batch workflow object from a configuration file\n\n    inputs:\n        file_path (str|Path): Path to the workflow configuration file\n        input_dir (str|Path): Directory containing input files for the batch processing\n        output_dir (str|Path): Output directory for the batch processing\n        channel_index (int): Index of the channel to process in each image (usually a structure channel)\n    \"\"\"\n    if file_path is None:\n        raise ArgumentNullError(\"file_path\")\n    if segmentation_name is None:\n        raise ArgumentNullError(\"segmentation_name\")\n    if input_dir is None:\n        raise ArgumentNullError(\"input_dir\")\n    if output_dir is None:\n        raise ArgumentNullError(\"output_dir\")\n\n    definition = self._workflow_config.get_workflow_definition_from_config_file(Path(file_path))\n    return BatchWorkflow(definition, input_dir, output_dir, segmentation_name, channel_index)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_engine.WorkflowEngine.get_executable_batch_workflows_from_config_file","title":"<code>get_executable_batch_workflows_from_config_file(file_path, input_dir, output_dir, segmentation_names, channel_index=-1)</code>","text":"<p>Get an executable batch workflow object from a configuration file</p> inputs <p>file_path (str|Path): Path to the workflow configuration file input_dir (str|Path): Directory containing input files for the batch processing output_dir (str|Path): Output directory for the batch processing channel_index (int): Index of the channel to process in each image (usually a structure channel)</p> Source code in <code>infer_subc/workflow/workflow_engine.py</code> <pre><code>def get_executable_batch_workflows_from_config_file(\n    self,\n    file_path: Union[List[str], List[Path]],\n    input_dir: Union[str, Path],\n    output_dir: Union[str, Path],\n    segmentation_names: List[str],\n    channel_index: int = -1,\n):\n\"\"\"\n    Get an executable batch workflow object from a configuration file\n\n    inputs:\n        file_path (str|Path): Path to the workflow configuration file\n        input_dir (str|Path): Directory containing input files for the batch processing\n        output_dir (str|Path): Output directory for the batch processing\n        channel_index (int): Index of the channel to process in each image (usually a structure channel)\n    \"\"\"\n    if file_path is None:\n        raise ArgumentNullError(\"file_path\")\n    if segmentation_names is None:\n        raise ArgumentNullError(\"segmentation_name\")\n    if input_dir is None:\n        raise ArgumentNullError(\"input_dir\")\n    if output_dir is None:\n        raise ArgumentNullError(\"output_dir\")\n\n    definitions = [self._workflow_config.get_workflow_definition_from_config_file(Path(fn)) for fn in file_path]\n    return BatchWorkflow(definitions, input_dir, output_dir, segmentation_names, channel_index)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_engine.WorkflowEngine.get_executable_workflow","title":"<code>get_executable_workflow(workflow_name, input_image)</code>","text":"<p>Get an executable workflow object</p> inputs <p>workflow_name (str): Name of the workflow to load input_image (ndarray): input image for the workflow to execute on</p> Source code in <code>infer_subc/workflow/workflow_engine.py</code> <pre><code>def get_executable_workflow(self, workflow_name: str, input_image: np.ndarray) -&gt; Workflow:\n\"\"\"\n    Get an executable workflow object\n\n    inputs:\n        workflow_name (str): Name of the workflow to load\n        input_image (ndarray): input image for the workflow to execute on\n    \"\"\"\n    if workflow_name is None:\n        raise ArgumentNullError(\"workflow_name\")\n    if input_image is None:\n        raise ArgumentNullError(\"input_image\")\n\n    definition = self._get_workflow_definition(workflow_name)\n\n    return Workflow(definition, input_image)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_engine.WorkflowEngine.get_executable_workflow_from_config_file","title":"<code>get_executable_workflow_from_config_file(file_path, input_image)</code>","text":"<p>Get an executable workflow object from a configuration file</p> inputs <p>file_path (str|Path): Path to the workflow configuration file input_image (ndarray): input image for the workflow to execute on</p> Source code in <code>infer_subc/workflow/workflow_engine.py</code> <pre><code>def get_executable_workflow_from_config_file(\n    self, file_path: Union[str, Path], input_image: np.ndarray\n) -&gt; Workflow:\n\"\"\"\n    Get an executable workflow object from a configuration file\n\n    inputs:\n        file_path (str|Path): Path to the workflow configuration file\n        input_image (ndarray): input image for the workflow to execute on\n    \"\"\"\n    if input_image is None:\n        raise ArgumentNullError(\"input_image\")\n    if file_path is None:\n        raise ArgumentNullError(\"file_path\")\n\n    definition = self._workflow_config.get_workflow_definition_from_config_file(Path(file_path))\n    return Workflow(definition, input_image)\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_step.WorkflowStep","title":"<code>WorkflowStep</code>  <code>dataclass</code>","text":"<p>Represents a single step in an aicssegmentation Workflow</p> Source code in <code>infer_subc/workflow/workflow_step.py</code> <pre><code>@dataclass\nclass WorkflowStep:\n\"\"\"\n    Represents a single step in an aicssegmentation Workflow\n    \"\"\"\n\n    category: WorkflowStepCategory\n    function: SegmenterFunction\n    step_number: int\n    parent: List[int]\n    parameter_values: Dict[str, List] = None\n\n    @property\n    def name(self):\n        return self.function.display_name\n\n    def execute(self, input_images: List[np.ndarray], parameters: Dict[str, Any] = None) -&gt; np.ndarray:\n\"\"\"\n        Execute this workflow step on the given input image and return the result.\n\n        Params:\n            input_images (List[np.ndarray]): List of image inputs to perform this\n                    workflow step on, generally parent image\n            parameters (Dict): Dictionary of parameters to pass to the\n                                underlying function\n\n        Returns\n            self.result (np.ndarray): Result of performing workflow step\n                                        on the given image.\n        \"\"\"\n        if not isinstance(input_images, list):\n            raise ValueError(\"input_images must be a list\")\n\n        if parameters is not None and not self._check_parameters(parameters):\n            raise ValueError(\n                \"Provided parameters are invalid. All keys in the parameters dictionary\"\n                \"must correspond to existing parameter names defined for the underlying workflow function.\"\n                \"Note: parameter names are case sensitive\"\n            )\n\n        py_module = importlib.import_module(self.function.module)\n        py_function = getattr(py_module, self.function.function)\n\n        try:\n            # Most functions require unpacking the images\n            if parameters is not None:\n                return py_function(*input_images, **parameters)\n\n            return py_function(*input_images)\n        except TypeError:\n            # Some functions want it as a list\n            if parameters is not None:\n                return py_function(input_images, **parameters)\n            return py_function(input_images)\n\n    def _check_parameters(self, parameters: Dict[str, Any]) -&gt; bool:\n        for key in parameters.keys():\n            if key not in self.function.parameters.keys():\n                return False\n\n        return True\n</code></pre>"},{"location":"infer_subc/workflow/#infer_subc.workflow.workflow_step.WorkflowStep.execute","title":"<code>execute(input_images, parameters=None)</code>","text":"<p>Execute this workflow step on the given input image and return the result.</p> <p>Parameters:</p> Name Type Description Default <code>input_images</code> <code>List[np.ndarray]</code> <p>List of image inputs to perform this     workflow step on, generally parent image</p> required <code>parameters</code> <code>Dict</code> <p>Dictionary of parameters to pass to the                 underlying function</p> <code>None</code> <p>Returns     self.result (np.ndarray): Result of performing workflow step                                 on the given image.</p> Source code in <code>infer_subc/workflow/workflow_step.py</code> <pre><code>def execute(self, input_images: List[np.ndarray], parameters: Dict[str, Any] = None) -&gt; np.ndarray:\n\"\"\"\n    Execute this workflow step on the given input image and return the result.\n\n    Params:\n        input_images (List[np.ndarray]): List of image inputs to perform this\n                workflow step on, generally parent image\n        parameters (Dict): Dictionary of parameters to pass to the\n                            underlying function\n\n    Returns\n        self.result (np.ndarray): Result of performing workflow step\n                                    on the given image.\n    \"\"\"\n    if not isinstance(input_images, list):\n        raise ValueError(\"input_images must be a list\")\n\n    if parameters is not None and not self._check_parameters(parameters):\n        raise ValueError(\n            \"Provided parameters are invalid. All keys in the parameters dictionary\"\n            \"must correspond to existing parameter names defined for the underlying workflow function.\"\n            \"Note: parameter names are case sensitive\"\n        )\n\n    py_module = importlib.import_module(self.function.module)\n    py_function = getattr(py_module, self.function.function)\n\n    try:\n        # Most functions require unpacking the images\n        if parameters is not None:\n            return py_function(*input_images, **parameters)\n\n        return py_function(*input_images)\n    except TypeError:\n        # Some functions want it as a list\n        if parameters is not None:\n            return py_function(input_images, **parameters)\n        return py_function(input_images)\n</code></pre>"},{"location":"infer_subc/core/file_io/","title":"infer_subc/core/file_io","text":"<p>Helpers for file input and output</p>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.AICSImageReaderWrap","title":"<code>AICSImageReaderWrap</code>  <code>dataclass</code>","text":"<p>Simple dataclass wrapper for the AICSImage output to prepare for imprting to our bioim class TODO: make a nice reppr</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>@dataclass\nclass AICSImageReaderWrap:\n\"\"\"\n    Simple dataclass wrapper for the AICSImage output to prepare for imprting to our bioim class\n    TODO: make a nice reppr\n    \"\"\"\n\n    name: str\n    image: np.ndarray\n    meta: Dict[str, Any]\n    raw_meta: Tuple[Dict[str, Any], Union[Dict[str, Any], List]]\n\n    def __init__(self, name: str, image: np.ndarray, meta: Dict[str, Any]):\n        self.name = name\n        self.image = image\n        self.meta = meta\n        self.raw_meta = get_raw_meta_data(meta)\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.etree_to_dict","title":"<code>etree_to_dict(t)</code>","text":"<p>etree dumper from stackoverflow use to dump meta_dictmetadata</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def etree_to_dict(t):\n\"\"\"\n    etree dumper from stackoverflow use to dump meta_dict[metadata][raw_image_metadata]\n    \"\"\"\n    d = {t.tag: {} if t.attrib else None}\n    children = list(t)\n    if children:\n        dd = defaultdict(list)\n        for dc in map(etree_to_dict, children):\n            for k, v in dc.items():\n                dd[k].append(v)\n        d = {t.tag: {k: v[0] if len(v) == 1 else v for k, v in dd.items()}}\n    if t.attrib:\n        d[t.tag].update((\"@\" + k, v) for k, v in t.attrib.items())\n    if t.text:\n        text = t.text.strip()\n        if children or t.attrib:\n            if text:\n                d[t.tag][\"#text\"] = text\n        else:\n            d[t.tag] = text\n    return d\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_inferred_organelle","title":"<code>export_inferred_organelle(img_out, name, meta_dict, out_data_path)</code>","text":"<p>write inferred organelle to ome.tif file</p>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_inferred_organelle--parameters","title":"Parameters","text":"img_out <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> str <p>name of organelle.  i.e. nuc, lyso, etc.</p> meta_dict <p>dictionary of meta-data (ome) only using original file name here, but could add metadata</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_inferred_organelle--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def export_inferred_organelle(img_out: np.ndarray, name: str, meta_dict: Dict, out_data_path: Path) -&gt; str:\n\"\"\"\n    write inferred organelle to ome.tif file\n\n    Parameters\n    ------------\n    img_out:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    name: str\n        name of organelle.  i.e. nuc, lyso, etc.\n    meta_dict:\n        dictionary of meta-data (ome) only using original file name here, but could add metadata\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    # get some top-level info about the RAW data\n    # channel_names = meta_dict['name']\n    # img = meta_dict['metadata']['aicsimage']\n    # scale = meta_dict['scale']\n    # channel_axis = meta_dict['channel_axis']\n\n    # copy the original file name to meta\n    img_name = Path(meta_dict[\"file_name\"])  #\n    # add params to metadata\n\n    if not Path.exists(out_data_path):\n        Path.mkdir(out_data_path)\n        print(f\"making {out_data_path}\")\n\n    img_name_out = f\"{img_name.stem}-{name}\"\n    # HACK: skip the ome\n    # out_file_n = export_ome_tiff(img_out, meta_dict, img_name_out, str(out_data_path) + \"/\", name)\n    out_file_n = export_tiff(img_out, img_name_out, out_data_path, name, meta_dict)\n    print(f\"saved file: {out_file_n}\")\n    return out_file_n\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_inferred_organelle_AICS","title":"<code>export_inferred_organelle_AICS(img_out, name, meta_dict, out_data_path)</code>","text":"<p>write inferred organelle to ome.tif file with AICSIMAGEIO</p>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_inferred_organelle_AICS--parameters","title":"Parameters","text":"img_out <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> str <p>name of organelle.  i.e. nuc, lyso, etc.</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_inferred_organelle_AICS--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def export_inferred_organelle_AICS(img_out: np.ndarray, name: str, meta_dict: Dict, out_data_path: Path) -&gt; str:\n\"\"\"\n    write inferred organelle to ome.tif file with AICSIMAGEIO\n\n    Parameters\n    ------------\n    img_out:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    name: str\n        name of organelle.  i.e. nuc, lyso, etc.\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    img_name = Path(meta_dict[\"file_name\"])  #\n\n    if not Path.exists(out_data_path):\n        Path.mkdir(out_data_path)\n        print(f\"making {out_data_path}\")\n\n    img_name_out = f\"{img_name.stem}-{name}\"\n    out_file_n = export_tiff_AICS(img_out, img_name_out, out_data_path, name, meta_dict)\n\n    print(f\"saved file: {out_file_n}\")\n    return out_file_n\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_inferred_organelle_stack","title":"<code>export_inferred_organelle_stack(img_out, layer_names, meta_dict, data_root_path)</code>","text":"<p>stack all the inferred objects and stack along 0 dimension</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def export_inferred_organelle_stack(img_out, layer_names, meta_dict, data_root_path):\n\"\"\"\n    stack all the inferred objects and stack along 0 dimension\n    \"\"\"\n    # get some top-level info about the RAW data\n    channel_names = meta_dict[\"name\"]\n    img = meta_dict[\"metadata\"][\"aicsimage\"]\n    scale = meta_dict[\"scale\"]\n    channel_axis = meta_dict[\"channel_axis\"]\n\n    img_name = Path(meta_dict[\"file_name\"])  #\n    # add params to metadata\n    meta_dict[\"layer_names\"] = layer_names\n    out_path = data_root_path / \"inferred_objects\"\n    name = \"stack\"\n    img_name_out = f\"{img_name.stem}-{name}\"\n\n    out_file_n = export_ome_tiff(img_out, meta_dict, img_name_out, str(out_path), layer_names)\n    print(f\"saved file: {out_file_n}\")\n    return out_file_n\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_ndarray","title":"<code>export_ndarray(data_in, img_name, out_path)</code>","text":""},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_ndarray--data_in-typesarraylike","title":"data_in: types.ArrayLike,","text":""},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_ndarray--meta_in-dict","title":"meta_in: dict,","text":""},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_ndarray--img_name-typespathlike","title":"img_name: types.PathLike,","text":""},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_ndarray--out_path-typespathlike","title":"out_path: types.PathLike,","text":""},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_ndarray--curr_chan-int","title":"curr_chan: int","text":""},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_ndarray--assumes-a-single-image","title":"assumes a single image","text":"Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def export_ndarray(data_in, img_name, out_path) -&gt; str:\n\"\"\"\n    #  data_in: types.ArrayLike,\n    #  meta_in: dict,\n    # img_name: types.PathLike,\n    # out_path: types.PathLike,\n    # curr_chan: int\n    # assumes a single image\n    \"\"\"\n    out_name = out_path + img_name + \".npy\"\n    data_in.tofile(out_name)\n    return out_name\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_tiff","title":"<code>export_tiff(data_in, img_name, out_path, channel_names=None, meta_in=None)</code>","text":"<p>wrapper for exporting  tiff with tifffile.imwrite  --&gt; usiong AICSimage is too slow     prsumably handling the OME meta data is what is so slow.</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def export_tiff(\n    data_in: np.ndarray,\n    img_name: str,\n    out_path: Union[Path, str],\n    channel_names: Union[List[str], None] = None,\n    meta_in: Union[Dict, None] = None,\n) -&gt; int:\n\"\"\"\n    wrapper for exporting  tiff with tifffile.imwrite\n     --&gt; usiong AICSimage is too slow\n        prsumably handling the OME meta data is what is so slow.\n    \"\"\"\n\n    # start = time.time()\n\n    out_name = Path(out_path, f\"{img_name}.tiff\")\n\n    # TODO: add metadata OR simpliify and pass name rather than meta-data\n    # image_names = [img_name]\n    # # chan_names = meta_in['metadata']['aicsimage'].channel_names\n    # physical_pixel_sizes = [meta_in[\"metadata\"][\"aicsimage\"].physical_pixel_sizes]\n    # # dimension_order = [\"CZYX\"]\n    # if channel_names is None:\n    #     channel_names = [meta_in[\"metadata\"][\"aicsimage\"].channel_names]\n    # else:\n    #     channel_names = [channel_names]\n    # if len(data_in.shape) == 3:  # single channel zstack\n    #     dimension_order = [\"ZYX\"]\n    #     # data_in = data_in[np.newaxis, :, :, :]\n    # elif len(data_in.shape) == 2:  # single channel , 1Z\n    #     dimension_order = [\"YX\"]\n    #     # data_in = data_in[np.newaxis, np.newaxis, :, :]\n    #     physical_pixel_sizes[0] = [physical_pixel_sizes[0][1:]]\n\n    dtype = data_in.dtype\n    if dtype == \"bool\" or dtype == np.uint8:\n        data_in = data_in.astype(np.uint16)\n        data_in[data_in &gt; 0] = 1\n        dtype = data_in.dtype\n        # print(f\"changed `bool` -&gt; {dtype}\")\n    # else:\n        # print(f\"export as {dtype}\")\n\n    ret = imwrite(\n            out_name,\n            data_in,\n            dtype=dtype,\n            # metadata={\n            #     \"axes\": dimension_order,\n            #     # \"physical_pixel_sizes\": physical_pixel_sizes,\n            #     # \"channel_names\": channel_names,\n            # },\n        )\n    # end = time.time()\n    # print(f\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; tifffile.imwrite in ({(end - start):0.2f}) sec\")\n    return ret\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.export_tiff_AICS","title":"<code>export_tiff_AICS(data_in, img_name, out_path, channel_names=None, meta_in=None)</code>","text":"<p>aicssegmentation way to do it</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def export_tiff_AICS(\n    data_in: np.ndarray,\n    img_name: str,\n    out_path: Union[Path, str],\n    channel_names: Union[List[str], None] = None,\n    meta_in: Union[Dict, None] = None,\n) -&gt; str:\n\"\"\"\n    aicssegmentation way to do it\n    \"\"\"\n    start = time.time()\n    # img_name = meta_in[\"file_name\"]  #\n    # add params to metadata\n    out_name = Path(out_path, img_name + \".tiff\")\n\n    if data_in.dtype == \"bool\":\n        data_in = data_in.astype(np.uint8)\n        data_in[data_in &gt; 0] = 255\n\n    OmeTiffWriter.save(data=data_in, uri=out_name.as_uri(), dim_order=\"ZYX\")\n    end = time.time()\n    print(f\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; export_tiff_AICS ({(end - start):0.2f}) sec\")\n    print(f\"saved file AICS {out_name}\")\n    return out_name\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.get_raw_meta_data","title":"<code>get_raw_meta_data(meta_dict)</code>","text":"<p>not sure why the linux backend works for ome... need to solve</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def get_raw_meta_data(meta_dict):\n\"\"\"\n    not sure why the linux backend works for ome... need to solve\n    \"\"\"\n    curr_platform = system()\n\n    if curr_platform == \"Linux\":\n        raw_meta_data = meta_dict[\"metadata\"][\"raw_image_metadata\"].dict()\n        ome_types = meta_dict[\"metadata\"][\"ome_types\"]\n    elif curr_platform == \"Darwin\":\n        raw_meta_data = meta_dict[\"metadata\"][\"raw_image_metadata\"]\n        ome_types = []\n    else:\n        raw_meta_data = meta_dict[\"metadata\"][\"raw_image_metadata\"]\n        ome_types = []\n        print(f\"warning: platform = '{curr_platform}' is untested\")\n    return (raw_meta_data, ome_types)\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.import_inferred_organelle","title":"<code>import_inferred_organelle(name, meta_dict, out_data_path)</code>","text":"<p>read inferred organelle from ome.tif file</p>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.import_inferred_organelle--parameters","title":"Parameters","text":"str <p>name of organelle.  i.e. nuc, lyso, etc.</p> meta_dict <p>dictionary of meta-data (ome) from original file</p> out_data_path <p>Path object of directory where tiffs are read from</p>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.import_inferred_organelle--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def import_inferred_organelle(name: str, meta_dict: Dict, out_data_path: Path) -&gt; Union[np.ndarray, None]:\n\"\"\"\n    read inferred organelle from ome.tif file\n\n    Parameters\n    ------------\n    name: str\n        name of organelle.  i.e. nuc, lyso, etc.\n    meta_dict:\n        dictionary of meta-data (ome) from original file\n    out_data_path:\n        Path object of directory where tiffs are read from\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n\n    # copy the original file name to meta\n    img_name = Path(meta_dict[\"file_name\"])  #\n    # add params to metadata\n\n    organelle_fname = f\"{img_name.stem}-{name}.tiff\"\n\n    organelle_path = out_data_path / organelle_fname\n\n    if Path.exists(organelle_path):\n        # organelle_obj, _meta_dict = read_ome_image(organelle_path)\n        organelle_obj = read_tiff_image(organelle_path)  # .squeeze()\n        print(f\"loaded  inferred {len(organelle_obj.shape)}D `{name}`  from {out_data_path} \")\n        return organelle_obj\n    else:\n        print(f\"`{name}` object not found: {organelle_path}\")\n        raise FileNotFoundError(f\"`{name}` object not found: {organelle_path}\")\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.import_inferred_organelle_AICS","title":"<code>import_inferred_organelle_AICS(name, meta_dict, out_data_path)</code>","text":"<p>read inferred organelle from ome.tif file with AICSIMAGEIO</p>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.import_inferred_organelle_AICS--parameters","title":"Parameters","text":"str <p>name of organelle.  i.e. nuc, lyso, etc.</p> meta_dict <p>dictionary of meta-data (ome) from original file</p> out_data_path <p>Path object of directory where tiffs are read from</p>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.import_inferred_organelle_AICS--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def import_inferred_organelle_AICS(name: str, meta_dict: Dict, out_data_path: Path) -&gt; Union[np.ndarray, None]:\n\"\"\"\n    read inferred organelle from ome.tif file with AICSIMAGEIO\n\n    Parameters\n    ------------\n    name: str\n        name of organelle.  i.e. nuc, lyso, etc.\n    meta_dict:\n        dictionary of meta-data (ome) from original file\n    out_data_path:\n        Path object of directory where tiffs are read from\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    img_name = Path(meta_dict[\"file_name\"])\n    # HACK: skip OME\n    # organelle_fname = f\"{name}_{img_name.split('/')[-1].split('.')[0]}.ome.tiff\"\n\n    organelle_fname = f\"{img_name.stem}-{name}.tiff\"\n\n    organelle_path = out_data_path / organelle_fname\n\n    if Path.exists(organelle_path):\n        # organelle_obj, _meta_dict = read_ome_image(organelle_path)\n        organelle_obj = read_tiff_image_AICS(organelle_path)  # .squeeze()\n        print(f\"loaded  inferred {len(organelle_obj.shape)}D `{name}`  from {out_data_path} \")\n        return organelle_obj &gt; 0\n    else:\n        print(f\"`{name}` object not found: {organelle_path}\")\n        raise FileNotFoundError(f\"`{name}` object not found: {organelle_path}\")\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.list_image_files","title":"<code>list_image_files(data_folder, file_type, postfix=None)</code>","text":"<p>get a list of all the filetypes TODO: aics has cleaner functions than this \"lambda\" should this use Path methods? or return Path?</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def list_image_files(data_folder: Path, file_type: str, postfix: Union[str, None] = None) -&gt; List:\n\"\"\"\n    get a list of all the filetypes\n    TODO: aics has cleaner functions than this \"lambda\"\n    should this use Path methods? or return Path?\n    \"\"\"\n\n    if postfix is not None:\n        return sorted(data_folder.glob(f\"*{postfix}{file_type}\"))\n    else:\n        return sorted(data_folder.glob(f\"*{file_type}\"))\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.read_czi_image","title":"<code>read_czi_image(image_name)</code>","text":"<p>return output from napari aiscioimage reader (alias for read_ome_image)</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def read_czi_image(image_name):\n\"\"\"\n    return output from napari aiscioimage reader (alias for read_ome_image)\n    \"\"\"\n    return read_ome_image(image_name)\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.read_input_image","title":"<code>read_input_image(image_name)</code>","text":"<p>send output from napari aiscioimage reader wrapped in dataclass</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def read_input_image(image_name):\n\"\"\"\n    send output from napari aiscioimage reader wrapped in dataclass\n    \"\"\"\n    data_out, meta_out, layer_type = reader_function(image_name)[0]\n    return AICSImageReaderWrap(image_name, data_out, meta_out)\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.read_ome_image","title":"<code>read_ome_image(image_name)</code>","text":"<p>return output from napari aiscioimage reader</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def read_ome_image(image_name):\n\"\"\"\n    return output from napari aiscioimage reader\n    \"\"\"\n    data_out, meta_out, layer_type = reader_function(image_name, in_memory=True)[0]\n\n    meta_out[\"file_name\"] = image_name\n    return (data_out, meta_out)\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.read_tiff_image","title":"<code>read_tiff_image(image_name)</code>","text":"<p>return tiff image with tifffile.imread.  Using the <code>reader_function</code> (vial read_ome_image) and AICSimage is too slow     prsumably handling the OME meta data is what is so slow.</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def read_tiff_image(image_name):\n\"\"\"\n    return tiff image with tifffile.imread.  Using the `reader_function` (vial read_ome_image) and AICSimage is too slow\n        prsumably handling the OME meta data is what is so slow.\n    \"\"\"\n    # start = time.time()\n    image = imread(\n        image_name,\n    )\n    # end = time.time()\n    # print(f\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; tifffile.imread  (dtype={image.dtype} in ({(end - start):0.2f}) sec\")\n    return image  # .get_image_data(\"CZYX\")\n</code></pre>"},{"location":"infer_subc/core/file_io/#infer_subc.core.file_io.read_tiff_image_AICS","title":"<code>read_tiff_image_AICS(image_name)</code>","text":"<p>aicssegmentation way to do it</p> Source code in <code>infer_subc/core/file_io.py</code> <pre><code>def read_tiff_image_AICS(image_name):\n\"\"\"aicssegmentation way to do it\"\"\"\n    start = time.time()\n    image = AICSImage(image_name)\n    if len(image.scenes) &gt; 1:\n        raise ValueError(\"Multi-Scene images are unsupported\")\n\n    if image.dims.T &gt; 1:\n        raise ValueError(\"Timelapse images are unsupported.\")\n\n    if image.dims.C &gt; 1:\n        im_out = image.get_image_data(\"CZYX\")\n\n    im_out = image.get_image_data(\"ZYX\")\n    end = time.time()\n    print(f\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; AICSImage read  (dtype={image.dtype}in ({(end - start):0.2f}) sec\")\n    return im_out\n</code></pre>"},{"location":"infer_subc/core/img/","title":"infer_subc/core/img","text":"<p>Image processing functions.  Most are wrappers to well known <code>skimage</code> and <code>scipy.ndimate</code> utilities as well as core routines from <code>aicssegmentation</code></p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.adjacent","title":"<code>adjacent(labels)</code>","text":"<p>Return a binary mask of all pixels which are adjacent to a pixel of a different label.</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def adjacent(labels):\n\"\"\"Return a binary mask of all pixels which are adjacent to a pixel of\n    a different label.\n\n    \"\"\"\n    high = labels.max() + 1\n    if high &gt; np.iinfo(labels.dtype).max:\n        labels = labels.astype(np.int32)\n    image_with_high_background = labels.copy()\n    image_with_high_background[labels == 0] = high\n    min_label = minimum_filter(\n        image_with_high_background,\n        footprint=np.ones((3, 3), bool),\n        mode=\"constant\",\n        cval=high,\n    )\n    max_label = maximum_filter(labels, footprint=np.ones((3, 3), bool), mode=\"constant\", cval=0)\n    return (min_label != max_label) &amp; (labels &gt; 0)\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.aggregate_signal_channels","title":"<code>aggregate_signal_channels(img_in, chs, ws=None)</code>","text":"<p>return a weighted sum of the image across channels (DEPRICATED)</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.aggregate_signal_channels--parameters","title":"Parameters","text":"img_in <p>np.ndarray  [ch,z,x,y]</p> chs <p>list/tuple of channels to aggregate</p> ws <p>list/tuple/ of weights for aggregation</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.aggregate_signal_channels--returns","title":"Returns","text":"<pre><code>np.ndarray\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def aggregate_signal_channels(\n    img_in: np.ndarray, chs: Union[List, Tuple], ws: Union[List, Tuple, Any] = None\n) -&gt; np.ndarray:\n\"\"\"\n    return a weighted sum of the image across channels (DEPRICATED)\n\n    Parameters\n    ------------\n    img_in:\n        np.ndarray  [ch,z,x,y]\n    chs:\n        list/tuple of channels to aggregate\n    ws:\n        list/tuple/ of weights for aggregation\n\n    Returns\n    -------------\n        np.ndarray\n    \"\"\"\n    n_chan = len(chs)\n    if n_chan &lt;= 1:\n        return img_in[chs]\n\n    if ws is None:\n        ws = n_chan * [1.0]\n    img_out = np.zeros_like(img_in[0]).astype(np.double)\n    for w, ch in zip(ws, chs):\n        img_out += w * img_in[ch]\n    return img_out\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.apply_log_li_threshold","title":"<code>apply_log_li_threshold(img_in, thresh_factor=1.0, thresh_min=None, thresh_max=None)</code>","text":"<p>return a binary mask after applying a log_li threshold</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.apply_log_li_threshold--parameters","title":"Parameters","text":"img_in <p>input ndimage array (np.ndimage)</p> thresh_factor <p>scaling value for threshold, defaults=1.0</p> <p>thresh_min     absolute minumum for threshold, default=None thresh_max     absolute maximum for threshold, default=None</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.apply_log_li_threshold--returns","title":"Returns","text":"<pre><code>thresholded boolean np.ndarray\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def apply_log_li_threshold(\n    img_in: np.ndarray,\n    thresh_factor: float = 1.0,\n    thresh_min: Union[None, float] = None,\n    thresh_max: Union[None, float] = None,\n) -&gt; np.ndarray:\n\"\"\"return a binary mask after applying a log_li threshold\n\n    Parameters\n    ------------\n    img_in:\n        input ndimage array (np.ndimage)\n    thresh_factor:\n        scaling value for threshold, defaults=1.0\n    thresh_min\n        absolute minumum for threshold, default=None\n    thresh_max\n        absolute maximum for threshold, default=None\n\n    Returns\n    -------------\n        thresholded boolean np.ndarray\n    \"\"\"\n    # struct_obj = struct_img &gt; filters.threshold_li(struct_img)\n    threshold_value_log = threshold_li_log(img_in)\n    threshold = threshold_value_log * thresh_factor\n\n    if thresh_min is not None:\n        threshold = max(threshold, thresh_min)\n    if thresh_max is not None:\n        threshold = min(threshold, thresh_max)\n    return img_in &gt; threshold\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.apply_mask","title":"<code>apply_mask(img_in, mask)</code>","text":"<p>mask the image</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.apply_mask--parameters","title":"Parameters","text":"img_in <p>the image to filter on</p> mask <p>the mask to apply</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.apply_mask--returns","title":"Returns","text":"img_out <p>a new (copied) array with mask applied</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def apply_mask(img_in: np.ndarray, mask: np.ndarray) -&gt; np.ndarray:\n\"\"\"mask the image\n\n    Parameters\n    ------------\n    img_in:\n        the image to filter on\n    mask:\n        the mask to apply\n\n    Returns\n    -----------\n    img_out:\n        a new (copied) array with mask applied\n    \"\"\"\n    assert img_in.shape == mask.shape\n\n    img_out = img_in.copy()\n    if mask.dtype == \"bool\":\n        img_out[~mask] = 0\n    else:\n        img_out[mask &lt; 1] = 0\n\n    return img_out\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.apply_threshold","title":"<code>apply_threshold(img_in, method='otsu', thresh_factor=1.0, thresh_min=None, thresh_max=None)</code>","text":"<p>return a binary mask after applying a log_li threshold</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.apply_threshold--parameters","title":"Parameters","text":"img_in <p>np.ndarray input image</p> method <p>method for applying threshold.  \"otsu\"  or \"li\" (default), \"triangle\", \"median\", \"ave\", \"sauvola\",\"multi_otsu\",\"muiltiotsu\"</p> thresh_factor <p>scaling value for threshold, defaults=1.0</p> <p>thresh_min     absolute minumum for threshold, default=None thresh_max     absolute maximum for threshold, default=None</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.apply_threshold--returns","title":"Returns","text":"<pre><code>thresholded boolean np.ndarray\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def apply_threshold(\n    img_in: np.ndarray,\n    method: str = \"otsu\",\n    thresh_factor: float = 1.0,\n    thresh_min: Union[None, float] = None,\n    thresh_max: Union[None, float] = None,\n) -&gt; np.ndarray:\n\"\"\"return a binary mask after applying a log_li threshold\n\n    Parameters\n    ------------\n    img_in:\n        np.ndarray input image\n    method:\n        method for applying threshold.  \"otsu\"  or \"li\" (default), \"triangle\", \"median\", \"ave\", \"sauvola\",\"multi_otsu\",\"muiltiotsu\"\n    thresh_factor:\n        scaling value for threshold, defaults=1.0\n    thresh_min\n        absolute minumum for threshold, default=None\n    thresh_max\n        absolute maximum for threshold, default=None\n\n    Returns\n    -------------\n        thresholded boolean np.ndarray\n    \"\"\"\n\n    if method == \"tri\" or method == \"triangle\":\n        threshold_val = threshold_triangle(img_in)\n    elif method == \"med\" or method == \"median\":\n        threshold_val = np.percentile(img_in, 50)\n    elif method == \"ave\" or method == \"ave_tri_med\":\n        global_tri = threshold_triangle(img_in)\n        global_median = np.percentile(img_in, 50)\n        threshold_val = (global_tri + global_median) / 2\n    elif method == \"li\" or method == \"cross_entropy\" or method == \"crossentropy\":\n        threshold_val = threshold_li(img_in)\n    elif method == \"sauvola\":\n        threshold_val = threshold_sauvola(img_in)\n    elif method == \"mult_otsu\" or method == \"multiotsu\":\n        threshold_val = threshold_multiotsu(img_in)\n    else:  # default to \"otsu\"\n        threshold_val = threshold_otsu(img_in)\n\n    threshold = threshold_val * thresh_factor\n\n    if thresh_min is not None:\n        threshold = max(threshold, thresh_min)\n    if thresh_max is not None:\n        threshold = min(threshold, thresh_max)\n    return img_in &gt; threshold\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.choose_agg_signal_zmax","title":"<code>choose_agg_signal_zmax(img_in, chs, ws=None, mask=None)</code>","text":"<p>return z the maximum signal for the aggregate signal</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.choose_agg_signal_zmax--parameters","title":"Parameters","text":"img_in <p>np.ndarray  [ch,z,x,y]</p> chs <p>list of channels to aggregate</p> ws <p>list of weights for aggregation</p> mask <p>mask for img_in</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.choose_agg_signal_zmax--returns","title":"Returns","text":"<pre><code>np.ndarray z with maximum signal\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def choose_agg_signal_zmax(img_in: np.ndarray, chs: List[int], ws=None, mask=None) -&gt; np.ndarray:\n\"\"\"\n    return z the maximum signal for the aggregate signal\n\n    Parameters\n    ------------\n    img_in:\n        np.ndarray  [ch,z,x,y]\n    chs:\n        list of channels to aggregate\n    ws:\n        list of weights for aggregation\n    mask:\n        mask for img_in\n\n    Returns\n    -------------\n        np.ndarray z with maximum signal\n    \"\"\"\n    total_florescence_ = aggregate_signal_channels(img_in, chs)\n    if mask is not None:\n        total_florescence_[mask] = 0.0\n    return int(total_florescence_.sum(axis=(1, 2)).argmax())\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.choose_max_label","title":"<code>choose_max_label(raw_signal, labels_in, target_labels=None)</code>","text":"<p>keep only the segmentation corresponding to the maximum raw signal.  candidate  label is taken from target_labels if not None</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.choose_max_label--parameters","title":"Parameters","text":"raw_signal <p>the image to filter on</p> labels_in <p>segmentation labels</p> target_labels <p>labels to consider</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.choose_max_label--returns","title":"Returns","text":"<pre><code>np.ndarray of labels corresponding to the largest total signal\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def choose_max_label(\n    raw_signal: np.ndarray, labels_in: np.ndarray, target_labels: Union[np.ndarray, None] = None\n) -&gt; np.ndarray:\n\"\"\"\n    keep only the segmentation corresponding to the maximum raw signal.  candidate  label is taken from target_labels if not None\n\n    Parameters\n    ------------\n    raw_signal:\n        the image to filter on\n    labels_in:\n        segmentation labels\n    target_labels:\n        labels to consider\n\n    Returns\n    -------------\n        np.ndarray of labels corresponding to the largest total signal\n\n    \"\"\"\n    keep_label = get_max_label(raw_signal, labels_in, target_labels)\n    labels_max = np.zeros_like(labels_in)\n    labels_max[labels_in == keep_label] = 1\n    return labels_max\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.color_labels","title":"<code>color_labels(labels, distance_transform=False)</code>","text":"<p>Color a labels matrix so that no adjacent labels have the same color</p> <p>distance_transform - if true, distance transform the labels to find out      which objects are closest to each other.</p> <p>Create a label coloring matrix which assigns a color (1-n) to each pixel in the labels matrix such that all pixels similarly labeled are similarly colored and so that no similiarly colored, 8-connected pixels have different labels.</p> <p>You can use this function to partition the labels matrix into groups of objects that are not touching; you can then operate on masks and be assured that the pixels from one object won't interfere with pixels in another.</p> <p>returns the color matrix</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def color_labels(labels, distance_transform=False):\n\"\"\"Color a labels matrix so that no adjacent labels have the same color\n\n    distance_transform - if true, distance transform the labels to find out\n         which objects are closest to each other.\n\n    Create a label coloring matrix which assigns a color (1-n) to each pixel\n    in the labels matrix such that all pixels similarly labeled are similarly\n    colored and so that no similiarly colored, 8-connected pixels have\n    different labels.\n\n    You can use this function to partition the labels matrix into groups\n    of objects that are not touching; you can then operate on masks\n    and be assured that the pixels from one object won't interfere with\n    pixels in another.\n\n    returns the color matrix\n    \"\"\"\n    if distance_transform:\n        i, j = distance_transform_edt(labels == 0, return_distances=False, return_indices=True)\n        dt_labels = labels[i, j]\n    else:\n        dt_labels = labels\n    # Get the neighbors for each object\n    v_count, v_index, v_neighbor = find_neighbors(dt_labels)\n    # Quickly get rid of labels with no neighbors. Greedily assign\n    # all of these a color of 1\n    v_color = np.zeros(len(v_count) + 1, int)  # the color per object - zero is uncolored\n    zero_count = v_count == 0\n    if np.all(zero_count):\n        # can assign all objects the same color\n        return (labels != 0).astype(int)\n    v_color[1:][zero_count] = 1\n    v_count = v_count[~zero_count]\n    v_index = v_index[~zero_count]\n    v_label = np.argwhere(~zero_count).transpose()[0] + 1\n    # If you process the most connected labels first and use a greedy\n    # algorithm to preferentially assign a label to an existing color,\n    # you'll get a coloring that uses 1+max(connections) at most.\n    #\n    # Welsh, \"An upper bound for the chromatic number of a graph and\n    # its application to timetabling problems\", The Computer Journal, 10(1)\n    # p 85 (1967)\n    #\n    sort_order = np.lexsort([-v_count])\n    v_count = v_count[sort_order]\n    v_index = v_index[sort_order]\n    v_label = v_label[sort_order]\n    for i in range(len(v_count)):\n        neighbors = v_neighbor[v_index[i] : v_index[i] + v_count[i]]\n        colors = np.unique(v_color[neighbors])\n        if colors[0] == 0:\n            if len(colors) == 1:\n                # only one color and it's zero. All neighbors are unlabeled\n                v_color[v_label[i]] = 1\n                continue\n            else:\n                colors = colors[1:]\n        # The colors of neighbors will be ordered, so there are two cases:\n        # * all colors up to X appear - colors == np.arange(1,len(colors)+1)\n        # * some color is missing - the color after the first missing will\n        #   be mislabeled: colors[i] != np.arange(1, len(colors)+1)\n        crange = np.arange(1, len(colors) + 1)\n        misses = crange[colors != crange]\n        if len(misses):\n            color = misses[0]\n        else:\n            color = len(colors) + 1\n        v_color[v_label[i]] = color\n    return v_color[labels]\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.distance_to_edge","title":"<code>distance_to_edge(labels)</code>","text":"<p>Compute the distance of a pixel to the edge of its object</p> <p>labels - a labels matrix</p> <p>returns a matrix of distances</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def distance_to_edge(labels):\n\"\"\"Compute the distance of a pixel to the edge of its object\n\n    labels - a labels matrix\n\n    returns a matrix of distances\n    \"\"\"\n    colors = color_labels(labels)\n    max_color = np.max(colors)\n    result = np.zeros(labels.shape)\n    if max_color == 0:\n        return result\n\n    for i in range(1, max_color + 1):\n        mask = colors == i\n        result[mask] = distance_transform_edt(mask)[mask]\n    return result\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.enhance_neurites","title":"<code>enhance_neurites(image, radius, volumetric=False)</code>","text":"<p>enhance \"neurites\" or filiments</p> <p>Parameters</p> <p>image: np.ndarray      the image to filter on  radius: int      radius of the \"filter\"  volumetric: bool      True for 3D analysis</p> <p>Returns</p> <p>result:      filtered boolean np.ndarray</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def enhance_neurites(image: np.ndarray, radius: int, volumetric: bool = False) -&gt; np.ndarray:\n\"\"\"enhance \"neurites\" or filiments\n\n    Parameters\n     ------------\n     image: np.ndarray\n         the image to filter on\n     radius: int\n         radius of the \"filter\"\n     volumetric: bool\n         True for 3D analysis\n\n     Returns\n     -----------\n     result:\n         filtered boolean np.ndarray\n    \"\"\"\n    if volumetric:\n        selem = ball(radius)\n    else:\n        selem = disk(radius)\n    white = white_tophat(image, selem)\n    black = black_tophat(image, selem)\n    result = image + white - black\n    result[result &gt; 1] = 1\n    result[result &lt; 0] = 0\n\n    return result\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.enhance_speckles","title":"<code>enhance_speckles(image, radius, volumetric=False)</code>","text":"<p>enhance \"spreckles\" small dots</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.enhance_speckles--parameters","title":"Parameters","text":"np.ndarray <p>the image to filter on</p> int <p>radius of the \"filter\"</p> bool <p>True for 3D analysis</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.enhance_speckles--returns","title":"Returns","text":"result <p>filtered boolean np.ndarray</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def enhance_speckles(image: np.ndarray, radius: int, volumetric: bool = False) -&gt; np.ndarray:\n\"\"\"enhance \"spreckles\" small dots\n\n    Parameters\n    ------------\n    image: np.ndarray\n        the image to filter on\n    radius: int\n        radius of the \"filter\"\n    volumetric: bool\n        True for 3D analysis\n\n    Returns\n    -----------\n    result:\n        filtered boolean np.ndarray\n    \"\"\"\n    radius = radius / 2\n    if volumetric:\n        selem = ball(radius)\n    else:\n        selem = disk(radius)\n\n    # if radius &gt;10:\n    #         minimum = scipy.ndimage.minimum_filter(image, footprint=selem)\n    #         maximum = scipy.ndimage.maximum_filter(minimum, footprint=selem)\n    #         result = data - maximum\n    # else:\n    result = white_tophat(image)\n\n    return result\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.filament_filter","title":"<code>filament_filter(in_img, filament_scale, filament_cut)</code>","text":"<p>filament wrapper to properly pack parameters into filament_2d_wrapper</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.filament_filter--parameters","title":"Parameters","text":"in_img <p>the image to filter on np.ndarray</p> filament_scale <p>scale or size of the \"filter\" float</p> filament_cut <p>cutoff for thresholding float</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.filament_filter--returns","title":"Returns","text":"result <p>filtered boolean np.ndarray</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def filament_filter(in_img: np.ndarray, filament_scale: float, filament_cut: float) -&gt; np.ndarray:\n\"\"\"filament wrapper to properly pack parameters into filament_2d_wrapper\n\n    Parameters\n    ------------\n    in_img:\n        the image to filter on np.ndarray\n    filament_scale:\n        scale or size of the \"filter\" float\n    filament_cut:\n        cutoff for thresholding float\n\n    Returns\n    -----------\n    result:\n        filtered boolean np.ndarray\n\n    \"\"\"\n    f2_param = [[filament_scale, filament_cut]]\n    # f2_param = [[1, 0.15]]  # [scale_1, cutoff_1]\n    return filament_2d_wrapper(in_img, f2_param)\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.fill_and_filter_linear_size","title":"<code>fill_and_filter_linear_size(img, hole_min, hole_max, min_size, method='slice_by_slice', connectivity=1)</code>","text":"<p>wraper to aiscsegmentation <code>hole_filling</code> and <code>size_filter</code> with size argument in linear units</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.fill_and_filter_linear_size--parameters","title":"Parameters","text":"img <p>the image to filter on</p> int <p>the minimum width of the holes to be filled</p> int <p>the maximum width of the holes to be filled</p> int <p>the minimum size expressed as 1D length (so squared for slice-by-slice, cubed for 3D)</p> str <p>either \"3D\" or \"slice_by_slice\", default is \"slice_by_slice\"</p> int <p>the connectivity to use when computing object size</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.fill_and_filter_linear_size--returns","title":"Returns","text":"<pre><code>a binary image after hole filling and filtering small objects; np.ndarray\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def fill_and_filter_linear_size(\n    img: np.ndarray, hole_min: int, hole_max: int, min_size: int, method: str = \"slice_by_slice\", connectivity: int = 1\n) -&gt; np.ndarray:\n\"\"\"wraper to aiscsegmentation `hole_filling` and `size_filter` with size argument in linear units\n\n    Parameters\n    ------------\n    img:\n        the image to filter on\n    hole_min: int\n        the minimum width of the holes to be filled\n    hole_max: int\n        the maximum width of the holes to be filled\n    min_size: int\n        the minimum size expressed as 1D length (so squared for slice-by-slice, cubed for 3D)\n    method: str\n        either \"3D\" or \"slice_by_slice\", default is \"slice_by_slice\"\n    connnectivity: int\n        the connectivity to use when computing object size\n    Returns\n    -------------\n        a binary image after hole filling and filtering small objects; np.ndarray\n    \"\"\"\n    if not img.any():\n        return img\n\n    if method == \"3D\":\n        if hole_max &gt; 0:\n            img = hole_filling(img, hole_min=hole_min**3, hole_max=hole_max**3, fill_2d=False)\n        return size_filter(img, min_size=min_size**3, method=\"3D\", connectivity=connectivity)\n    elif method == \"slice_by_slice\":\n        if hole_max &gt; 0:\n            img = hole_filling(img, hole_min=hole_min**2, hole_max=hole_max**2, fill_2d=True)\n        return size_filter(img, min_size=min_size**2, method=\"slice_by_slice\", connectivity=connectivity)\n    else:\n        print(f\"undefined method: {method}\")\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.find_neighbors","title":"<code>find_neighbors(labels)</code>","text":"<p>Find the set of objects that touch each object in a labels matrix</p> <p>Construct a \"list\", per-object, of the objects 8-connected adjacent to that object. Returns three 1-d arrays: * array of #'s of neighbors per object * array of indexes per object to that object's list of neighbors * array holding the neighbors.</p> <p>For instance, say 1 touches 2 and 3 and nobody touches 4. The arrays are: [ 2, 1, 1, 0], [ 0, 2, 3, 4], [ 2, 3, 1, 1]</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def find_neighbors(labels):\n\"\"\"Find the set of objects that touch each object in a labels matrix\n\n    Construct a \"list\", per-object, of the objects 8-connected adjacent\n    to that object.\n    Returns three 1-d arrays:\n    * array of #'s of neighbors per object\n    * array of indexes per object to that object's list of neighbors\n    * array holding the neighbors.\n\n    For instance, say 1 touches 2 and 3 and nobody touches 4. The arrays are:\n    [ 2, 1, 1, 0], [ 0, 2, 3, 4], [ 2, 3, 1, 1]\n    \"\"\"\n    max_label = np.max(labels)\n    # Make a labels matrix with zeros around the edges so we can do index\n    # offsets without worrying.\n    #\n    new_labels = np.zeros(np.array(labels.shape) + 2, labels.dtype)\n    new_labels[1:-1, 1:-1] = labels\n    labels = new_labels\n    # Only consider the points that are next to others\n    adjacent_mask = adjacent(labels)\n    adjacent_i, adjacent_j = np.argwhere(adjacent_mask).transpose()\n    # Get matching vectors of labels and neighbor labels for the 8\n    # compass directions.\n    count = len(adjacent_i)\n    if count == 0:\n        return (np.zeros(max_label, int), np.zeros(max_label, int), np.zeros(0, int))\n    # The following bizarre construct does the following:\n    # labels[adjacent_i, adjacent_j] looks up the label for each pixel\n    # [...]*8 creates a list of 8 references to it\n    # np.hstack concatenates, giving 8 repeats of the list\n    v_label = np.hstack([labels[adjacent_i, adjacent_j]] * 8)\n    v_neighbor = np.zeros(count * 8, int)\n    index = 0\n    for i, j in ((-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)):\n        v_neighbor[index : index + count] = labels[adjacent_i + i, adjacent_j + j]\n        index += count\n    #\n    # sort by label and neighbor\n    #\n    sort_order = np.lexsort((v_neighbor, v_label))\n    v_label = v_label[sort_order]\n    v_neighbor = v_neighbor[sort_order]\n    #\n    # eliminate duplicates by comparing each element after the first one\n    # to its previous\n    #\n    first_occurrence = np.ones(len(v_label), bool)\n    first_occurrence[1:] = (v_label[1:] != v_label[:-1]) | (v_neighbor[1:] != v_neighbor[:-1])\n    v_label = v_label[first_occurrence]\n    v_neighbor = v_neighbor[first_occurrence]\n    #\n    # eliminate neighbor = self and neighbor = background\n    #\n    to_remove = (v_label == v_neighbor) | (v_neighbor == 0)\n    v_label = v_label[~to_remove]\n    v_neighbor = v_neighbor[~to_remove]\n    #\n    # The count of # of neighbors\n    #\n    v_count = fixup_scipy_ndimage_result(sum(np.ones(v_label.shape), v_label, np.arange(max_label, dtype=np.int32) + 1))\n    v_count = v_count.astype(int)\n    #\n    # The index into v_neighbor\n    #\n    v_index = np.cumsum(v_count)\n    v_index[1:] = v_index[:-1]\n    v_index[0] = 0\n    return (v_count, v_index, v_neighbor)\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.fixup_scipy_ndimage_result","title":"<code>fixup_scipy_ndimage_result(whatever_it_returned)</code>","text":"<p>Convert a result from scipy.ndimage to a numpy array</p> <p>scipy.ndimage has the annoying habit of returning a single, bare value instead of an array if the indexes passed in are of length 1. For instance: scipy.ndimage.maximum(image, labels, [1]) returns a float but scipy.ndimage.maximum(image, labels, [1,2]) returns a list</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def fixup_scipy_ndimage_result(whatever_it_returned):\n\"\"\"Convert a result from scipy.ndimage to a numpy array\n\n    scipy.ndimage has the annoying habit of returning a single, bare\n    value instead of an array if the indexes passed in are of length 1.\n    For instance:\n    scipy.ndimage.maximum(image, labels, [1]) returns a float\n    but\n    scipy.ndimage.maximum(image, labels, [1,2]) returns a list\n    \"\"\"\n    if getattr(whatever_it_returned, \"__getitem__\", False):\n        return np.array(whatever_it_returned)\n    else:\n        return np.array([whatever_it_returned])\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.get_interior_labels","title":"<code>get_interior_labels(img_in)</code>","text":"<p>gets the labeled objects from the X,Y \"interior\" of the image. We only want to clear the objects touching the sides of the volume, but not the top and bottom, so we pad and crop the volume along the 0th axis</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.get_interior_labels--parameters","title":"Parameters","text":"img_in <p>a 3d image</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.get_interior_labels--returns","title":"Returns","text":"<pre><code>np.ndimage of labeled segmentations NOT touching the sides\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def get_interior_labels(img_in: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    gets the labeled objects from the X,Y \"interior\" of the image. We only want to clear the objects touching the sides of the volume, but not the top and bottom, so we pad and crop the volume along the 0th axis\n\n    Parameters\n    ------------\n    img_in:\n        a 3d image\n\n    Returns\n    -------------\n        np.ndimage of labeled segmentations NOT touching the sides\n\n    \"\"\"\n    segmented_padded = np.pad(\n        label(img_in),\n        ((1, 1), (0, 0), (0, 0)),\n        mode=\"constant\",\n        constant_values=0,\n    )\n    interior = clear_border(segmented_padded)[1:-1]\n    return interior\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.get_max_label","title":"<code>get_max_label(raw_signal, labels_in, target_labels=None)</code>","text":"<p>keep only the label with the maximum raw signal.  candidate  label is taken from target_labels if not None</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.get_max_label--parameters","title":"Parameters","text":"raw_signal <p>the image to filter on</p> labels_in <p>segmentation labels</p> target_labels <p>labels to consider</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.get_max_label--returns","title":"Returns","text":"<pre><code>np.ndarray of labels corresponding to the largest total signal\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def get_max_label(\n    raw_signal: np.ndarray, labels_in: np.ndarray, target_labels: Union[np.ndarray, None] = None\n) -&gt; np.ndarray:\n\"\"\"\n    keep only the label with the maximum raw signal.  candidate  label is taken from target_labels if not None\n\n    Parameters\n    ------------\n    raw_signal:\n        the image to filter on\n    labels_in:\n        segmentation labels\n    target_labels:\n        labels to consider\n\n    Returns\n    -------------\n        np.ndarray of labels corresponding to the largest total signal\n\n    \"\"\"\n    if target_labels is None:\n        all_labels = np.unique(labels_in)[1:]\n    else:\n        all_labels = np.unique(target_labels)[1:]\n\n    total_signal = [raw_signal[labels_in == label].sum() for label in all_labels]\n    # combine NU and \"labels\" to make a CELLMASK\n    keep_label = all_labels[np.argmax(total_signal)]\n\n    return keep_label\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.hole_filling_linear_size","title":"<code>hole_filling_linear_size(img, hole_min, hole_max, fill_2d=True)</code>","text":"<p>Fill holes  wraper to aiscsegmentation <code>hole_filling</code> with size argument in linear units.  always does slice-by-slice</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.hole_filling_linear_size--parameters","title":"Parameters","text":"img <p>the image to filter on</p> int <p>the minimum width of the holes to be filled</p> int <p>the maximum width of the holes to be filled</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.hole_filling_linear_size--returns","title":"Returns","text":"<pre><code>a binary image after hole filling\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def hole_filling_linear_size(img: np.ndarray, hole_min: int, hole_max: int, fill_2d=True) -&gt; np.ndarray:\n\"\"\"Fill holes  wraper to aiscsegmentation `hole_filling` with size argument in linear units.  always does slice-by-slice\n\n    Parameters\n    ------------\n    img:\n        the image to filter on\n    hole_min: int\n        the minimum width of the holes to be filled\n    hole_max: int\n        the maximum width of the holes to be filled\n\n    Returns\n    -----------\n        a binary image after hole filling\n    \"\"\"\n    if fill_2d:\n        return hole_filling(img, hole_min=hole_min**2, hole_max=hole_max**2, fill_2d=True)\n    else:\n        return hole_filling(img, hole_min=hole_min**3, hole_max=hole_max**3, fill_2d=False)\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.img_to_bool","title":"<code>img_to_bool(data_in)</code>","text":"<p>helper to make sure we are keeping track of things correctly</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def img_to_bool(data_in: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    helper to make sure we are keeping track of things correctly\n    \"\"\"\n    print(f\"changing from {data_in.dtype} to bool\")\n    data_out = data_in &gt; 0\n    print(f\"    -&gt; {data_out.dtype}\")\n    return data_out\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.img_to_uint8","title":"<code>img_to_uint8(data_in)</code>","text":"<p>helper to convert bask to <code>binary</code> uint8 (true -&gt; 255) to accomodate napari default scaling</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def img_to_uint8(data_in: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    helper to convert bask to `binary` uint8 (true -&gt; 255) to accomodate napari default scaling\n    \"\"\"\n    print(f\"changing from {data_in.dtype} to np.uint8\")\n    data_in = data_in.astype(np.uint8)\n    data_in[data_in &gt; 0] = 1\n    return data_in\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.inverse_log_transform","title":"<code>inverse_log_transform(image, d)</code>","text":"<p>Convert the values in image back to the scale prior to log_transform</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.inverse_log_transform--parameters","title":"Parameters","text":"image <p>a 3d image</p> d <p>dictionary returned by log_transform</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.inverse_log_transform--returns","title":"Returns","text":"<pre><code>de-logged image (np.ndarray)\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def inverse_log_transform(image: np.ndarray, d: dict) -&gt; np.ndarray:\n\"\"\"Convert the values in image back to the scale prior to log_transform\n\n    Parameters\n    ------------\n    image:\n        a 3d image\n    d:\n        dictionary returned by log_transform\n\n    Returns\n    -------------\n        de-logged image (np.ndarray)\n    \"\"\"\n    return np.exp(unstretch(image, d[\"log_min\"], d[\"log_max\"]))\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.label_bool_as_uint16","title":"<code>label_bool_as_uint16(in_obj)</code>","text":"<p>label segmentation and return as uint16</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.label_bool_as_uint16--parameters","title":"Parameters","text":"in_obj <p>a 3d image segmentaiton</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.label_bool_as_uint16--returns","title":"Returns","text":"<pre><code>np.ndimage of labeled segmentations as np.uint16\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def label_bool_as_uint16(in_obj: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    label segmentation and return as uint16\n\n    Parameters\n    ------------\n    in_obj:\n        a 3d image segmentaiton\n\n    Returns\n    -------------\n        np.ndimage of labeled segmentations as np.uint16\n\n    \"\"\"\n    return (in_obj &gt; 0).astype(np.uint16)\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.label_uint16","title":"<code>label_uint16(in_obj)</code>","text":"<p>label segmentation and return as uint16</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.label_uint16--parameters","title":"Parameters","text":"in_obj <p>a 3d image segmentaiton</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.label_uint16--returns","title":"Returns","text":"<pre><code>np.ndimage of labeled segmentations as np.uint16\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def label_uint16(in_obj: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    label segmentation and return as uint16\n\n    Parameters\n    ------------\n    in_obj:\n        a 3d image segmentaiton\n\n    Returns\n    -------------\n        np.ndimage of labeled segmentations as np.uint16\n\n    \"\"\"\n    if in_obj.dtype == \"bool\":\n        return label(in_obj).astype(np.uint16)\n    else:  # in_obj.dtype == np.uint8:\n        return label(in_obj &gt; 0).astype(np.uint16)\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.log_transform","title":"<code>log_transform(image)</code>","text":"<p>Renormalize image intensities to log space</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.log_transform--parameters","title":"Parameters","text":"image <p>a 3d image</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.log_transform--returns","title":"Returns","text":"<pre><code>Returns a tuple of transformed image and a dictionary to be passed into\ninverse_log_transform. The minimum and maximum from the dictionary\ncan be applied to an image by the inverse_log_transform to\nconvert it back to its former intensity values.\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def log_transform(image: np.ndarray) -&gt; Tuple[np.ndarray, dict]:\n\"\"\"Renormalize image intensities to log space\n\n    Parameters\n    ------------\n    image:\n        a 3d image\n\n    Returns\n    -------------\n        Returns a tuple of transformed image and a dictionary to be passed into\n        inverse_log_transform. The minimum and maximum from the dictionary\n        can be applied to an image by the inverse_log_transform to\n        convert it back to its former intensity values.\n    \"\"\"\n    orig_min, orig_max = extrema(image)[:2]\n    #\n    # We add 1/2 bit noise to an 8 bit image to give the log a bottom\n    #\n    limage = image.copy()\n    noise_min = orig_min + (orig_max - orig_min) / 256.0 + np.finfo(image.dtype).eps\n    limage[limage &lt; noise_min] = noise_min\n    d = {\"noise_min\": noise_min}\n    limage = np.log(limage)\n    log_min, log_max = extrema(limage)[:2]\n    d[\"log_min\"] = log_min\n    d[\"log_max\"] = log_max\n    return stretch(limage), d\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.make_aggregate","title":"<code>make_aggregate(img_in, w0=0, w1=0, w2=0, w3=0, w4=0, w5=0, w6=0, w7=0, w8=0, w9=0, scale_min_max=True)</code>","text":"<p>define multi_channel aggregate.  weighted sum wrapper (plugin)</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.make_aggregate--parameters","title":"Parameters","text":"<p>w0,w1,w2,w3,w4,w5,w6,w7,w8,w9     channel weights</p> scale_min_max <p>scale to [0,1] if True. default True</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.make_aggregate--returns","title":"Returns","text":"<pre><code>np.ndarray scaled aggregate\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def make_aggregate(\n    img_in: np.ndarray,\n    w0: int = 0,\n    w1: int = 0,\n    w2: int = 0,\n    w3: int = 0,\n    w4: int = 0,\n    w5: int = 0,\n    w6: int = 0,\n    w7: int = 0,\n    w8: int = 0,\n    w9: int = 0,\n    scale_min_max: bool = True,\n) -&gt; np.ndarray:\n\"\"\"define multi_channel aggregate.  weighted sum wrapper (plugin)\n\n    Parameters\n    ------------\n    w0,w1,w2,w3,w4,w5,w6,w7,w8,w9\n        channel weights\n    scale_min_max:\n        scale to [0,1] if True. default True\n\n    Returns\n    -------------\n        np.ndarray scaled aggregate\n\n    \"\"\"\n    weights = (w0, w1, w2, w3, w4, w5, w6, w7, w8, w9)\n    if scale_min_max:\n        # TODO: might NOT overflow here... maybe NOT do the normaization first?\n        return min_max_intensity_normalization(weighted_aggregate(min_max_intensity_normalization(img_in), *weights))\n    else:\n        return weighted_aggregate(img_in, *weights)\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.masked_inverted_watershed","title":"<code>masked_inverted_watershed(img_in, markers, mask)</code>","text":"<p>wrapper for watershed on inverted image and masked</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.masked_inverted_watershed--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def masked_inverted_watershed(img_in, markers, mask):\n\"\"\"wrapper for watershed on inverted image and masked\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n\n    \"\"\"\n    labels_out = watershed(\n        1.0 - img_in,\n        markers=markers,\n        connectivity=np.ones((1, 3, 3), bool),\n        mask=mask,\n    )\n    return labels_out\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.masked_object_thresh","title":"<code>masked_object_thresh(structure_img_smooth, th_method, cutoff_size, th_adjust)</code>","text":"<p>wrapper for applying Masked Object Thresholding with just two parameters via <code>MO</code> from <code>aicssegmentation</code></p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.masked_object_thresh--parameters","title":"Parameters","text":"structure_img_smooth <p>a 3d image</p> th_method <p>which method to use for calculating global threshold. Options include: \"triangle\", \"median\", and \"ave_tri_med\". \"ave_tri_med\" refers the average of \"triangle\" threshold and \"mean\" threshold.</p> cutoff_size <p>Masked Object threshold <code>size_min</code></p> th_adjust <p>Masked Object threshold <code>local_adjust</code></p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.masked_object_thresh--returns","title":"Returns","text":"<pre><code>np.ndimage\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def masked_object_thresh(\n    structure_img_smooth: np.ndarray, th_method: str, cutoff_size: int, th_adjust: float\n) -&gt; np.ndarray:\n\"\"\"\n    wrapper for applying Masked Object Thresholding with just two parameters via `MO` from `aicssegmentation`\n\n    Parameters\n    ------------\n    structure_img_smooth:\n        a 3d image\n    th_method:\n         which method to use for calculating global threshold. Options include:\n         \"triangle\", \"median\", and \"ave_tri_med\".\n         \"ave_tri_med\" refers the average of \"triangle\" threshold and \"mean\" threshold.\n    cutoff_size:\n        Masked Object threshold `size_min`\n    th_adjust:\n        Masked Object threshold `local_adjust`\n\n    Returns\n    -------------\n        np.ndimage\n\n    \"\"\"\n    struct_obj = MO(\n        structure_img_smooth,\n        object_minArea=cutoff_size,\n        global_thresh_method=th_method,\n        extra_criteria=True,\n        local_adjust=th_adjust,\n        return_object=False,\n        dilate=False,  # WARNING: dilate=True causes a bug if there is only one Z\n    )\n    return struct_obj\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.median_filter_slice_by_slice","title":"<code>median_filter_slice_by_slice(struct_img, size)</code>","text":"<p>wrapper for applying 2D median filter slice by slice on a 3D image</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.median_filter_slice_by_slice--parameters","title":"Parameters","text":"img <p>a 3d image</p> size <p>the linear \"size\" which will be squared for</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.median_filter_slice_by_slice--returns","title":"Returns","text":"<pre><code>np.ndimage\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def median_filter_slice_by_slice(struct_img: np.ndarray, size: int) -&gt; np.ndarray:\n\"\"\"\n    wrapper for applying 2D median filter slice by slice on a 3D image\n\n    Parameters\n    ------------\n    img:\n        a 3d image\n\n    size:\n        the linear \"size\" which will be squared for\n\n    Returns\n    -------------\n        np.ndimage\n\n    \"\"\"\n    structure_img_denoise = np.zeros_like(struct_img)\n\n    # this might be faster:  scipy.signal.medfilt2d()\n    for zz in range(struct_img.shape[0]):\n        structure_img_denoise[zz, :, :] = median_filter(struct_img[zz, :, :], size=size)\n\n    return structure_img_denoise\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.min_max_intensity_normalization","title":"<code>min_max_intensity_normalization(struct_img)</code>","text":"<p>Normalize the intensity of input image so that the value range is from 0 to 1.</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.min_max_intensity_normalization--parameters","title":"Parameters","text":"img <p>a 3d image</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.min_max_intensity_normalization--returns","title":"Returns","text":"<pre><code>np.ndimage\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def min_max_intensity_normalization(struct_img: np.ndarray) -&gt; np.ndarray:\n\"\"\"Normalize the intensity of input image so that the value range is from 0 to 1.\n\n    Parameters\n    ------------\n    img:\n        a 3d image\n\n    Returns\n    -------------\n        np.ndimage\n    \"\"\"\n    strech_min = struct_img.min()\n    strech_max = struct_img.max()\n    # do we need to convert to float?\n    # #.astype(np.double)\n    struct_img = (struct_img - strech_min + 1e-8) / (strech_max - strech_min + 1e-8)\n\n    return struct_img\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.scale_and_smooth","title":"<code>scale_and_smooth(img_in, median_sz=1, gauss_sig=1.34, slice_by_slice=True)</code>","text":"<p>helper to perform min-max scaling, and median+gaussian smoothign all at once Parameters</p> np.ndarray <p>a 3d image</p> int <p>width of median filter for signal</p> float <p>sigma for gaussian smoothing of  signal</p> slice_by_slice <p>NOT IMPLIMENTED.  toggles whether to do 3D operations or slice by slice in Z</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.scale_and_smooth--returns","title":"Returns","text":"<pre><code>np.ndimage\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def scale_and_smooth(\n    img_in: np.ndarray, median_sz: int = 1, gauss_sig: float = 1.34, slice_by_slice: bool = True\n) -&gt; np.ndarray:\n\"\"\"\n    helper to perform min-max scaling, and median+gaussian smoothign all at once\n    Parameters\n    ------------\n    img_in: np.ndarray\n        a 3d image\n    median_sz: int\n        width of median filter for signal\n    gauss_sig: float\n        sigma for gaussian smoothing of  signal\n    slice_by_slice:\n        NOT IMPLIMENTED.  toggles whether to do 3D operations or slice by slice in Z\n\n    Returns\n    -------------\n        np.ndimage\n\n    \"\"\"\n    img = min_max_intensity_normalization(img_in.copy())  # is this copy nescesa\n\n    # TODO:  make non-slice-by-slice work\n    slice_by_slice = True\n    if slice_by_slice:\n        if median_sz &gt; 1:\n            img = median_filter_slice_by_slice(img, size=median_sz)\n        img = image_smoothing_gaussian_slice_by_slice(img, sigma=gauss_sig)\n    else:\n        print(\" PLEASE CHOOOSE 'slice-by-slice', 3D is not yet implimented\")\n\n    return img\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.select_channel_from_raw","title":"<code>select_channel_from_raw(img_in, chan)</code>","text":"<p>\" select channel from multi-channel 3D image (np.ndarray) Parameters</p> img_in <p>the 3D image to be filterd on</p> chan <p>channel to extract.</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.select_channel_from_raw--returns","title":"Returns","text":"<pre><code>np.ndarray\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def select_channel_from_raw(img_in: np.ndarray, chan: Union[int, Tuple[int]]) -&gt; np.ndarray:\n\"\"\" \"\n    select channel from multi-channel 3D image (np.ndarray)\n    Parameters\n    ------------\n    img_in :\n        the 3D image to be filterd on\n    chan :\n        channel to extract.\n\n    Returns\n    -------------\n        np.ndarray\n    \"\"\"\n    return img_in[chan]\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.select_z_from_raw","title":"<code>select_z_from_raw(img_in, z_slice)</code>","text":"<p>select Z-slice from 3D multi-channel image (np.ndarray)</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.select_z_from_raw--parameters","title":"Parameters","text":"img_in <p>the 3D image to be filterd on</p> chan <p>channel to extract.</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.select_z_from_raw--returns","title":"Returns","text":"<pre><code>np.ndarray\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def select_z_from_raw(img_in: np.ndarray, z_slice: Union[int, Tuple[int]]) -&gt; np.ndarray:\n\"\"\"\n    select Z-slice from 3D multi-channel image (np.ndarray)\n\n    Parameters\n    ------------\n    img_in :\n        the 3D image to be filterd on\n    chan :\n        channel to extract.\n\n    Returns\n    -------------\n        np.ndarray\n    \"\"\"\n    if isinstance(z_slice, int):\n        z_slice = [z_slice]\n    else:\n        z_slice = list(z_slice)\n\n    return img_in[:, z_slice, :, :]\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.size_filter_linear_size","title":"<code>size_filter_linear_size(img, min_size, method='slice_by_slice', connectivity=1)</code>","text":"<p>size filter wraper to aiscsegmentation <code>size_filter</code> with size argument in linear units</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.size_filter_linear_size--parameters","title":"Parameters","text":"img <p>the image to filter on</p> int <p>the minimum size expressed as 1D length (so squared for slice-by-slice, cubed for 3D)</p> str <p>either \"3D\" or \"slice_by_slice\", default is \"slice_by_slice\"</p> int <p>the connectivity to use when computing object size</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.size_filter_linear_size--returns","title":"Returns","text":"<pre><code>np.ndarray\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def size_filter_linear_size(\n    img: np.ndarray, min_size: int, method: str = \"slice_by_slice\", connectivity: int = 1\n) -&gt; np.ndarray:\n\"\"\"size filter wraper to aiscsegmentation `size_filter` with size argument in linear units\n\n    Parameters\n    ------------\n    img:\n        the image to filter on\n    min_size: int\n        the minimum size expressed as 1D length (so squared for slice-by-slice, cubed for 3D)\n    method: str\n        either \"3D\" or \"slice_by_slice\", default is \"slice_by_slice\"\n    connnectivity: int\n        the connectivity to use when computing object size\n    Returns\n    -------------\n        np.ndarray\n    \"\"\"\n    # return remove_small_objects(img &gt; 0, min_size=min_size, connectivity=connectivity, in_place=False)\n    if not img.any():\n        return img\n\n    if method == \"3D\":\n        return size_filter(img, min_size=min_size**3, method=\"3D\", connectivity=connectivity)\n    elif method == \"slice_by_slice\":\n        return size_filter(img, min_size=min_size**2, method=\"slice_by_slice\", connectivity=connectivity)\n    else:\n        raise NotImplementedError(f\"unsupported method {method}\")\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.size_similarly","title":"<code>size_similarly(labels, secondary)</code>","text":"<p>Size the secondary matrix similarly to the labels matrix</p> <p>labels - labels matrix secondary - a secondary image or labels matrix which might be of             different size. Return the resized secondary matrix and a mask indicating what portion of the secondary matrix is bogus (manufactured values).</p> <p>Either the mask is all ones or the result is a copy, so you can modify the output within the unmasked region w/o destroying the original.</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def size_similarly(labels, secondary):\n\"\"\"Size the secondary matrix similarly to the labels matrix\n\n    labels - labels matrix\n    secondary - a secondary image or labels matrix which might be of\n                different size.\n    Return the resized secondary matrix and a mask indicating what portion\n    of the secondary matrix is bogus (manufactured values).\n\n    Either the mask is all ones or the result is a copy, so you can\n    modify the output within the unmasked region w/o destroying the original.\n    \"\"\"\n    if labels.shape[:2] == secondary.shape[:2]:\n        return secondary, np.ones(secondary.shape, bool)\n    if labels.shape[0] &lt;= secondary.shape[0] and labels.shape[1] &lt;= secondary.shape[1]:\n        if secondary.ndim == 2:\n            return (\n                secondary[: labels.shape[0], : labels.shape[1]],\n                np.ones(labels.shape, bool),\n            )\n        else:\n            return (\n                secondary[: labels.shape[0], : labels.shape[1], :],\n                np.ones(labels.shape, bool),\n            )\n\n    #\n    # Some portion of the secondary matrix does not cover the labels\n    #\n    result = np.zeros(list(labels.shape) + list(secondary.shape[2:]), secondary.dtype)\n    i_max = min(secondary.shape[0], labels.shape[0])\n    j_max = min(secondary.shape[1], labels.shape[1])\n    if secondary.ndim == 2:\n        result[:i_max, :j_max] = secondary[:i_max, :j_max]\n    else:\n        result[:i_max, :j_max, :] = secondary[:i_max, :j_max, :]\n    mask = np.zeros(labels.shape, bool)\n    mask[:i_max, :j_max] = 1\n    return result, mask\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.spot_filter_3","title":"<code>spot_filter_3(in_img, dot_scale_1, dot_cut_1, dot_scale_2, dot_cut_2, dot_scale_3, dot_cut_3)</code>","text":"<p>spot filter helper function for 3 levels (scale+cut).  if scale_i is &gt; 0.0001 its skipped</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.spot_filter_3--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> dot_scale_1 <p>scale or size of the \"filter\" float</p> dot_cut_1 <p>cutoff for thresholding float</p> dot_scale_2 <p>scale or size of the \"filter\" float</p> dot_cut_2 <p>cutoff for thresholding float</p> dot_scale_3 <p>scale or size of the \"filter\" float</p> dot_cut_3 <p>cutoff for thresholding float</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.spot_filter_3--returns","title":"Returns","text":"<p>segmented dots over 3 scales</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def spot_filter_3(\n    in_img: np.ndarray,\n    dot_scale_1: float,\n    dot_cut_1: float,\n    dot_scale_2: float,\n    dot_cut_2: float,\n    dot_scale_3: float,\n    dot_cut_3: float,\n) -&gt; np.ndarray:\n\"\"\"spot filter helper function for 3 levels (scale+cut).  if scale_i is &gt; 0.0001 its skipped\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    dot_scale_1:\n        scale or size of the \"filter\" float\n    dot_cut_1:\n        cutoff for thresholding float\n    dot_scale_2:\n        scale or size of the \"filter\" float\n    dot_cut_2:\n        cutoff for thresholding float\n    dot_scale_3:\n        scale or size of the \"filter\" float\n    dot_cut_3:\n        cutoff for thresholding float\n\n    Returns\n    -------------\n    segmented dots over 3 scales\n\n    \"\"\"\n    scales = [dot_scale_1, dot_scale_2, dot_scale_3]\n    cuts = [dot_cut_1, dot_cut_2, dot_cut_3]\n\n    s2_param = [[sc, ct] for sc, ct in zip(scales, cuts) if sc &gt; 0.0001]\n    # s2_param = [[dot_scale1, dot_cut1], [dot_scale2, dot_cut2], [dot_scale3, dot_cut3]]\n    return dot_2d_slice_by_slice_wrapper(in_img, s2_param)\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.stack_layers","title":"<code>stack_layers(*layers)</code>","text":"<p>wrapper to stack the inferred objects into a single numpy.ndimage</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def stack_layers(*layers) -&gt; np.ndarray:\n\"\"\"wrapper to stack the inferred objects into a single numpy.ndimage\"\"\"\n\n    return np.stack(layers, axis=0)\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.stack_masks","title":"<code>stack_masks(nuc_mask, cellmask, cyto_mask)</code>","text":"<p>stack canonical masks:  cellmask, nuc, cytoplasm as uint8 (never more than 255 nuclei)</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def stack_masks(nuc_mask: np.ndarray, cellmask: np.ndarray, cyto_mask: np.ndarray) -&gt; np.ndarray:\n\"\"\"stack canonical masks:  cellmask, nuc, cytoplasm as uint8 (never more than 255 nuclei)\"\"\"\n    layers = [nuc_mask, cellmask, cyto_mask]\n    return np.stack(layers, axis=0).astype(np.uint8)\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.stretch","title":"<code>stretch(image, mask=None)</code>","text":"<p>Normalize an image to make the minimum zero and maximum one</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.stretch--parameters","title":"Parameters","text":"image <p>a 3d image to be normalized</p> mask <p>optional mask of relevant pixels. None (default) means don't mask</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.stretch--returns","title":"Returns","text":"<pre><code>stretched (normalized to [0,1]) image (np.ndarray)\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def stretch(image: np.ndarray, mask: Union[np.ndarray, None] = None) -&gt; np.ndarray:\n\"\"\"Normalize an image to make the minimum zero and maximum one\n\n    Parameters\n    ------------\n    image:\n        a 3d image to be normalized\n    mask:\n        optional mask of relevant pixels. None (default) means don't mask\n\n    Returns\n    -------------\n        stretched (normalized to [0,1]) image (np.ndarray)\n\n    \"\"\"\n    image = np.array(image, float)\n    if np.product(image.shape) == 0:\n        return image\n    if mask is None:\n        minval = np.min(image)\n        maxval = np.max(image)\n        if minval == maxval:\n            if minval &lt; 0:\n                return np.zeros_like(image)\n            elif minval &gt; 1:\n                return np.ones_like(image)\n            return image\n        else:\n            return (image - minval) / (maxval - minval)\n    else:\n        significant_pixels = image[mask]\n        if significant_pixels.size == 0:\n            return image\n        minval = np.min(significant_pixels)\n        maxval = np.max(significant_pixels)\n        if minval == maxval:\n            transformed_image = minval\n        else:\n            transformed_image = (significant_pixels - minval) / (maxval - minval)\n        result = image.copy()\n        image[mask] = transformed_image\n        return image\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.threshold_li_log","title":"<code>threshold_li_log(image_in)</code>","text":"<p>thin wrapper to log-scale and inverse log image for threshold finding using li minimum cross-entropy</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.threshold_li_log--parameters","title":"Parameters","text":"image <p>an np.ndarray</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.threshold_li_log--returns","title":"Returns","text":"<pre><code>boolean np.ndarray\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def threshold_li_log(image_in: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    thin wrapper to log-scale and inverse log image for threshold finding using li minimum cross-entropy\n\n    Parameters\n    ------------\n    image:\n        an np.ndarray\n    Returns\n    -------------\n        boolean np.ndarray\n\n    \"\"\"\n    image, d = log_transform(image_in.copy())\n    threshold = threshold_li(image)\n    threshold = inverse_log_transform(threshold, d)\n    return threshold\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.threshold_multiotsu_log","title":"<code>threshold_multiotsu_log(image_in)</code>","text":"<p>thin wrapper to log-scale and inverse log image for threshold finding using otsu</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.threshold_multiotsu_log--parameters","title":"Parameters","text":"image <p>an np.ndarray</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.threshold_multiotsu_log--returns","title":"Returns","text":"<pre><code>boolean np.ndarray\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def threshold_multiotsu_log(image_in):\n\"\"\"\n    thin wrapper to log-scale and inverse log image for threshold finding using otsu\n\n    Parameters\n    ------------\n    image:\n        an np.ndarray\n    Returns\n    -------------\n        boolean np.ndarray\n    \"\"\"\n    image, d = log_transform(image_in.copy())\n    thresholds = threshold_multiotsu(image)\n    thresholds = inverse_log_transform(thresholds, d)\n    return thresholds\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.threshold_otsu_log","title":"<code>threshold_otsu_log(image_in)</code>","text":"<p>thin wrapper to log-scale and inverse log image for threshold finding using otsu</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.threshold_otsu_log--parameters","title":"Parameters","text":"image <p>an np.ndarray</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.threshold_otsu_log--returns","title":"Returns","text":"<pre><code>boolean np.ndarray\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def threshold_otsu_log(image_in):\n\"\"\"\n    thin wrapper to log-scale and inverse log image for threshold finding using otsu\n\n    Parameters\n    ------------\n    image:\n        an np.ndarray\n    Returns\n    -------------\n        boolean np.ndarray\n    \"\"\"\n    image, d = log_transform(image_in.copy())\n    threshold = threshold_otsu(image)\n    threshold = inverse_log_transform(threshold, d)\n    return threshold\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.unstretch","title":"<code>unstretch(image, minval, maxval)</code>","text":"<p>Perform the inverse of stretch, given a stretched image</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.unstretch--parameters","title":"Parameters","text":"image <p>an image stretched by stretch or similarly scaled value or values</p> minval <p>minimum of previously stretched image</p> maxval <p>maximum of previously stretched image</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.unstretch--returns","title":"Returns","text":"<pre><code>stretched (normalized to [0,1]) image (np.ndarray)\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def unstretch(image: np.ndarray, minval: Union[int, float], maxval: Union[int, float]) -&gt; np.ndarray:\n\"\"\"Perform the inverse of stretch, given a stretched image\n\n    Parameters\n    ------------\n    image:\n        an image stretched by stretch or similarly scaled value or values\n    minval:\n        minimum of previously stretched image\n    maxval:\n        maximum of previously stretched image\n\n    Returns\n    -------------\n        stretched (normalized to [0,1]) image (np.ndarray)\n    \"\"\"\n    return image * (maxval - minval) + minval\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.vesselness_slice_by_slice","title":"<code>vesselness_slice_by_slice(nd_array, sigma, cutoff=-1, tau=0.75)</code>","text":"<p>wrapper for applying multi-scale 2D filament filter on 3D images in a slice by slice fashion,  Note that it only performs at a single scale....     NOTE: The paramater whiteonblack = True is hardcoded which sets the filamentous structures are bright on dark background</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.vesselness_slice_by_slice--parameters","title":"Parameters","text":"nd_array <p>the 3D image to be filterd on</p> sigma <p>single scale to use</p> cutoff <p>the cutoff value to apply on the filter result. If the cutoff is negative, no cutoff will be applied. Default is -1.</p> tau <p>parameter that controls response uniformity. The value has to be between 0.5 and 1. Lower tau means more intense output response. Default is 0.5</p> Source code in <code>infer_subc/core/img.py</code> <pre><code>def vesselness_slice_by_slice(nd_array: np.ndarray, sigma: float, cutoff: float = -1, tau: float = 0.75):\n\"\"\"\n    wrapper for applying multi-scale 2D filament filter on 3D images in a\n    slice by slice fashion,  Note that it only performs at a single scale....     NOTE: The paramater\n    whiteonblack = True is hardcoded which sets the filamentous structures are bright on dark background\n\n    Parameters\n    -----------\n    nd_array:\n        the 3D image to be filterd on\n    sigma:\n        single scale to use\n    cutoff:\n        the cutoff value to apply on the filter result. If the cutoff is\n        negative, no cutoff will be applied. Default is -1.\n    tau:\n        parameter that controls response uniformity. The value has to be\n        between 0.5 and 1. Lower tau means more intense output response.\n        Default is 0.5\n    \"\"\"\n\n    # # this hack is to accomodate the workflow widgets\n    # if not isinstance(sigmas, List):\n    #     sigmas = [sigmas]\n\n    mip = np.amax(nd_array, axis=0)\n    response = np.zeros(nd_array.shape)\n    for zz in range(nd_array.shape[0]):\n        tmp = np.concatenate((nd_array[zz, :, :], mip), axis=1)\n        tmp = vesselness2D(tmp, sigmas=[sigma], tau=tau, whiteonblack=True)\n        response[zz, :, : nd_array.shape[2] - 3] = tmp[:, : nd_array.shape[2] - 3]\n\n    if cutoff &lt; 0:\n        return response\n    else:\n        return response &gt; cutoff\n</code></pre>"},{"location":"infer_subc/core/img/#infer_subc.core.img.weighted_aggregate","title":"<code>weighted_aggregate(img_in, *weights)</code>","text":"<p>helper to find weighted sum images Parameters</p> img_in <p>a 3d imagenp.ndarray</p> <p>*weights:     list of integer weights to apply to our channels.  if the weights are less than 1, they will NOT be included (and might not be there)</p>"},{"location":"infer_subc/core/img/#infer_subc.core.img.weighted_aggregate--returns","title":"Returns","text":"<pre><code>np.ndimage of weighted sum of channels\n</code></pre> Source code in <code>infer_subc/core/img.py</code> <pre><code>def weighted_aggregate(img_in: np.ndarray, *weights: int) -&gt; np.ndarray:\n\"\"\"\n    helper to find weighted sum images\n    Parameters\n    ------------\n    img_in:\n        a 3d imagenp.ndarray\n    *weights:\n        list of integer weights to apply to our channels.  if the weights are less than 1, they will NOT be included (and might not be there)\n\n    Returns\n    -------------\n        np.ndimage of weighted sum of channels\n\n    \"\"\"\n\n    img_out = np.zeros_like(img_in[0]).astype(np.double)\n    for ch, w in enumerate(weights):\n        if w &gt; 0:\n            img_out += (w * 1.0) * img_in[ch]\n\n    return img_out\n</code></pre>"},{"location":"infer_subc/napari/organelle_config/","title":"Organelle config","text":"<p>the 'organelle_config' path contains a workflow definitions and the contracts for the workflow module to access the infer_subc module.</p> <p>all_functions.json contains prototypes for all the functions callable by workflows.</p>"},{"location":"infer_subc/napari/plugin/","title":"organelle-segmenter-plugin","text":"<p>The <code>infer_subc</code> module is exposed to Napari via the organelle-segmenter-plugin which was co-developed with 'infer_subc'</p>"},{"location":"infer_subc/organelles/cellmask/","title":"infer_subc/organelles/cellmask","text":"<p>Routines for inference of cellmask for masking later organell segmentation steps.</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.choose_max_label_cellmask_union_nucleus","title":"<code>choose_max_label_cellmask_union_nucleus(cellmask_img, cellmask_obj, nuclei_labels, interior_labels=True)</code>","text":"<p>get cellmask UNION nuclei for largest signal label</p> <pre><code>Parameters\n</code></pre> cellmask_img <p>the cellmask image intensities</p> cellmask_obj <p>thresholded cellmask mask</p> nuclei_labels <p>inferred nuclei labels (np.uint16)</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.choose_max_label_cellmask_union_nucleus--returns","title":"Returns","text":"<pre><code>boolean np.ndarray of cellmask+nuc corresponding to the label of largest total cellmask signal\n</code></pre> Source code in <code>infer_subc/organelles/cellmask.py</code> <pre><code>def choose_max_label_cellmask_union_nucleus(\n    cellmask_img: np.ndarray, cellmask_obj: np.ndarray, nuclei_labels: np.ndarray, interior_labels: bool = True\n) -&gt; np.ndarray:\n\"\"\"get cellmask UNION nuclei for largest signal label\n\n        Parameters\n    ------------\n    cellmask_img:\n        the cellmask image intensities\n    cellmask_obj:\n        thresholded cellmask mask\n    nuclei_labels:\n        inferred nuclei labels (np.uint16)\n\n    Returns\n    -------------\n        boolean np.ndarray of cellmask+nuc corresponding to the label of largest total cellmask signal\n\n    \"\"\"\n\n    cellmask_labels = masked_inverted_watershed(cellmask_img, nuclei_labels, cellmask_obj)\n\n    # should we restrict to interior nuclear labels?\n    # get_interior_labels(nuclei_object)\n    # would need to update get_max_label to only choose the labels in get_interior_label\n    target_labels = get_interior_labels(nuclei_labels) if interior_labels else None\n\n    keep_label = get_max_label(cellmask_img, cellmask_labels, target_labels=target_labels)\n\n    cellmask_out = np.zeros_like(cellmask_labels)\n    cellmask_out[cellmask_labels == keep_label] = 1\n    cellmask_out[nuclei_labels == keep_label] = 1\n\n    return cellmask_out &gt; 0\n</code></pre>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.fixed_infer_cellmask_fromaggr","title":"<code>fixed_infer_cellmask_fromaggr(in_img, nuclei_obj)</code>","text":"<p>Procedure to infer cellmask from linearly unmixed input, with a fixed set of parameters for each step in the procedure.  i.e. \"hard coded\"</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.fixed_infer_cellmask_fromaggr--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p> nuclei_obj <p>a 3d image containing the inferred nuclei</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.fixed_infer_cellmask_fromaggr--returns","title":"Returns","text":"cellmask_mask <p>a logical/labels object defining boundaries of cellmask</p> Source code in <code>infer_subc/organelles/cellmask.py</code> <pre><code>def fixed_infer_cellmask_fromaggr(in_img: np.ndarray, nuclei_obj: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer cellmask from linearly unmixed input, with a *fixed* set of parameters for each step in the procedure.  i.e. \"hard coded\"\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n    nuclei_obj:\n        a 3d image containing the inferred nuclei\n\n    Returns\n    -------------\n    cellmask_mask:\n        a logical/labels object defining boundaries of cellmask\n    \"\"\"\n\n    ###################\n    # PARAMETERS\n    ###################\n    median_sz = 15\n    gauss_sig = 1.34\n    mo_method = \"ave\"\n    mo_adjust = 0.5\n    mo_cutoff_size = 150\n    max_hole_w = 50\n    small_obj_w = 45\n\n    cellmask_out = infer_cellmask_fromaggr(\n        in_img, nuclei_obj, median_sz, gauss_sig, mo_method, mo_adjust, mo_cutoff_size, max_hole_w, small_obj_w\n    )\n\n    return cellmask_out\n</code></pre>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.get_cellmask","title":"<code>get_cellmask(in_img, nuclei_obj, meta_dict, out_data_path)</code>","text":"<p>load cellmask if it exists, otherwise calculate and write inferred cellmask to ome.tif file</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.get_cellmask--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> nuclei_obj <p>a 3d image containing the inferred nuclei</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.get_cellmask--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/cellmask.py</code> <pre><code>def get_cellmask(in_img: np.ndarray, nuclei_obj: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    load cellmask if it exists, otherwise calculate and write inferred cellmask to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    nuclei_obj:\n        a 3d image containing the inferred nuclei\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n\n    try:\n        cellmask = import_inferred_organelle(\"cell\", meta_dict, out_data_path)\n    except:\n        start = time.time()\n        print(\"starting segmentation...\")\n        cellmask = fixed_infer_cellmask_fromaggr(in_img, nuclei_obj)\n        out_file_n = export_inferred_organelle(cellmask, \"cell\", meta_dict, out_data_path)\n        end = time.time()\n        print(f\"inferred (and exported) cellmask in ({(end - start):0.2f}) sec\")\n\n    return cellmask&gt;0\n</code></pre>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.infer_and_export_cellmask","title":"<code>infer_and_export_cellmask(in_img, nuclei_obj, meta_dict, out_data_path)</code>","text":"<p>infer cellmask and write inferred cellmask to ome.tif file</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.infer_and_export_cellmask--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> nuclei_obj <p>a 3d image containing the inferred nuclei</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.infer_and_export_cellmask--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/cellmask.py</code> <pre><code>def infer_and_export_cellmask(\n    in_img: np.ndarray, nuclei_obj: np.ndarray, meta_dict: Dict, out_data_path: Path\n) -&gt; np.ndarray:\n\"\"\"\n    infer cellmask and write inferred cellmask to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    nuclei_obj:\n        a 3d image containing the inferred nuclei\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    cellmask = fixed_infer_cellmask_fromaggr(in_img, nuclei_obj)\n    out_file_n = export_inferred_organelle(cellmask, \"cell\", meta_dict, out_data_path)\n    print(f\"inferred cellmask. wrote {out_file_n}\")\n    return cellmask&gt;0\n</code></pre>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.infer_cellmask_fromaggr","title":"<code>infer_cellmask_fromaggr(in_img, nuclei_obj, median_sz, gauss_sig, mo_method, mo_adjust, mo_cutoff_size, max_hole_w, small_obj_w)</code>","text":"<p>Procedure to infer cellmask from linearly unmixed input.</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.infer_cellmask_fromaggr--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p> nuclei_obj <p>a 3d image containing the inferred nuclei</p> median_sz <p>width of median filter for cellmask signal</p> gauss_sig <p>sigma for gaussian smoothing of cellmask signal</p> mo_method <p>which method to use for calculating global threshold. Options include: \"triangle\" (or \"tri\"), \"median\" (or \"med\"), and \"ave_tri_med\" (or \"ave\"). \"ave\" refers the average of \"triangle\" threshold and \"mean\" threshold.</p> mo_adjust <p>Masked Object threshold <code>local_adjust</code></p> mo_cutoff_size <p>Masked Object threshold <code>size_min</code></p> max_hole_w <p>hole filling cutoff for cellmask signal post-processing</p> small_obj_w <p>minimu object size cutoff for cellmask signal post-processing</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.infer_cellmask_fromaggr--returns","title":"Returns","text":"cellmask_mask <p>a logical/labels object defining boundaries of cellmask</p> Source code in <code>infer_subc/organelles/cellmask.py</code> <pre><code>def infer_cellmask_fromaggr(\n    in_img: np.ndarray,\n    nuclei_obj: np.ndarray,\n    median_sz: int,\n    gauss_sig: float,\n    mo_method: str,\n    mo_adjust: float,\n    mo_cutoff_size: int,\n    max_hole_w: int,\n    small_obj_w: int,\n) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer cellmask from linearly unmixed input.\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n    nuclei_obj:\n        a 3d image containing the inferred nuclei\n    median_sz:\n        width of median filter for _cellmask_ signal\n    gauss_sig:\n        sigma for gaussian smoothing of _cellmask_ signal\n    mo_method:\n         which method to use for calculating global threshold. Options include:\n         \"triangle\" (or \"tri\"), \"median\" (or \"med\"), and \"ave_tri_med\" (or \"ave\").\n         \"ave\" refers the average of \"triangle\" threshold and \"mean\" threshold.\n    mo_adjust:\n        Masked Object threshold `local_adjust`\n    mo_cutoff_size:\n        Masked Object threshold `size_min`\n    max_hole_w:\n        hole filling cutoff for cellmask signal post-processing\n    small_obj_w:\n        minimu object size cutoff for cellmask signal post-processing\n\n    Returns\n    -------------\n    cellmask_mask:\n        a logical/labels object defining boundaries of cellmask\n\n    \"\"\"\n    # nuc_ch = NUC_CH\n    ###################\n    # EXTRACT\n    ###################\n    print(f\"shape in_img {in_img.shape}\")\n    print(f\"shape nuclei_obj {nuclei_obj.shape}\")\n\n    struct_img = raw_cellmask_fromaggr(in_img)\n    # scaled_signal = struct_img.copy()  # already scaled\n\n    ###################\n    # PRE_PROCESSING\n    ###################\n    ################# part 1- cellmask\n    print(f\"shape struct_img {struct_img.shape}\")\n\n    # Linear-ish processing\n    struct_img = scale_and_smooth(struct_img, median_sz=median_sz, gauss_sig=gauss_sig)\n\n    struct_img_non_lin = non_linear_cellmask_transform_MCZ(struct_img)\n\n    ###################\n    # CORE_PROCESSING\n    ###################\n    struct_obj = masked_object_thresh(\n        struct_img_non_lin, th_method=mo_method, cutoff_size=mo_cutoff_size, th_adjust=mo_adjust\n    )\n\n    ###################\n    # POST_PROCESSING\n    ###################\n    # struct_obj = hole_filling_linear_size(struct_obj,\n    #                                             hole_min =0 ,\n    #                                             hole_max=max_hole_w)\n    # struct_obj = size_filter_linear_size(struct_obj,\n    #                                                 min_size= small_obj_w)\n    struct_obj = fill_and_filter_linear_size(struct_obj, hole_min=0, hole_max=max_hole_w, min_size=small_obj_w)\n\n    ###################\n    # POST- POST_PROCESSING\n    ###################\n    cellmask_out = choose_max_label_cellmask_union_nucleus(struct_img, struct_obj, nuclei_obj)\n\n    return cellmask_out\n</code></pre>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.non_linear_cellmask_transform_MCZ","title":"<code>non_linear_cellmask_transform_MCZ(in_img)</code>","text":"<p>non-linear distortion to fill out cellmask log + edge of smoothed composite</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.non_linear_cellmask_transform_MCZ--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.non_linear_cellmask_transform_MCZ--returns","title":"Returns","text":"<pre><code>np.ndarray scaled aggregate\n</code></pre> Source code in <code>infer_subc/organelles/cellmask.py</code> <pre><code>def non_linear_cellmask_transform_MCZ(in_img):\n\"\"\"non-linear distortion to fill out cellmask\n    log + edge of smoothed composite\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n\n    Returns\n    -------------\n        np.ndarray scaled aggregate\n    \"\"\"\n    # non-Linear processing\n    log_img, d = log_transform(in_img.copy())\n    log_img = min_max_intensity_normalization(log_img)\n    return min_max_intensity_normalization(scharr(log_img)) + log_img\n</code></pre>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.raw_cellmask_fromaggr","title":"<code>raw_cellmask_fromaggr(img_in, scale_min_max=True)</code>","text":"<p>define cellmask image CELLMASK_W = (6.,1.,2.) CELLMASK_CH = (LYSO_CH,ER_CH,GOLGI_CH)</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.raw_cellmask_fromaggr--parameters","title":"Parameters","text":"<p>img_in     a 3d image</p> scale_min_max <p>scale to [0,1] if True. default True</p>"},{"location":"infer_subc/organelles/cellmask/#infer_subc.organelles.cellmask.raw_cellmask_fromaggr--returns","title":"Returns","text":"<pre><code>np.ndarray scaled aggregate\n</code></pre> Source code in <code>infer_subc/organelles/cellmask.py</code> <pre><code>def raw_cellmask_fromaggr(img_in: np.ndarray, scale_min_max: bool = True) -&gt; np.ndarray:\n\"\"\"define cellmask image\n    CELLMASK_W = (6.,1.,2.)\n    CELLMASK_CH = (LYSO_CH,ER_CH,GOLGI_CH)\n\n    Parameters\n    ------------\n    img_in\n        a 3d image\n    scale_min_max:\n        scale to [0,1] if True. default True\n\n    Returns\n    -------------\n        np.ndarray scaled aggregate\n\n    \"\"\"\n    weights = (0, 6, 0, 2, 0, 1)\n    if scale_min_max:\n        return min_max_intensity_normalization(weighted_aggregate(img_in, *weights))\n    else:\n        return weighted_aggregate(img_in, *weights)\n</code></pre>"},{"location":"infer_subc/organelles/cytoplasm/","title":"infer_subc/organelles/cytoplasm","text":""},{"location":"infer_subc/organelles/cytoplasm/#infer_subc.organelles.cytoplasm.get_cytoplasm","title":"<code>get_cytoplasm(nuclei_obj, cellmask, meta_dict, out_data_path)</code>","text":"<p>load cytoplasm if it exists, otherwise calculate and write to ome.tif file</p>"},{"location":"infer_subc/organelles/cytoplasm/#infer_subc.organelles.cytoplasm.get_cytoplasm--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> cellmask <p>a 3d image containing the cellmask object (mask)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/cytoplasm/#infer_subc.organelles.cytoplasm.get_cytoplasm--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/cytoplasm.py</code> <pre><code>def get_cytoplasm(nuclei_obj: np.ndarray, cellmask: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    load cytoplasm if it exists, otherwise calculate and write to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    cellmask:\n        a 3d image containing the cellmask object (mask)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    try:\n        cytoplasm = import_inferred_organelle(\"cyto\", meta_dict, out_data_path)&gt;0\n    except:\n        start = time.time()\n        print(\"starting segmentation...\")\n        cytoplasm = infer_and_export_cytoplasm(nuclei_obj, cellmask, meta_dict, out_data_path)\n        end = time.time()\n        print(f\"inferred cytoplasm in ({(end - start):0.2f}) sec\")\n\n    return cytoplasm\n</code></pre>"},{"location":"infer_subc/organelles/cytoplasm/#infer_subc.organelles.cytoplasm.infer_and_export_cytoplasm","title":"<code>infer_and_export_cytoplasm(nuclei_object, cellmask, meta_dict, out_data_path)</code>","text":"<p>infer nucleus and write inferred nuclei to ome.tif file</p>"},{"location":"infer_subc/organelles/cytoplasm/#infer_subc.organelles.cytoplasm.infer_and_export_cytoplasm--parameters","title":"Parameters","text":"nuclei_object <p>a 3d image containing the nuclei object</p> cellmask <p>a 3d image containing the cellmask object (mask)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/cytoplasm/#infer_subc.organelles.cytoplasm.infer_and_export_cytoplasm--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/cytoplasm.py</code> <pre><code>def infer_and_export_cytoplasm(\n    nuclei_object: np.ndarray, cellmask: np.ndarray, meta_dict: Dict, out_data_path: Path\n) -&gt; np.ndarray:\n\"\"\"\n    infer nucleus and write inferred nuclei to ome.tif file\n\n    Parameters\n    ------------\n    nuclei_object:\n        a 3d image containing the nuclei object\n    cellmask:\n        a 3d image containing the cellmask object (mask)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    cytoplasm = infer_cytoplasm(nuclei_object, cellmask)\n\n    out_file_n = export_inferred_organelle(cytoplasm, \"cyto\", meta_dict, out_data_path)\n    print(f\"inferred cytoplasm. wrote {out_file_n}\")\n    return cytoplasm\n</code></pre>"},{"location":"infer_subc/organelles/cytoplasm/#infer_subc.organelles.cytoplasm.infer_cytoplasm","title":"<code>infer_cytoplasm(nuclei_object, cellmask, erode_nuclei=True)</code>","text":"<p>Procedure to infer infer from linearly unmixed input. (logical cellmask AND NOT nucleus)</p>"},{"location":"infer_subc/organelles/cytoplasm/#infer_subc.organelles.cytoplasm.infer_cytoplasm--parameters","title":"Parameters","text":"nuclei_object <p>a 3d image containing the nuclei object</p> cellmask <p>a 3d image containing the cellmask object (mask)</p> erode_nuclei <p>should we erode?</p>"},{"location":"infer_subc/organelles/cytoplasm/#infer_subc.organelles.cytoplasm.infer_cytoplasm--returns","title":"Returns","text":"<p>cytoplasm_mask     boolean np.ndarray</p> Source code in <code>infer_subc/organelles/cytoplasm.py</code> <pre><code>def infer_cytoplasm(nuclei_object: np.ndarray, cellmask: np.ndarray, erode_nuclei: bool = True) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer infer from linearly unmixed input. (logical cellmask AND NOT nucleus)\n\n    Parameters\n    ------------\n    nuclei_object:\n        a 3d image containing the nuclei object\n    cellmask:\n        a 3d image containing the cellmask object (mask)\n    erode_nuclei:\n        should we erode?\n\n    Returns\n    -------------\n    cytoplasm_mask\n        boolean np.ndarray\n\n    \"\"\"\n    nucleus_obj = apply_mask(nuclei_object, cellmask)\n\n    if erode_nuclei:\n        cytoplasm_mask = np.logical_xor(cellmask, binary_erosion(nucleus_obj))\n    else:\n        cytoplasm_mask = np.logical_xor(cellmask, nucleus_obj)\n\n    return cytoplasm_mask\n</code></pre>"},{"location":"infer_subc/organelles/er/","title":"infer_subc/organelles/er","text":""},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.fixed_infer_ER","title":"<code>fixed_infer_ER(in_img)</code>","text":"<p>Procedure to infer endoplasmic rediculum from linearly unmixed input with fixed parameters</p>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.fixed_infer_ER--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.fixed_infer_ER--returns","title":"Returns","text":"<p>peroxi_object     mask defined extent of peroxisome object</p> Source code in <code>infer_subc/organelles/er.py</code> <pre><code>def fixed_infer_ER(in_img: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer endoplasmic rediculum from linearly unmixed input with *fixed parameters*\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n\n    Returns\n    -------------\n    peroxi_object\n        mask defined extent of peroxisome object\n    \"\"\"\n    median_sz = 3\n    gauss_sig = 2.0\n    filament_scale = 1\n    filament_cut = 0.015\n    small_obj_w = 2\n    return infer_ER(in_img, median_sz, gauss_sig, filament_scale, filament_cut, small_obj_w)\n</code></pre>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.get_ER","title":"<code>get_ER(in_img, meta_dict, out_data_path)</code>","text":"<p>load endoplasmic_reticulum if it exists, otherwise calculate and write to ome.tif file</p>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.get_ER--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.get_ER--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/er.py</code> <pre><code>def get_ER(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    load endoplasmic_reticulum if it exists, otherwise calculate and write to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n\n    try:\n        er = import_inferred_organelle(\"ER\", meta_dict, out_data_path)\n    except:\n        start = time.time()\n        print(\"starting segmentation...\")\n        er = infer_and_export_ER(in_img, meta_dict, out_data_path)\n        end = time.time()\n        print(f\"inferred (and exported) ER in ({(end - start):0.2f}) sec\")\n\n    return er\n</code></pre>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.infer_ER","title":"<code>infer_ER(in_img, median_sz, gauss_sig, filament_scale, filament_cut, small_obj_w)</code>","text":"<p>Procedure to infer peroxisome from linearly unmixed input.</p>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.infer_ER--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p> median_sz <p>width of median filter for signal</p> gauss_sig <p>sigma for gaussian smoothing of  signal</p> filament_scale <p>scale (log_sigma) for filament filter</p> filament_cut <p>threshold for filament fitered threshold</p> small_obj_w <p>minimu object size cutoff for nuclei post-processing</p>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.infer_ER--returns","title":"Returns","text":"<p>peroxi_object     mask defined extent of peroxisome object</p> Source code in <code>infer_subc/organelles/er.py</code> <pre><code>def infer_ER(\n    in_img: np.ndarray,\n    median_sz: int,\n    gauss_sig: float,\n    filament_scale: float,\n    filament_cut: float,\n    small_obj_w: int,\n) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer peroxisome from linearly unmixed input.\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n    median_sz:\n        width of median filter for signal\n    gauss_sig:\n        sigma for gaussian smoothing of  signal\n    filament_scale:\n        scale (log_sigma) for filament filter\n    filament_cut:\n        threshold for filament fitered threshold\n    small_obj_w:\n        minimu object size cutoff for nuclei post-processing\n    Returns\n    -------------\n    peroxi_object\n        mask defined extent of peroxisome object\n    \"\"\"\n    er_ch = ER_CH\n    ###################\n    # EXTRACT\n    ###################\n    er = select_channel_from_raw(in_img, er_ch)\n\n    ###################\n    # PRE_PROCESSING\n    ###################\n    # er = normalized_edge_preserving_smoothing(er)\n    struct_img = scale_and_smooth(er, median_sz=median_sz, gauss_sig=gauss_sig)\n\n    ###################\n    # CORE_PROCESSING\n    ###################\n    # f2_param = [[filament_scale, filament_cut]]\n    # # f2_param = [[1, 0.15]]  # [scale_1, cutoff_1]\n    # struct_obj = filament_2d_wrapper(er, f2_param)\n    struct_obj = filament_filter(struct_img, filament_scale, filament_cut)\n\n    ###################\n    # POST_PROCESSING\n    ###################\n    struct_obj = size_filter_linear_size(struct_obj, min_size=small_obj_w)\n\n    return label_bool_as_uint16(struct_obj)\n</code></pre>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.infer_and_export_ER","title":"<code>infer_and_export_ER(in_img, meta_dict, out_data_path)</code>","text":"<p>infer ER and write inferred ER to ome.tif file</p>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.infer_and_export_ER--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/er/#infer_subc.organelles.er.infer_and_export_ER--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/er.py</code> <pre><code>def infer_and_export_ER(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    infer ER and write inferred ER to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    er = fixed_infer_ER(in_img)\n    out_file_n = export_inferred_organelle(er, \"ER\", meta_dict, out_data_path)\n    print(f\"inferred ER. wrote {out_file_n}\")\n    return er\n</code></pre>"},{"location":"infer_subc/organelles/golgi/","title":"infer_subc/organelles/golgi","text":""},{"location":"infer_subc/organelles/golgi/#infer_subc.organelles.golgi.fixed_infer_golgi","title":"<code>fixed_infer_golgi(in_img, cytoplasm_mask=None)</code>","text":"<p>Procedure to infer golgi from linearly unmixed input.</p> <p>Parameters</p> <p>in_img:      a 3d image containing all the channels  Returns</p> <p>golgi_object      mask defined extent of golgi object</p> Source code in <code>infer_subc/organelles/golgi.py</code> <pre><code>def fixed_infer_golgi(in_img: np.ndarray, cytoplasm_mask: Optional[np.ndarray] = None) -&gt; np.ndarray:\n\"\"\"\n     Procedure to infer golgi from linearly unmixed input.\n\n     Parameters\n     ------------\n     in_img:\n         a 3d image containing all the channels\n     Returns\n     -------------\n    golgi_object\n         mask defined extent of golgi object\n    \"\"\"\n\n    median_sz = 4\n    gauss_sig = 1.34\n    mo_method = \"tri\"\n    mo_adjust = 0.90\n    mo_cutoff_size = 1200\n    min_thickness = 1.6\n    thin = 1\n    dot_scale = 1.6\n    dot_cut = 0.02\n    small_obj_w = 3\n\n    return infer_golgi(\n        in_img,\n        median_sz,\n        gauss_sig,\n        mo_method,\n        mo_adjust,\n        mo_cutoff_size,\n        min_thickness,\n        thin,\n        dot_scale,\n        dot_cut,\n        small_obj_w,\n    )\n</code></pre>"},{"location":"infer_subc/organelles/golgi/#infer_subc.organelles.golgi.get_golgi","title":"<code>get_golgi(in_img, meta_dict, out_data_path)</code>","text":"<p>load golgi if it exists, otherwise calculate and write to ome.tif file</p>"},{"location":"infer_subc/organelles/golgi/#infer_subc.organelles.golgi.get_golgi--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/golgi/#infer_subc.organelles.golgi.get_golgi--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/golgi.py</code> <pre><code>def get_golgi(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    load golgi if it exists, otherwise calculate and write to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n\n    try:\n        golgi = import_inferred_organelle(\"golgi\", meta_dict, out_data_path)\n    except:\n        start = time.time()\n        print(\"starting segmentation...\")\n        golgi = infer_and_export_golgi(in_img, meta_dict, out_data_path)\n        end = time.time()\n        print(f\"inferred (and exported) golgi in ({(end - start):0.2f}) sec\")\n\n    return golgi\n</code></pre>"},{"location":"infer_subc/organelles/golgi/#infer_subc.organelles.golgi.infer_and_export_golgi","title":"<code>infer_and_export_golgi(in_img, meta_dict, out_data_path)</code>","text":"<p>infer golgi and write inferred golgi to ome.tif file</p>"},{"location":"infer_subc/organelles/golgi/#infer_subc.organelles.golgi.infer_and_export_golgi--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/golgi/#infer_subc.organelles.golgi.infer_and_export_golgi--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/golgi.py</code> <pre><code>def infer_and_export_golgi(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    infer golgi and write inferred golgi to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    golgi = fixed_infer_golgi(in_img)\n    out_file_n = export_inferred_organelle(golgi, \"golgi\", meta_dict, out_data_path)\n    print(f\"inferred golgi. wrote {out_file_n}\")\n    return golgi\n</code></pre>"},{"location":"infer_subc/organelles/golgi/#infer_subc.organelles.golgi.infer_golgi","title":"<code>infer_golgi(in_img, median_sz, gauss_sig, mo_method, mo_adjust, mo_cutoff_size, min_thickness, thin, dot_scale, dot_cut, small_obj_w)</code>","text":"<p>Procedure to infer golgi from linearly unmixed input.</p> <p>Parameters</p> <p>in_img:      a 3d image containing all the channels  median_sz:      width of median filter for signal  mo_method:       which method to use for calculating global threshold. Options include:       \"triangle\" (or \"tri\"), \"median\" (or \"med\"), and \"ave_tri_med\" (or \"ave\").       \"ave\" refers the average of \"triangle\" threshold and \"mean\" threshold.  mo_adjust:      Masked Object threshold <code>local_adjust</code>  mo_cutoff_size:      Masked Object threshold <code>size_min</code>  min_thinkness:      Half of the minimum width you want to keep from being thinned.      For example, when the object width is smaller than 4, you don't      want to make this part even thinner (may break the thin object      and alter the topology), you can set this value as 2.  thin:      the amount to thin (has to be an positive integer). The number of       pixels to be removed from outter boundary towards center.  dot_scale:      scales (log_sigma) for dot filter (1,2, and 3)  dot_cut:      threshold for dot filter thresholds (1,2,and 3)  small_obj_w:      minimu object size cutoff for nuclei post-processing</p> <p>Returns</p> <p>golgi_object      mask defined extent of golgi object</p> Source code in <code>infer_subc/organelles/golgi.py</code> <pre><code>def infer_golgi(\n    in_img: np.ndarray,\n    median_sz: int,\n    gauss_sig: float,\n    mo_method: str,\n    mo_adjust: float,\n    mo_cutoff_size: int,\n    min_thickness: int,\n    thin: int,\n    dot_scale: float,\n    dot_cut: float,\n    small_obj_w: int,\n) -&gt; np.ndarray:\n\"\"\"\n     Procedure to infer golgi from linearly unmixed input.\n\n    Parameters\n     ------------\n     in_img:\n         a 3d image containing all the channels\n     median_sz:\n         width of median filter for signal\n     mo_method:\n          which method to use for calculating global threshold. Options include:\n          \"triangle\" (or \"tri\"), \"median\" (or \"med\"), and \"ave_tri_med\" (or \"ave\").\n          \"ave\" refers the average of \"triangle\" threshold and \"mean\" threshold.\n     mo_adjust:\n         Masked Object threshold `local_adjust`\n     mo_cutoff_size:\n         Masked Object threshold `size_min`\n     min_thinkness:\n         Half of the minimum width you want to keep from being thinned.\n         For example, when the object width is smaller than 4, you don't\n         want to make this part even thinner (may break the thin object\n         and alter the topology), you can set this value as 2.\n     thin:\n         the amount to thin (has to be an positive integer). The number of\n          pixels to be removed from outter boundary towards center.\n     dot_scale:\n         scales (log_sigma) for dot filter (1,2, and 3)\n     dot_cut:\n         threshold for dot filter thresholds (1,2,and 3)\n     small_obj_w:\n         minimu object size cutoff for nuclei post-processing\n\n     Returns\n     -------------\n     golgi_object\n         mask defined extent of golgi object\n    \"\"\"\n    golgi_ch = GOLGI_CH\n\n    ###################\n    # EXTRACT\n    ###################\n    golgi = select_channel_from_raw(in_img, golgi_ch)\n\n    ###################\n    # PRE_PROCESSING\n    ###################\n    golgi = scale_and_smooth(golgi, median_sz=median_sz, gauss_sig=gauss_sig)\n    ###################\n    # CORE_PROCESSING\n    ###################\n    # bw = MO(golgi, global_thresh_method=thresh_method, object_minArea=obj_min_area)\n    bw = masked_object_thresh(golgi, th_method=mo_method, cutoff_size=mo_cutoff_size, th_adjust=mo_adjust)\n\n    bw_thin = topology_preserving_thinning(bw, min_thickness, thin)\n\n    s3_param = [(dot_cut, dot_scale)]\n    bw_extra = dot_2d_slice_by_slice_wrapper(golgi, s3_param)\n    # bw_extra = dot_3d_wrapper(golgi, s3_param)\n\n    bw = np.logical_or(bw_extra, bw_thin)\n    ###################\n    # POST_PROCESSING\n    ###################\n    struct_obj = size_filter_linear_size(bw, min_size=small_obj_w, connectivity=1)\n\n    return label_uint16(struct_obj)\n</code></pre>"},{"location":"infer_subc/organelles/lipid/","title":"infer_subc/organelles/lipid","text":""},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.fixed_infer_LD","title":"<code>fixed_infer_LD(in_img)</code>","text":"<p>Procedure to infer cellmask from linearly unmixed input, with a fixed set of parameters for each step in the procedure.  i.e. \"hard coded\"</p>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.fixed_infer_LD--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.fixed_infer_LD--returns","title":"Returns","text":"<p>LD_body_object     mask defined extent of liipid body</p> Source code in <code>infer_subc/organelles/lipid.py</code> <pre><code>def fixed_infer_LD(in_img: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer cellmask from linearly unmixed input, with a *fixed* set of parameters for each step in the procedure.  i.e. \"hard coded\"\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n\n    Returns\n    -------------\n    LD_body_object\n        mask defined extent of liipid body\n\n    \"\"\"\n    median_sz = 0\n    gauss_sig = 2.34\n    method = \"otsu\"\n    threshold_factor = 0.99  # from cellProfiler\n    thresh_min = 0.5\n    thresh_max = 1.0\n    max_hole_w = 2.5\n    small_obj_w = 4\n\n    return infer_LD(\n        in_img, median_sz, gauss_sig, method, threshold_factor, thresh_min, thresh_max, max_hole_w, small_obj_w\n    )\n</code></pre>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.get_LD","title":"<code>get_LD(in_img, meta_dict, out_data_path)</code>","text":"<p>load lipid if it exists, otherwise calculate and write to ome.tif file</p>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.get_LD--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.get_LD--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/lipid.py</code> <pre><code>def get_LD(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    load lipid if it exists, otherwise calculate and write to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n\n    try:\n        lipid = import_inferred_organelle(\"LD\", meta_dict, out_data_path)\n    except:\n        start = time.time()\n        print(\"starting segmentation...\")\n        lipid = infer_and_export_LD(in_img, meta_dict, out_data_path)\n        end = time.time()\n        print(f\"inferred (and exported) lipid in ({(end - start):0.2f}) sec\")\n\n    return lipid\n</code></pre>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.infer_LD","title":"<code>infer_LD(in_img, median_sz, gauss_sig, method, thresh_factor, thresh_min, thresh_max, max_hole_w, small_obj_w)</code>","text":"<p>Procedure to infer peroxisome from linearly unmixed input.</p>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.infer_LD--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p> median_sz <p>width of median filter for signal</p> gauss_sig <p>sigma for gaussian smoothing of  signal</p> method <p>method for applying threshold.  \"otsu\"  or \"li\", \"triangle\", \"median\", \"ave\", \"sauvola\",\"multi_otsu\",\"muiltiotsu\"</p> thresh_factor <p>scaling value for threshold</p> thresh_min <p>absolute minumum for threshold</p> thresh_max <p>absolute maximum for threshold</p> max_hole_w <p>hole filling cutoff for lipid post-processing</p> small_obj_w <p>minimu object size cutoff for lipid post-processing</p>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.infer_LD--returns","title":"Returns","text":"<p>peroxi_object     mask defined extent of peroxisome object</p> Source code in <code>infer_subc/organelles/lipid.py</code> <pre><code>def infer_LD(\n    in_img: np.ndarray,\n    median_sz: int,\n    gauss_sig: float,\n    method: str,\n    thresh_factor: float,\n    thresh_min: float,\n    thresh_max: float,\n    max_hole_w: int,\n    small_obj_w: int,\n) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer peroxisome from linearly unmixed input.\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n    median_sz:\n        width of median filter for signal\n    gauss_sig:\n        sigma for gaussian smoothing of  signal\n    method:\n        method for applying threshold.  \"otsu\"  or \"li\", \"triangle\", \"median\", \"ave\", \"sauvola\",\"multi_otsu\",\"muiltiotsu\"\n    thresh_factor:\n        scaling value for threshold\n    thresh_min:\n        absolute minumum for threshold\n    thresh_max:\n        absolute maximum for threshold\n    max_hole_w:\n        hole filling cutoff for lipid post-processing\n    small_obj_w:\n        minimu object size cutoff for lipid post-processing\n    Returns\n    -------------\n    peroxi_object\n        mask defined extent of peroxisome object\n    \"\"\"\n    LD_ch = LD_CH\n    ###################\n    # EXTRACT\n    ###################\n    lipid = select_channel_from_raw(in_img, LD_ch)\n    ###################\n    # PRE_PROCESSING\n    ###################\n    lipid = scale_and_smooth(lipid, median_sz=median_sz, gauss_sig=gauss_sig)\n\n    ###################\n    # CORE_PROCESSING\n    ###################\n    bw = apply_threshold(\n        lipid, method=method, thresh_factor=thresh_factor, thresh_min=thresh_min, thresh_max=thresh_max\n    )\n\n    ###################\n    # POST_PROCESSING\n    ###################\n    # min_hole_w = 0\n    struct_obj = fill_and_filter_linear_size(bw, hole_min=0, hole_max=max_hole_w, min_size=small_obj_w)\n\n    return label_uint16(struct_obj)\n</code></pre>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.infer_and_export_LD","title":"<code>infer_and_export_LD(in_img, meta_dict, out_data_path)</code>","text":"<p>infer lipid bodies and write inferred lipid to ome.tif file</p>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.infer_and_export_LD--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/lipid/#infer_subc.organelles.lipid.infer_and_export_LD--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/lipid.py</code> <pre><code>def infer_and_export_LD(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    infer lipid bodies and write inferred lipid to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    lipid = fixed_infer_LD(in_img)\n    out_file_n = export_inferred_organelle(lipid, \"LD\", meta_dict, out_data_path)\n    print(f\"inferred lipid. wrote {out_file_n}\")\n    return lipid\n</code></pre>"},{"location":"infer_subc/organelles/lysosome/","title":"infer_subc/organelles/lysosome","text":""},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.fixed_infer_lyso","title":"<code>fixed_infer_lyso(in_img)</code>","text":"<p>Procedure to infer lyso from linearly unmixed input</p>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.fixed_infer_lyso--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.fixed_infer_lyso--returns","title":"Returns","text":"nuclei_object <p>mask defined extent of NU</p> Source code in <code>infer_subc/organelles/lysosome.py</code> <pre><code>def fixed_infer_lyso(in_img: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer lyso from linearly unmixed input\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n\n    Returns\n    -------------\n    nuclei_object:\n        mask defined extent of NU\n    \"\"\"\n    median_sz = 4\n    gauss_sig = 1.34\n    dot_scale_1 = 5\n    dot_cut_1 = 0.09\n    dot_scale_2 = 2.5\n    dot_cut_2 = 0.07\n    dot_scale_3 = 1\n    dot_cut_3 = 0.01\n    filament_scale = 1\n    filament_cut = 0.15\n    min_hole_w = 0\n    max_hole_w = 25\n    small_obj_w = 3\n\n    return infer_lyso(\n        in_img,\n        median_sz,\n        gauss_sig,\n        dot_cut_1,\n        dot_scale_1,\n        dot_cut_2,\n        dot_scale_2,\n        dot_cut_3,\n        dot_scale_3,\n        filament_scale,\n        filament_cut,\n        min_hole_w,\n        max_hole_w,\n        small_obj_w,\n    )\n</code></pre>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.get_lyso","title":"<code>get_lyso(in_img, meta_dict, out_data_path)</code>","text":"<p>load lyso if it exists, otherwise calculate and write to ome.tif file</p>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.get_lyso--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.get_lyso--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/lysosome.py</code> <pre><code>def get_lyso(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    load lyso if it exists, otherwise calculate and write to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    try:\n        start = time.time()\n        lyso = import_inferred_organelle(\"lyso\", meta_dict, out_data_path)\n        end = time.time()\n        print(f\"loaded lyso in ({(end - start):0.2f}) sec\")\n    except:\n        start = time.time()\n        print(\"starting segmentation...\")\n        lyso = infer_and_export_lyso(in_img, meta_dict, out_data_path)\n        end = time.time()\n        print(f\"inferred (and exported) lyso in ({(end - start):0.2f}) sec\")\n\n    return lyso\n</code></pre>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.infer_and_export_lyso","title":"<code>infer_and_export_lyso(in_img, meta_dict, out_data_path)</code>","text":"<p>infer lyso and write inferred lyso to ome.tif file</p>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.infer_and_export_lyso--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.infer_and_export_lyso--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/lysosome.py</code> <pre><code>def infer_and_export_lyso(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    infer lyso and write inferred lyso to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    lyso = fixed_infer_lyso(in_img)\n    out_file_n = export_inferred_organelle(lyso, \"lyso\", meta_dict, out_data_path)\n    print(f\"inferred lyso. wrote {out_file_n}\")\n    return lyso\n</code></pre>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.infer_lyso","title":"<code>infer_lyso(in_img, median_sz, gauss_sig, dot_scale_1, dot_cut_1, dot_scale_2, dot_cut_2, dot_scale_3, dot_cut_3, filament_scale, filament_cut, min_hole_w, max_hole_w, small_obj_w)</code>","text":"<p>Procedure to infer lyso from linearly unmixed input</p>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.infer_lyso--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p> median_sz <p>width of median filter for signal</p> gauss_sig <p>sigma for gaussian smoothing of  signal</p> dot_scale <p>scales (log_sigma) for dot filter (1,2, and 3)</p> dot_cut <p>threshold for dot filter thresholds (1,2,and 3)</p> filament_scale <p>scale (log_sigma) for filament filter</p> filament_cut <p>threshold for filament fitered threshold</p> min_hole_w <p>hole filling min for nuclei post-processing</p> max_hole_w <p>hole filling cutoff for nuclei post-processing</p> small_obj_w <p>minimu object size cutoff for nuclei post-processing</p>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.infer_lyso--returns","title":"Returns","text":"lyso_object <p>mask defined extent of lyso object</p> Source code in <code>infer_subc/organelles/lysosome.py</code> <pre><code>def infer_lyso(\n    in_img: np.ndarray,\n    median_sz: int,\n    gauss_sig: float,\n    dot_scale_1: float,\n    dot_cut_1: float,\n    dot_scale_2: float,\n    dot_cut_2: float,\n    dot_scale_3: float,\n    dot_cut_3: float,\n    filament_scale: float,\n    filament_cut: float,\n    min_hole_w: int,\n    max_hole_w: int,\n    small_obj_w: int,\n) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer lyso from linearly unmixed input\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n    median_sz:\n        width of median filter for signal\n    gauss_sig:\n        sigma for gaussian smoothing of  signal\n    dot_scale:\n        scales (log_sigma) for dot filter (1,2, and 3)\n    dot_cut:\n        threshold for dot filter thresholds (1,2,and 3)\n    filament_scale:\n        scale (log_sigma) for filament filter\n    filament_cut:\n        threshold for filament fitered threshold\n    min_hole_w:\n        hole filling min for nuclei post-processing\n    max_hole_w:\n        hole filling cutoff for nuclei post-processing\n    small_obj_w:\n        minimu object size cutoff for nuclei post-processing\n\n    Returns\n    -------------\n    lyso_object:\n        mask defined extent of lyso object\n\n    \"\"\"\n    lyso_ch = LYSO_CH\n    ###################\n    # EXTRACT\n    ###################\n    lyso = select_channel_from_raw(in_img, lyso_ch)\n\n    ###################\n    # PRE_PROCESSING\n    ###################\n    lyso = scale_and_smooth(lyso, median_sz=median_sz, gauss_sig=gauss_sig)\n\n    ###################\n    # CORE_PROCESSING\n    ###################\n    s2_param = [[dot_scale_1, dot_cut_1], [dot_scale_2, dot_cut_2], [dot_scale_3, dot_cut_3]]\n    bw_spot = dot_2d_slice_by_slice_wrapper(lyso, s2_param)\n\n    f2_param = [[filament_scale, filament_cut]]\n    bw_filament = filament_2d_wrapper(lyso, f2_param)\n    # TODO: consider 3D version to call: aicssegmentation::vesselness3D\n\n    bw = np.logical_or(bw_spot, bw_filament)\n\n    ###################\n    # POST_PROCESSING\n    ###################\n    struct_obj = fill_and_filter_linear_size(bw, hole_min=min_hole_w, hole_max=max_hole_w, min_size=small_obj_w)\n    return label_uint16(struct_obj)\n</code></pre>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.lyso_filiment_filter","title":"<code>lyso_filiment_filter(in_img)</code>","text":"<p>spot filter helper function for lyso (DEPRICATED)</p> Source code in <code>infer_subc/organelles/lysosome.py</code> <pre><code>def lyso_filiment_filter(in_img: np.ndarray) -&gt; np.ndarray:\n\"\"\"spot filter helper function for lyso (DEPRICATED)\"\"\"\n    filament_scale = 1\n    filament_cut = 0.15\n    f2_param = [[filament_scale, filament_cut]]\n    # f2_param = [[1, 0.15]]  # [scale_1, cutoff_1]\n    return filament_2d_wrapper(in_img, f2_param)\n</code></pre>"},{"location":"infer_subc/organelles/lysosome/#infer_subc.organelles.lysosome.lyso_spot_filter","title":"<code>lyso_spot_filter(in_img)</code>","text":"<p>spot filter helper function for lyso</p> Source code in <code>infer_subc/organelles/lysosome.py</code> <pre><code>def lyso_spot_filter(in_img: np.ndarray) -&gt; np.ndarray:\n\"\"\"spot filter helper function for lyso\"\"\"\n    dot_scale_1 = 5\n    dot_cut_1 = 0.09\n    dot_scale_2 = 2.5\n    dot_cut_2 = 0.07\n    dot_scale_3 = 1\n    dot_cut_3 = 0.01\n    s2_param = [[dot_scale_1, dot_cut_1], [dot_scale_2, dot_cut_2], [dot_scale_3, dot_cut_3]]\n    return dot_2d_slice_by_slice_wrapper(in_img, s2_param)\n</code></pre>"},{"location":"infer_subc/organelles/mitochondria/","title":"infer_subc/organelles/mitochondria","text":""},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.fixed_infer_mito","title":"<code>fixed_infer_mito(in_img)</code>","text":"<p>Procedure to infer mitochondria from linearly unmixed input</p>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.fixed_infer_mito--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.fixed_infer_mito--returns","title":"Returns","text":"<p>mito_object     mask defined extent of mitochondria</p> Source code in <code>infer_subc/organelles/mitochondria.py</code> <pre><code>def fixed_infer_mito(in_img: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer mitochondria from linearly unmixed input\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n\n    Returns\n    -------------\n    mito_object\n        mask defined extent of mitochondria\n    \"\"\"\n    median_sz = 3\n    gauss_sig = 1.4\n    vesselness_scale = 1.5\n    vesselness_cut = 0.05\n    small_obj_w = 3\n\n    return infer_mito(in_img, median_sz, gauss_sig, vesselness_scale, vesselness_cut, small_obj_w)\n</code></pre>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.get_mito","title":"<code>get_mito(in_img, meta_dict, out_data_path)</code>","text":"<p>load mitochondria if it exists, otherwise calculate and write to ome.tif file</p>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.get_mito--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.get_mito--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/mitochondria.py</code> <pre><code>def get_mito(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    load mitochondria if it exists, otherwise calculate and write to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n\n    try:\n        mitochondria = import_inferred_organelle(\"mito\", meta_dict, out_data_path)\n    except:\n        start = time.time()\n        print(\"starting segmentation...\")\n        mitochondria = infer_and_export_mito(in_img, meta_dict, out_data_path)\n        end = time.time()\n        print(f\"inferred (and exported) mitochondria in ({(end - start):0.2f}) sec\")\n\n    return mitochondria\n</code></pre>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.infer_and_export_mito","title":"<code>infer_and_export_mito(in_img, meta_dict, out_data_path)</code>","text":"<p>infer mitochondria and write inferred mitochondria to ome.tif file</p>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.infer_and_export_mito--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.infer_and_export_mito--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/mitochondria.py</code> <pre><code>def infer_and_export_mito(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    infer mitochondria and write inferred mitochondria to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    mitochondria = fixed_infer_mito(in_img)\n    out_file_n = export_inferred_organelle(mitochondria, \"mito\", meta_dict, out_data_path)\n    print(f\"inferred mitochondria. wrote {out_file_n}\")\n    return mitochondria\n</code></pre>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.infer_mito","title":"<code>infer_mito(in_img, median_sz, gauss_sig, vesselness_scale, vesselness_cut, small_obj_w)</code>","text":"<p>Procedure to infer mitochondria from linearly unmixed input.</p>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.infer_mito--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p> median_sz <p>width of median filter for signal</p> gauss_sig <p>sigma for gaussian smoothing of  signal</p> vesselness_scale <p>scale (log_sigma) for vesselness filter</p> vesselness_cut <p>threshold for vesselness fitered threshold</p> small_obj_w <p>minimu object size cutoff for nuclei post-processing</p>"},{"location":"infer_subc/organelles/mitochondria/#infer_subc.organelles.mitochondria.infer_mito--returns","title":"Returns","text":"<p>mito_object     mask defined extent of mitochondria</p> Source code in <code>infer_subc/organelles/mitochondria.py</code> <pre><code>def infer_mito(\n    in_img: np.ndarray,\n    median_sz: int,\n    gauss_sig: float,\n    vesselness_scale: float,\n    vesselness_cut: float,\n    small_obj_w: int,\n) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer mitochondria from linearly unmixed input.\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n    median_sz:\n        width of median filter for signal\n    gauss_sig:\n        sigma for gaussian smoothing of  signal\n    vesselness_scale:\n        scale (log_sigma) for vesselness filter\n    vesselness_cut:\n        threshold for vesselness fitered threshold\n    small_obj_w:\n        minimu object size cutoff for nuclei post-processing\n\n    Returns\n    -------------\n    mito_object\n        mask defined extent of mitochondria\n    \"\"\"\n    mito_ch = MITO_CH\n    ###################\n    # EXTRACT\n    ###################\n    mito = select_channel_from_raw(in_img, MITO_CH)\n\n    ###################\n    # PRE_PROCESSING\n    ###################\n    struct_img = scale_and_smooth(mito, median_sz=median_sz, gauss_sig=gauss_sig)\n\n    ###################\n    # CORE_PROCESSING\n    ###################\n    struct_img = vesselness_slice_by_slice(struct_img, sigma=vesselness_scale, cutoff=vesselness_cut, tau=0.75)\n\n    ###################\n    # POST_PROCESSING\n    ###################\n    struct_obj = size_filter_linear_size(struct_img, min_size=small_obj_w)\n\n    return label_uint16(struct_obj)\n</code></pre>"},{"location":"infer_subc/organelles/nuclei/","title":"infer_subc/organelles/nuclei","text":""},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.fixed_infer_nuclei","title":"<code>fixed_infer_nuclei(in_img)</code>","text":"<p>Procedure to infer cellmask from linearly unmixed input, with a fixed set of parameters for each step in the procedure.  i.e. \"hard coded\"</p>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.fixed_infer_nuclei--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels</p>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.fixed_infer_nuclei--returns","title":"Returns","text":"<p>nuclei_object     inferred nuclei</p> Source code in <code>infer_subc/organelles/nuclei.py</code> <pre><code>def fixed_infer_nuclei(in_img: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer cellmask from linearly unmixed input, with a *fixed* set of parameters for each step in the procedure.  i.e. \"hard coded\"\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels\n\n    Returns\n    -------------\n    nuclei_object\n        inferred nuclei\n\n    \"\"\"\n    nuc_ch = NUC_CH\n    median_sz = 4\n    gauss_sig = 1.34\n    thresh_factor = 0.9\n    thresh_min = 0.1\n    thresh_max = 1.0\n    max_hole_w = 25\n    small_obj_w = 15\n\n    return infer_nuclei_fromlabel(\n        in_img, nuc_ch, median_sz, gauss_sig, thresh_factor, thresh_min, thresh_max, max_hole_w, small_obj_w\n    )\n</code></pre>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.get_nuclei","title":"<code>get_nuclei(in_img, meta_dict, out_data_path)</code>","text":"<p>load nucleus if it exists, otherwise calculate and write to ome.tif file</p>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.get_nuclei--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.get_nuclei--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/nuclei.py</code> <pre><code>def get_nuclei(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    load nucleus if it exists, otherwise calculate and write to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n\n    try:\n        nuclei = import_inferred_organelle(\"nuc\", meta_dict, out_data_path)\n    except:\n        start = time.time()\n        print(\"starting segmentation...\")\n        nuclei = infer_and_export_nuclei(in_img, meta_dict, out_data_path)\n        end = time.time()\n        print(f\"inferred nuclei in ({(end - start):0.2f}) sec\")\n\n    return nuclei\n</code></pre>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.infer_and_export_nuclei","title":"<code>infer_and_export_nuclei(in_img, meta_dict, out_data_path)</code>","text":"<p>infer nuclei and write inferred nuclei to ome.tif file</p>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.infer_and_export_nuclei--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.infer_and_export_nuclei--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/nuclei.py</code> <pre><code>def infer_and_export_nuclei(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    infer nuclei and write inferred nuclei to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    nuclei = fixed_infer_nuclei(in_img)\n\n    out_file_n = export_inferred_organelle(nuclei, \"nuc\", meta_dict, out_data_path)\n    print(f\"inferred nuclei. wrote {out_file_n}\")\n    return nuclei\n</code></pre>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.infer_nuclei_fromlabel","title":"<code>infer_nuclei_fromlabel(in_img, nuc_ch, median_sz, gauss_sig, thresh_factor, thresh_min, thresh_max, max_hole_w, small_obj_w)</code>","text":"<p>Procedure to infer nuclei from linearly unmixed input.</p>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.infer_nuclei_fromlabel--parameters","title":"Parameters","text":"in_img <p>a 3d image containing all the channels; np.ndarray</p> median_sz <p>width of median filter for signal</p> gauss_sig <p>sigma for gaussian smoothing of  signal</p> thresh_factor <p>adjustment factor for log Li threholding</p> thresh_min <p>abs min threhold for log Li threholding</p> thresh_max <p>abs max threhold for log Li threholding</p> max_hole_w <p>hole filling cutoff for nuclei post-processing0</p> small_obj_w <p>minimu object size cutoff for nuclei post-processing</p>"},{"location":"infer_subc/organelles/nuclei/#infer_subc.organelles.nuclei.infer_nuclei_fromlabel--returns","title":"Returns","text":"<p>nuclei_object     mask defined extent of NU</p> Source code in <code>infer_subc/organelles/nuclei.py</code> <pre><code>def infer_nuclei_fromlabel(\n    in_img: np.ndarray,\n    nuc_ch: Union[int, None],\n    median_sz: int,\n    gauss_sig: float,\n    thresh_factor: float,\n    thresh_min: float,\n    thresh_max: float,\n    max_hole_w: int,\n    small_obj_w: int,\n) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer nuclei from linearly unmixed input.\n\n    Parameters\n    ------------\n    in_img:\n        a 3d image containing all the channels; np.ndarray\n    median_sz:\n        width of median filter for signal\n    gauss_sig:\n        sigma for gaussian smoothing of  signal\n    thresh_factor:\n        adjustment factor for log Li threholding\n    thresh_min:\n        abs min threhold for log Li threholding\n    thresh_max:\n        abs max threhold for log Li threholding\n    max_hole_w:\n        hole filling cutoff for nuclei post-processing0\n    small_obj_w:\n        minimu object size cutoff for nuclei post-processing\n\n    Returns\n    -------------\n    nuclei_object\n        mask defined extent of NU\n\n    \"\"\"\n\n    ###################\n    # PRE_PROCESSING\n    ###################\n    if nuc_ch is None:\n        nuc_ch = NUC_CH\n\n    nuclei = select_channel_from_raw(in_img, nuc_ch)\n\n    nuclei = scale_and_smooth(nuclei, median_sz=median_sz, gauss_sig=gauss_sig)\n\n    ###################\n    # CORE_PROCESSING\n    ###################\n    nuclei_object = apply_log_li_threshold(\n        nuclei, thresh_factor=thresh_factor, thresh_min=thresh_min, thresh_max=thresh_max\n    )\n\n    ###################\n    # POST_PROCESSING\n    ###################\n    nuclei_object = fill_and_filter_linear_size(nuclei_object, hole_min=0, hole_max=max_hole_w, min_size=small_obj_w)\n\n    return label_uint16(nuclei_object)\n</code></pre>"},{"location":"infer_subc/organelles/peroxisome/","title":"infer_subc/organelles/peroxisome","text":""},{"location":"infer_subc/organelles/peroxisome/#infer_subc.organelles.peroxisome.fixed_infer_perox","title":"<code>fixed_infer_perox(in_img)</code>","text":"<p>Procedure to infer peroxisome from linearly unmixed input with fixed parameters.</p> <p>Parameters</p> <p>in_img: np.ndarray      a 3d image containing all the channels</p> <p>Returns</p> <p>peroxi_object      mask defined extent of peroxisome object</p> Source code in <code>infer_subc/organelles/peroxisome.py</code> <pre><code>def fixed_infer_perox(in_img: np.ndarray) -&gt; np.ndarray:\n\"\"\"\n      Procedure to infer peroxisome from linearly unmixed input with fixed parameters.\n\n    Parameters\n     ------------\n     in_img: np.ndarray\n         a 3d image containing all the channels\n\n     Returns\n     -------------\n     peroxi_object\n         mask defined extent of peroxisome object\n    \"\"\"\n    median_sz = 0\n    gauss_sig = 3.0\n    dot_scale = 1.0\n    dot_cut = 0.01\n    small_obj_w = 2\n\n    return infer_perox(\n        in_img,\n        median_sz,\n        gauss_sig,\n        dot_scale,\n        dot_cut,\n        small_obj_w,\n    )\n</code></pre>"},{"location":"infer_subc/organelles/peroxisome/#infer_subc.organelles.peroxisome.get_perox","title":"<code>get_perox(in_img, meta_dict, out_data_path)</code>","text":"<p>load peroxisome if it exists, otherwise calculate and write to ome.tif file</p>"},{"location":"infer_subc/organelles/peroxisome/#infer_subc.organelles.peroxisome.get_perox--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/peroxisome/#infer_subc.organelles.peroxisome.get_perox--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/peroxisome.py</code> <pre><code>def get_perox(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    load peroxisome if it exists, otherwise calculate and write to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    try:\n        start = time.time()\n        print(\"starting segmentation...\")\n        peroxisome = import_inferred_organelle(\"perox\", meta_dict, out_data_path)\n        end = time.time()\n        print(f\"loaded peroxisome in ({(end - start):0.2f}) sec\")\n    except:\n        start = time.time()\n        print(\"starting segmentation...\")\n        peroxisome = infer_and_export_perox(in_img, meta_dict, out_data_path)\n        end = time.time()\n        print(f\"inferred (and exported) peroxisome in ({(end - start):0.2f}) sec\")\n\n    return peroxisome\n</code></pre>"},{"location":"infer_subc/organelles/peroxisome/#infer_subc.organelles.peroxisome.infer_and_export_perox","title":"<code>infer_and_export_perox(in_img, meta_dict, out_data_path)</code>","text":"<p>infer peroxisome and write inferred peroxisome to ome.tif file</p>"},{"location":"infer_subc/organelles/peroxisome/#infer_subc.organelles.peroxisome.infer_and_export_perox--parameters","title":"Parameters","text":"in_img <p>a 3d  np.ndarray image of the inferred organelle (labels or boolean)</p> meta_dict <p>dictionary of meta-data (ome)</p> out_data_path <p>Path object where tiffs are written to</p>"},{"location":"infer_subc/organelles/peroxisome/#infer_subc.organelles.peroxisome.infer_and_export_perox--returns","title":"Returns","text":"<p>exported file name</p> Source code in <code>infer_subc/organelles/peroxisome.py</code> <pre><code>def infer_and_export_perox(in_img: np.ndarray, meta_dict: Dict, out_data_path: Path) -&gt; np.ndarray:\n\"\"\"\n    infer peroxisome and write inferred peroxisome to ome.tif file\n\n    Parameters\n    ------------\n    in_img:\n        a 3d  np.ndarray image of the inferred organelle (labels or boolean)\n    meta_dict:\n        dictionary of meta-data (ome)\n    out_data_path:\n        Path object where tiffs are written to\n\n    Returns\n    -------------\n    exported file name\n\n    \"\"\"\n    peroxisome = fixed_infer_perox(in_img)\n    out_file_n = export_inferred_organelle(peroxisome, \"perox\", meta_dict, out_data_path)\n    print(f\"inferred peroxisome. wrote {out_file_n}\")\n    return peroxisome\n</code></pre>"},{"location":"infer_subc/organelles/peroxisome/#infer_subc.organelles.peroxisome.infer_perox","title":"<code>infer_perox(in_img, median_sz, gauss_sig, dot_scale, dot_cut, small_obj_w)</code>","text":"<p>Procedure to infer peroxisome from linearly unmixed input.</p> <p>Parameters</p> <p>in_img:      a 3d image containing all the channels</p> median_sz <p>width of median filter for signal</p> <p>gauss_sig:      sigma for gaussian smoothing of  signal  dot_scale:      scales (log_sigma) for dot filter (1,2, and 3)  dot_cut:      threshold for dot filter thresholds (1,2,and 3)  small_obj_w:      minimu object size cutoff for nuclei post-processing</p> <p>Returns</p> <p>peroxi_object      mask defined extent of peroxisome object</p> Source code in <code>infer_subc/organelles/peroxisome.py</code> <pre><code>def infer_perox(\n    in_img: np.ndarray,\n    median_sz: int,\n    gauss_sig: float,\n    dot_scale: float,\n    dot_cut: float,\n    small_obj_w: int,\n) -&gt; np.ndarray:\n\"\"\"\n    Procedure to infer peroxisome from linearly unmixed input.\n\n    Parameters\n     ------------\n     in_img:\n         a 3d image containing all the channels\n    median_sz:\n        width of median filter for signal\n     gauss_sig:\n         sigma for gaussian smoothing of  signal\n     dot_scale:\n         scales (log_sigma) for dot filter (1,2, and 3)\n     dot_cut:\n         threshold for dot filter thresholds (1,2,and 3)\n     small_obj_w:\n         minimu object size cutoff for nuclei post-processing\n\n     Returns\n     -------------\n     peroxi_object\n         mask defined extent of peroxisome object\n    \"\"\"\n    peroxi_ch = PEROX_CH\n    ###################\n    # EXTRACT\n    ###################\n    peroxi = select_channel_from_raw(in_img, peroxi_ch)\n\n    ###################\n    # PRE_PROCESSING\n    ###################\n    peroxi = scale_and_smooth(peroxi, median_sz=median_sz, gauss_sig=gauss_sig)  # skips for median_sz &lt; 2\n\n    ###################\n    # CORE_PROCESSING\n    ###################\n    s3_param = [[dot_scale, dot_cut]]\n    bw = dot_2d_slice_by_slice_wrapper(peroxi, s3_param)\n\n    ###################\n    # POST_PROCESSING\n    ###################\n    # struct_obj = size_filter_linear_size(bw, min_size=small_obj_w, connectivity=1)\n    struct_obj = fill_and_filter_linear_size(bw, hole_min=0, hole_max=0, min_size=small_obj_w)\n\n    return label_uint16(struct_obj)\n</code></pre>"},{"location":"infer_subc/utils/batch/","title":"infer_subc/utils","text":"<p>functions which help with processing batches of files</p>"},{"location":"infer_subc/utils/batch/#infer_subc.utils.batch.explode_mask","title":"<code>explode_mask(mask_path, postfix='masks', im_type='.tiff')</code>","text":"<p>Split a 3 channel 'masks' file into 'nuc', 'cell', and 'cyto' images.  WARNING: requires the channels to be nuc = 0, cell = 1, and cyto = 2</p> add logging instead of printing <p>append tiffcomments with provenance</p> Source code in <code>infer_subc/utils/batch.py</code> <pre><code>def explode_mask(mask_path: Union[Path,str], postfix: str= \"masks\", im_type: str = \".tiff\") -&gt; bool:\n\"\"\" \n    Split a 3 channel 'masks' file into 'nuc', 'cell', and 'cyto' images.  WARNING: requires the channels to be nuc = 0, cell = 1, and cyto = 2\n    TODO: add logging instead of printing\n        append tiffcomments with provenance\n    \"\"\"\n    if isinstance(mask_path, str): mask_path = Path(mask_path)\n    # load image \n    full_stem = mask_path.stem\n    if full_stem.endswith(postfix):\n        stem = full_stem.rstrip(postfix)\n        image = read_tiff_image(mask_path)\n        assert image.shape[0]==3\n\n        # make into np.uint16 labels\n        nuclei = label_uint16(image[0])\n        # export as np.uint8 (255)\n        cellmask = image[1]&gt;0            \n        cytoplasm = image[2]&gt;0\n\n        # write wasks\n        root_stem = mask_path.parent / stem\n        # ret1 = imwrite(f\"{root}nuclei{stem}\", nuclei)\n        ret1 = export_tiff(nuclei, f\"{stem}nuc\", mask_path.parent, None)\n        # ret2 = imwrite(f\"{root}cellmask{stem}\", cellmask)\n        ret2 = export_tiff(cellmask, f\"{stem}cell\", mask_path.parent, None)\n        # ret3 = imwrite(f\"{root}cytosol{stem}\", cytosol)\n        ret3 = export_tiff(cytoplasm, f\"{stem}cyto\", mask_path.parent, None)\n\n        # print(f\"wrote {stem}-{{nuclei,cellmask,cyto}}\")\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"infer_subc/utils/batch/#infer_subc.utils.batch.explode_masks","title":"<code>explode_masks(root_path, postfix='masks', im_type='.tiff')</code>","text":"add loggin instead of printing <p>append tiffcomments with provenance</p> Source code in <code>infer_subc/utils/batch.py</code> <pre><code>def explode_masks(root_path: Union[Path,str], postfix: str= \"masks\", im_type: str = \".tiff\"):\n\"\"\"  \n    TODO: add loggin instead of printing\n        append tiffcomments with provenance\n    \"\"\"\n    if isinstance(root_path, str): root_path = Path(root_path)\n\n    img_file_list = list_image_files(root_path,im_type, postfix)\n    wrote_cnt = 0\n    for img_f in img_file_list:\n        if explode_mask(img_f, postfix=postfix, im_type=im_type): \n            wrote_cnt += 1\n        else: \n            print(f\"failed to explode {img_f}\")\n    # else:\n    #     print(f\"how thefark!!! {img_f}\")\n\n\n    print(f\"exploded {wrote_cnt*100./len(img_file_list)} pct of {len(img_file_list)} files\")\n    return wrote_cnt\n</code></pre>"},{"location":"infer_subc/utils/batch/#infer_subc.utils.batch.find_segmentation_tiff_files","title":"<code>find_segmentation_tiff_files(prototype, organelles, int_path)</code>","text":"<p>find the nescessary image files based on protype, the organelles involved, and paths</p> Source code in <code>infer_subc/utils/batch.py</code> <pre><code>def find_segmentation_tiff_files(prototype:Union[Path,str], organelles: List[str], int_path: Union[Path,str]) -&gt; Dict:\n\"\"\"\n    find the nescessary image files based on protype, the organelles involved, and paths\n    \"\"\"\n\n    # raw\n    prototype = Path(prototype)\n    if not prototype.exists():\n        print(f\"bad prototype. please choose an existing `raw` file as prototype\")\n        return dict()\n    # make sure protoype ends with czi\n\n    out_files = {\"raw\":prototype}\n\n    int_path = Path(int_path) \n    # raw\n    if not int_path.is_dir():\n        print(f\"bad path argument. please choose an existing path containing organelle segmentations\")\n        return out_files\n\n    # cyto, cellmask\n    cyto_nm = int_path / f\"{prototype.stem}-cyto.tiff\"\n    if cyto_nm.exists():\n        out_files[\"cyto\"] = cyto_nm\n    else:\n        print(f\"cytosol mask not found.  We'll try to extract from masks \")\n        if explode_mask(int_path / f\"{prototype.stem}-masks.tiff\"): \n            out_files[\"cyto\"] = cyto_nm\n        else: \n            print(f\"failed to explode {prototype.stem}-masks.tiff\")\n            return out_files\n\n    cellmask_nm = int_path / f\"{prototype.stem}-cell.tiff\"\n    if  cellmask_nm.exists():\n        out_files[\"cell\"] = cellmask_nm\n    else:\n        print(f\"cellmask file not found in {int_path} returning\")\n        out_files[\"cell\"] = None\n\n    # organelles\n    for org_n in organelles:\n        org_name = Path(int_path) / f\"{prototype.stem}-{org_n}.tiff\"\n        if org_name.exists(): \n            out_files[org_n] = org_name\n        else: \n            print(f\"{org_n} .tiff file not found in {int_path} returning\")\n            out_files[org_n] = None\n\n    if \"nuc\" not in organelles:\n        nuc_nm = int_path / f\"{prototype.stem}-nuc.tiff\"\n        if  nuc_nm.exists():\n            out_files[\"nuc\"] = nuc_nm\n        else:\n            print(f\"nuc file not found in {int_path} returning\")\n            out_files[\"nuc\"] = None\n\n\n\n    return out_files\n</code></pre>"},{"location":"infer_subc/utils/batch/#infer_subc.utils.batch.fixed_infer_organelles","title":"<code>fixed_infer_organelles(img_data)</code>","text":"<p>wrapper to infer all organelles from a single multi-channel image</p> Source code in <code>infer_subc/utils/batch.py</code> <pre><code>def fixed_infer_organelles(img_data):\n\"\"\"\n    wrapper to infer all organelles from a single multi-channel image\n    \"\"\"\n    # ch_to_agg = (LYSO_CH, MITO_CH, GOLGI_CH, PEROX_CH, ER_CH, LD_CH)\n\n    # nuc_ch = NUC_CH\n    # optimal_Z = find_optimal_Z(img_data, nuc_ch, ch_to_agg)\n    # optimal_Z = fixed_find_optimal_Z(img_data)\n    # # Stage 1:  nuclei, cellmask, cytoplasm\n    # img_2D = fixed_get_optimal_Z_image(img_data)\n\n    cellmask = fixed_infer_cellmask_fromaggr(img_data)\n\n    nuclei_object = fixed_infer_nuclei(img_data, cellmask)\n\n    cytoplasm_mask = infer_cytoplasm(nuclei_object, cellmask)\n\n    # cyto masked objects.\n    lyso_object = fixed_infer_lyso(img_data, cytoplasm_mask)\n    mito_object = fixed_infer_mito(img_data, cytoplasm_mask)\n    golgi_object = fixed_infer_golgi(img_data, cytoplasm_mask)\n    peroxi_object = fixed_infer_perox(img_data, cytoplasm_mask)\n    er_object = fixed_infer_ER(img_data, cytoplasm_mask)\n    LD_object = fixed_infer_LD(img_data, cytoplasm_mask)\n\n    img_layers = [\n        nuclei_object,\n        lyso_object,\n        mito_object,\n        golgi_object,\n        peroxi_object,\n        er_object,\n        LD_object,\n        cellmask,\n        cytoplasm_mask,\n    ]\n\n    layer_names = [\n        \"nuclei\",\n        \"lyso\",\n        \"mitochondria\",\n        \"golgi\",\n        \"peroxisome\",\n        \"er\",\n        \"LD_body\",\n        \"cell\",\n        \"cytoplasm_mask\",\n    ]\n    # TODO: pack outputs into something napari readable\n    img_out = np.stack(img_layers, axis=0)\n    return (img_out, layer_names)\n</code></pre>"},{"location":"infer_subc/utils/batch/#infer_subc.utils.batch.process_czi_image","title":"<code>process_czi_image(czi_file_name, data_root_path)</code>","text":"<p>wrapper for processing</p> Source code in <code>infer_subc/utils/batch.py</code> <pre><code>def process_czi_image(czi_file_name, data_root_path):\n\"\"\"wrapper for processing\"\"\"\n\n    img_data, meta_dict = read_czi_image(czi_file_name)\n    # # get some top-level info about the RAW data\n    # channel_names = meta_dict['name']\n    # img = meta_dict['metadata']['aicsimage']\n    # scale = meta_dict['scale']\n    # channel_axis = meta_dict['channel_axis']\n\n    inferred_organelles, layer_names, optimal_Z = fixed_infer_organelles(img_data)\n    out_file_n = export_inferred_organelle(inferred_organelles, layer_names, meta_dict, data_root_path)\n\n    ## TODO:  collect stats...\n\n    return out_file_n\n</code></pre>"},{"location":"infer_subc/utils/batch/#infer_subc.utils.batch.stack_organelle_layers","title":"<code>stack_organelle_layers(*layers)</code>","text":"<p>wrapper to stack the inferred objects into a single numpy.ndimage</p> Source code in <code>infer_subc/utils/batch.py</code> <pre><code>def stack_organelle_layers(*layers) -&gt; np.ndarray:\n\"\"\"wrapper to stack the inferred objects into a single numpy.ndimage\"\"\"\n\n    return np.stack(layers, axis=0)\n</code></pre>"},{"location":"infer_subc/utils/batch/#infer_subc.utils.batch.stack_organelle_objects","title":"<code>stack_organelle_objects(cellmask, nuclei_object, cytoplasm_mask, lyso_object, mito_object, golgi_object, peroxi_object, er_object, LD_object)</code>","text":"<p>wrapper to stack the inferred objects into a single numpy.ndimage</p> Source code in <code>infer_subc/utils/batch.py</code> <pre><code>def stack_organelle_objects(\n    cellmask,\n    nuclei_object,\n    cytoplasm_mask,\n    lyso_object,\n    mito_object,\n    golgi_object,\n    peroxi_object,\n    er_object,\n    LD_object,\n) -&gt; np.ndarray:\n\"\"\"wrapper to stack the inferred objects into a single numpy.ndimage\"\"\"\n    img_layers = [\n        cellmask,\n        nuclei_object,\n        cytoplasm_mask,\n        lyso_object,\n        mito_object,\n        golgi_object,\n        peroxi_object,\n        er_object,\n        LD_object,\n    ]\n    return np.stack(img_layers, axis=0)\n</code></pre>"},{"location":"infer_subc/utils/etc/","title":"infer_subc/utils","text":"<p>Also there are 'util/directories.py', 'util/filesystempy', 'util/lazy.py', and a hack from <code>aicsimageio</code> 'util/_aicsimage_reader.py'</p> <p>In the base module there are also 'constants.py' and 'exceptions.py'</p>"},{"location":"infer_subc/utils/stats/","title":"infer_subc/utils/stats.py","text":"<p>These functions take the segmentations and produce summary statistics with the <code>skimage.regionprops</code> </p>"},{"location":"infer_subc/utils/stats/#infer_subcutilsstats_helperpy","title":"infer_subc/utils/stats_helper.py","text":"<p>These helper functions bulk process the segmentations to produce the stats.</p>"},{"location":"infer_subc/utils/utils/","title":"Overview","text":""},{"location":"infer_subc/utils/utils/#infer_subcutils","title":"infer_subc/utils","text":""},{"location":"infer_subc/utils/utils/#infer_subcutils_1","title":"infer_subc/utils","text":"<p>Also there are 'util/directories.py', 'util/filesystempy', 'util/lazy.py', and a hack from <code>aicsimageio</code> 'util/_aicsimage_reader.py'</p>"},{"location":"nbs/overview/","title":"explanatory notebooks","text":"<p>This series of notebooks illustrates the </p> <p>Robust inference of subcellular objects:</p> <ul> <li>1\ufe0f\u20e3. Infer cellmask</li> <li>2\ufe0f\u20e3. infer nuclei </li> <li>3\ufe0f\u20e3. Infer cytoplasm</li> <li>4\ufe0f\u20e3. Infer lysosome</li> <li>5\ufe0f\u20e3. Infer mitochondria</li> <li>6\ufe0f\u20e3. Infer golgi complex</li> <li>7\ufe0f\u20e3. Infer peroxisome</li> <li>8\ufe0f\u20e3. Infer endoplasmic reticulum</li> <li>9\ufe0f\u20e3. Infer lipid body </li> </ul> <p>other examples</p> <ul> <li>1\ufe0f\u20e34\ufe0f\u20e3. final workflow</li> <li>1\ufe0f\u20e31\ufe0f\u20e3. batch process</li> </ul> <p>basics</p> <ul> <li>0\ufe0f\u20e30\ufe0f\u20e3.1\ufe0f\u20e3. framework overview</li> <li>0\ufe0f\u20e30\ufe0f\u20e3.1\ufe0f\u20e3. pipeline setup</li> </ul> <p>stats</p> <ul> <li>1\ufe0f\u20e30\ufe0f\u20e3. regionprop stats</li> </ul> <p>workflow .json composition</p> <ul> <li>1\ufe0f\u20e32\ufe0f\u20e3. function prototoypes</li> <li>1\ufe0f\u20e33\ufe0f\u20e3. workflow defs</li> </ul>"}]}